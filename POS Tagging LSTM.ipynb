{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3 Second Draft.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mkK8Gwt6Ze7E",
        "1D1MTm1mZjPH",
        "l_L4CpynZmGJ",
        "beIXXbMPTGOL",
        "7PT68vc5TR-H",
        "cFXxs8hJTUAE",
        "RPEeD2X-TcBS",
        "8ZTkg1h8Tdli",
        "79f76XjrTfya",
        "tyyfT7xWTiwC",
        "gGFyCB0tTk2N",
        "SJvsHq7YTny4",
        "LflHCsqkZ9Q0",
        "DastmMUHZslW",
        "KmDu9v3bk_E4",
        "UVWn8ibvm5UQ",
        "qyiksAgAlYPn",
        "N_3hiu1nlga6",
        "qYhHgNfClrI1",
        "klaZRLJUlxik",
        "f4Qi0jHgnYBg",
        "_fuFTJqzluVR",
        "INgd_jMEl8Hr",
        "1upNWl6Hl_iO",
        "FkdpYOmKmC9X",
        "X0dQor4FP6aW",
        "TL1UyJROQL7R",
        "aTzMeGURQRC1",
        "MYSDbQQXQbdu",
        "oTtMoGzhQio1",
        "trdBRj8TQj17",
        "BW0zdOcSQt-8",
        "hXIV4uKDQ17P",
        "l3dwbLFeQ9Be",
        "iAASZBTcQ-5M",
        "kVdHqXbxR9_f",
        "eGRKT0CMSaHI",
        "K2KVizu4Sxnz",
        "QUQlsFoLSCCM",
        "Zuot-2j6SLSi",
        "TZjGWdXTSOul",
        "SpfHNjDqSTjM",
        "9kCWJlWZp0Ma"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ssQS9JgkPfa",
        "outputId": "dd5acffd-feb5-4550-83b7-bebffcdf98ba"
      },
      "source": [
        "pip install pyconll"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/60/7f/148a5b6f99b8a22373bfbcafd9d6776278fec14810ae95c4fe37965f6619/pyconll-3.0.4-py3-none-any.whl\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G53Zv0thZXJl"
      },
      "source": [
        "# Import Packages and Datasets from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egc2ibsJdsI2"
      },
      "source": [
        "# Our standard imports for maths and basic methodology\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For user feedback\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pyconll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljs9CkCskWtk",
        "outputId": "fda89209-309f-4c42-d1eb-1caccf96e2c1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-Perseus/master/grc_perseus-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:11:57--  https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-Perseus/master/grc_perseus-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14837818 (14M) [text/plain]\n",
            "Saving to: ‘grc_perseus-ud-train.conllu’\n",
            "\n",
            "grc_perseus-ud-trai 100%[===================>]  14.15M  60.2MB/s    in 0.2s    \n",
            "\n",
            "2021-05-25 17:11:59 (60.2 MB/s) - ‘grc_perseus-ud-train.conllu’ saved [14837818/14837818]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Dq8yZAp67p",
        "outputId": "22a6fd90-f9d1-4348-aa4f-e7431e59e52f"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-Perseus/master/grc_perseus-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:11:59--  https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-Perseus/master/grc_perseus-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1980089 (1.9M) [text/plain]\n",
            "Saving to: ‘grc_perseus-ud-test.conllu’\n",
            "\n",
            "grc_perseus-ud-test 100%[===================>]   1.89M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:00 (33.0 MB/s) - ‘grc_perseus-ud-test.conllu’ saved [1980089/1980089]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPIFD8RCj6vj",
        "outputId": "38d390e9-0a74-4480-e21f-353fc832fd9b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/dev/es_ancora-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:00--  https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/dev/es_ancora-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29279116 (28M) [text/plain]\n",
            "Saving to: ‘es_ancora-ud-train.conllu’\n",
            "\n",
            "es_ancora-ud-train. 100%[===================>]  27.92M   107MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:01 (107 MB/s) - ‘es_ancora-ud-train.conllu’ saved [29279116/29279116]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSQkLEHqAup",
        "outputId": "df58a7af-cc67-4d35-ab9a-06a305d8f95b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/dev/es_ancora-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:01--  https://raw.githubusercontent.com/UniversalDependencies/UD_Spanish-AnCora/dev/es_ancora-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3461362 (3.3M) [text/plain]\n",
            "Saving to: ‘es_ancora-ud-test.conllu’\n",
            "\n",
            "es_ancora-ud-test.c 100%[===================>]   3.30M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-25 17:12:02 (23.3 MB/s) - ‘es_ancora-ud-test.conllu’ saved [3461362/3461362]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEaqXatEkbaV",
        "outputId": "a35742b5-5710-453f-fb4d-18be67a39d66"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Latin-Perseus/master/la_perseus-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:02--  https://raw.githubusercontent.com/UniversalDependencies/UD_Latin-Perseus/master/la_perseus-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1588955 (1.5M) [text/plain]\n",
            "Saving to: ‘la_perseus-ud-train.conllu’\n",
            "\n",
            "la_perseus-ud-train 100%[===================>]   1.51M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:03 (26.5 MB/s) - ‘la_perseus-ud-train.conllu’ saved [1588955/1588955]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4D6zMMBqEIe",
        "outputId": "dd31d661-7211-4cd5-ad2c-703d86174a6a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Latin-Perseus/master/la_perseus-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:03--  https://raw.githubusercontent.com/UniversalDependencies/UD_Latin-Perseus/master/la_perseus-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 984663 (962K) [text/plain]\n",
            "Saving to: ‘la_perseus-ud-test.conllu’\n",
            "\n",
            "la_perseus-ud-test. 100%[===================>] 961.58K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-05-25 17:12:03 (19.3 MB/s) - ‘la_perseus-ud-test.conllu’ saved [984663/984663]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8sKa0NMT-qQ",
        "outputId": "2fcbf53d-0d63-4412-ce42-149349852302"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_French-Sequoia/master/fr_sequoia-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:03--  https://raw.githubusercontent.com/UniversalDependencies/UD_French-Sequoia/master/fr_sequoia-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3160042 (3.0M) [text/plain]\n",
            "Saving to: ‘fr_sequoia-ud-train.conllu’\n",
            "\n",
            "fr_sequoia-ud-train 100%[===================>]   3.01M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-25 17:12:04 (28.6 MB/s) - ‘fr_sequoia-ud-train.conllu’ saved [3160042/3160042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62goLuWAT-4q",
        "outputId": "74679fe7-c865-4d52-8948-2692780af32d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_French-Sequoia/master/fr_sequoia-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:04--  https://raw.githubusercontent.com/UniversalDependencies/UD_French-Sequoia/master/fr_sequoia-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 627072 (612K) [text/plain]\n",
            "Saving to: ‘fr_sequoia-ud-test.conllu’\n",
            "\n",
            "fr_sequoia-ud-test. 100%[===================>] 612.38K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-25 17:12:04 (22.4 MB/s) - ‘fr_sequoia-ud-test.conllu’ saved [627072/627072]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kpwyIvrT_Pl",
        "outputId": "b5f776ee-1c28-41ee-decc-8817d1a9bbe4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Italian-VIT/master/it_vit-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:04--  https://raw.githubusercontent.com/UniversalDependencies/UD_Italian-VIT/master/it_vit-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14137747 (13M) [text/plain]\n",
            "Saving to: ‘it_vit-ud-train.conllu’\n",
            "\n",
            "it_vit-ud-train.con 100%[===================>]  13.48M  32.9MB/s    in 0.4s    \n",
            "\n",
            "2021-05-25 17:12:05 (32.9 MB/s) - ‘it_vit-ud-train.conllu’ saved [14137747/14137747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wxXcXkYT_uM",
        "outputId": "1b6e773f-3fd6-4a9b-e70d-c11486ad44a4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Italian-VIT/master/it_vit-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:05--  https://raw.githubusercontent.com/UniversalDependencies/UD_Italian-VIT/master/it_vit-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1653240 (1.6M) [text/plain]\n",
            "Saving to: ‘it_vit-ud-test.conllu’\n",
            "\n",
            "it_vit-ud-test.conl 100%[===================>]   1.58M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:06 (26.4 MB/s) - ‘it_vit-ud-test.conllu’ saved [1653240/1653240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1LWoSCKUAEG",
        "outputId": "f19053ec-05e3-4115-f19f-1a3da141a0db"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Dutch-LassySmall/master/nl_lassysmall-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:06--  https://raw.githubusercontent.com/UniversalDependencies/UD_Dutch-LassySmall/master/nl_lassysmall-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6123072 (5.8M) [text/plain]\n",
            "Saving to: ‘nl_lassysmall-ud-train.conllu’\n",
            "\n",
            "nl_lassysmall-ud-tr 100%[===================>]   5.84M  21.1MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:07 (21.1 MB/s) - ‘nl_lassysmall-ud-train.conllu’ saved [6123072/6123072]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq3VBLLBUAQ4",
        "outputId": "9794f3a3-609d-462c-cc82-5857716c1ee3"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Dutch-LassySmall/master/nl_lassysmall-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:07--  https://raw.githubusercontent.com/UniversalDependencies/UD_Dutch-LassySmall/master/nl_lassysmall-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 947436 (925K) [text/plain]\n",
            "Saving to: ‘nl_lassysmall-ud-test.conllu’\n",
            "\n",
            "nl_lassysmall-ud-te 100%[===================>] 925.23K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-05-25 17:12:08 (21.7 MB/s) - ‘nl_lassysmall-ud-test.conllu’ saved [947436/947436]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WPekQQvUAfp",
        "outputId": "8efb88be-1dba-496b-faf8-e929b9af933a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:08--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13473379 (13M) [text/plain]\n",
            "Saving to: ‘en_ewt-ud-train.conllu’\n",
            "\n",
            "en_ewt-ud-train.con 100%[===================>]  12.85M  64.2MB/s    in 0.2s    \n",
            "\n",
            "2021-05-25 17:12:09 (64.2 MB/s) - ‘en_ewt-ud-train.conllu’ saved [13473379/13473379]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ULapcpUAvS",
        "outputId": "8c6b8ed8-0a39-4cf7-b8cf-06400934051b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:09--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1713436 (1.6M) [text/plain]\n",
            "Saving to: ‘en_ewt-ud-test.conllu’\n",
            "\n",
            "en_ewt-ud-test.conl 100%[===================>]   1.63M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-05-25 17:12:09 (24.8 MB/s) - ‘en_ewt-ud-test.conllu’ saved [1713436/1713436]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hewFu_77UDe7",
        "outputId": "91a2d009-e3fe-414d-d806-f88e86cc4fba"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_German-GSD/master/de_gsd-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:09--  https://raw.githubusercontent.com/UniversalDependencies/UD_German-GSD/master/de_gsd-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19412594 (19M) [text/plain]\n",
            "Saving to: ‘de_gsd-ud-train.conllu’\n",
            "\n",
            "de_gsd-ud-train.con 100%[===================>]  18.51M  55.4MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:11 (55.4 MB/s) - ‘de_gsd-ud-train.conllu’ saved [19412594/19412594]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVO6wxQ4UDw3",
        "outputId": "094a842c-223b-4d08-fe69-8fb36cb9f8f6"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_German-GSD/master/de_gsd-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:11--  https://raw.githubusercontent.com/UniversalDependencies/UD_German-GSD/master/de_gsd-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1197660 (1.1M) [text/plain]\n",
            "Saving to: ‘de_gsd-ud-test.conllu’\n",
            "\n",
            "de_gsd-ud-test.conl 100%[===================>]   1.14M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:11 (17.6 MB/s) - ‘de_gsd-ud-test.conllu’ saved [1197660/1197660]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0MW_slNUD_G",
        "outputId": "015ffc69-190a-49b0-f0e9-a8f77ce13411"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:11--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13443822 (13M) [text/plain]\n",
            "Saving to: ‘fi_tdt-ud-train.conllu’\n",
            "\n",
            "fi_tdt-ud-train.con 100%[===================>]  12.82M  43.6MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:12 (43.6 MB/s) - ‘fi_tdt-ud-train.conllu’ saved [13443822/13443822]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY_GWu3jUEMQ",
        "outputId": "84b44a5c-8a36-488b-ceb4-c59c17271996"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:12--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1736471 (1.7M) [text/plain]\n",
            "Saving to: ‘fi_tdt-ud-test.conllu’\n",
            "\n",
            "fi_tdt-ud-test.conl 100%[===================>]   1.66M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:13 (27.0 MB/s) - ‘fi_tdt-ud-test.conllu’ saved [1736471/1736471]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYXt3HQsUEcG",
        "outputId": "65c572f8-dd9c-4717-e6b2-ccd0e920b178"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Swedish-Talbanken/master/sv_talbanken-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:13--  https://raw.githubusercontent.com/UniversalDependencies/UD_Swedish-Talbanken/master/sv_talbanken-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5839622 (5.6M) [text/plain]\n",
            "Saving to: ‘sv_talbanken-ud-train.conllu’\n",
            "\n",
            "sv_talbanken-ud-tra 100%[===================>]   5.57M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-25 17:12:14 (43.5 MB/s) - ‘sv_talbanken-ud-train.conllu’ saved [5839622/5839622]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgxFddbqdSXa",
        "outputId": "948075ee-f791-45d5-d6b8-7013dca5f629"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Swedish-Talbanken/master/sv_talbanken-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:14--  https://raw.githubusercontent.com/UniversalDependencies/UD_Swedish-Talbanken/master/sv_talbanken-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1781482 (1.7M) [text/plain]\n",
            "Saving to: ‘sv_talbanken-ud-test.conllu’\n",
            "\n",
            "sv_talbanken-ud-tes 100%[===================>]   1.70M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-25 17:12:14 (27.6 MB/s) - ‘sv_talbanken-ud-test.conllu’ saved [1781482/1781482]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWbRjnqUdeQg",
        "outputId": "1411d941-63f7-47c0-9517-3c5b6c152964"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Hebrew-HTB/master/he_htb-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:14--  https://raw.githubusercontent.com/UniversalDependencies/UD_Hebrew-HTB/master/he_htb-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10403144 (9.9M) [text/plain]\n",
            "Saving to: ‘he_htb-ud-train.conllu’\n",
            "\n",
            "he_htb-ud-train.con 100%[===================>]   9.92M  35.2MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:15 (35.2 MB/s) - ‘he_htb-ud-train.conllu’ saved [10403144/10403144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI52V1JsdenP",
        "outputId": "21d7ca4d-756e-4256-a7d5-c4c7be3e1eaf"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Hebrew-HTB/master/he_htb-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:15--  https://raw.githubusercontent.com/UniversalDependencies/UD_Hebrew-HTB/master/he_htb-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 931163 (909K) [text/plain]\n",
            "Saving to: ‘he_htb-ud-test.conllu’\n",
            "\n",
            "he_htb-ud-test.conl 100%[===================>] 909.34K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-05-25 17:12:15 (25.1 MB/s) - ‘he_htb-ud-test.conllu’ saved [931163/931163]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM_dguG0dnn3",
        "outputId": "5be26537-9b54-4ec9-cacb-c33307024fcd"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Afrikaans-AfriBooms/master/af_afribooms-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:16--  https://raw.githubusercontent.com/UniversalDependencies/UD_Afrikaans-AfriBooms/master/af_afribooms-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2125899 (2.0M) [text/plain]\n",
            "Saving to: ‘af_afribooms-ud-train.conllu’\n",
            "\n",
            "af_afribooms-ud-tra 100%[===================>]   2.03M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-05-25 17:12:16 (40.9 MB/s) - ‘af_afribooms-ud-train.conllu’ saved [2125899/2125899]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_a5WXnEdn1n",
        "outputId": "66da4fb2-5826-421c-f747-e57bce91dfc8"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Afrikaans-AfriBooms/master/af_afribooms-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:16--  https://raw.githubusercontent.com/UniversalDependencies/UD_Afrikaans-AfriBooms/master/af_afribooms-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 633696 (619K) [text/plain]\n",
            "Saving to: ‘af_afribooms-ud-test.conllu’\n",
            "\n",
            "af_afribooms-ud-tes 100%[===================>] 618.84K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-05-25 17:12:16 (16.4 MB/s) - ‘af_afribooms-ud-test.conllu’ saved [633696/633696]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-klqAesfP-P",
        "outputId": "fbcb08e0-8eaa-4304-8c7b-46708536654b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_French-FTB/master/fr_ftb-ud-train.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:16--  https://raw.githubusercontent.com/UniversalDependencies/UD_French-FTB/master/fr_ftb-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24657119 (24M) [text/plain]\n",
            "Saving to: ‘fr_ftb-ud-train.conllu’\n",
            "\n",
            "fr_ftb-ud-train.con 100%[===================>]  23.51M  68.2MB/s    in 0.3s    \n",
            "\n",
            "2021-05-25 17:12:18 (68.2 MB/s) - ‘fr_ftb-ud-train.conllu’ saved [24657119/24657119]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPRJQM62fQUZ",
        "outputId": "89c624f6-adb5-4b1b-d77d-fc5d2b299ca4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_French-FTB/master/fr_ftb-ud-test.conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 17:12:18--  https://raw.githubusercontent.com/UniversalDependencies/UD_French-FTB/master/fr_ftb-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4130256 (3.9M) [text/plain]\n",
            "Saving to: ‘fr_ftb-ud-test.conllu’\n",
            "\n",
            "fr_ftb-ud-test.conl 100%[===================>]   3.94M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-05-25 17:12:18 (41.7 MB/s) - ‘fr_ftb-ud-test.conllu’ saved [4130256/4130256]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkK8Gwt6Ze7E"
      },
      "source": [
        "# Latin Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKA4-KqCkuTv"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/la_perseus-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_latin_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_latin_train=[[word.upos for word in sentence] for sentence in conll] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RVCaqD9qQbQ"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/la_perseus-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_latin_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_latin_test=[[word.upos for word in sentence] for sentence in conll] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D1MTm1mZjPH"
      },
      "source": [
        "# Spanish Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgiuCGnkmJW",
        "outputId": "18d5e4fc-181f-4db9-bfcf-02c8dc89a491"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/es_ancora-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_spanish_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_spanish_train=[[word.upos for word in sentence] for sentence in conll] \n",
        "print(len(X_spanish_train))\n",
        "print(len(y_spanish_train))\n",
        "print(X_spanish_train[0])\n",
        "print(y_spanish_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14266\n",
            "14266\n",
            "['El', 'presidente', 'del', 'de', 'el', 'órgano', 'regulador', 'de', 'las', 'Telecomunicaciones', 'se', 'mostró', 'partidario', 'de', 'completar', 'esta', 'liberalización', 'de', 'las', 'telecomunicaciones', 'con', 'otras', 'medidas', 'que', 'incentiven', 'la', 'competencia', 'como', 'puede', 'ser', 'abrir', 'el', 'acceso', 'a', 'la', 'información', 'de', 'los', 'clientes', 'de', 'Telefónica', 'a', 'otros', 'operadores', '.']\n",
            "['DET', 'NOUN', None, 'ADP', 'DET', 'NOUN', 'ADJ', 'ADP', 'DET', 'PROPN', 'PRON', 'VERB', 'ADJ', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'DET', 'NOUN', 'SCONJ', 'NOUN', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM6rntcMqaHZ"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/es_ancora-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_spanish_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_spanish_test=[[word.upos for word in sentence] for sentence in conll] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_L4CpynZmGJ"
      },
      "source": [
        "# Ancient Greek Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndQdmDak7DT"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/grc_perseus-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_agreek_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_agreek_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Adhg8pVqqpy"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/grc_perseus-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_agreek_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_agreek_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beIXXbMPTGOL"
      },
      "source": [
        "# French Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6jPE1v1TuZv"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/fr_ftb-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_french_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_french_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9NLOoQsTu08"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/fr_ftb-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_french_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_french_test=[[word.upos for word in sentence] for sentence in conll] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PT68vc5TR-H"
      },
      "source": [
        "# Italian Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qgKivI_TvzP"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/it_vit-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_italian_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_italian_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waRZCIijTwGM"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/it_vit-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_italian_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_italian_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFXxs8hJTUAE"
      },
      "source": [
        "# Dutch Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfOgQApuTxAp"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/nl_lassysmall-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_dutch_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_dutch_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpndo1bCTxUP"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/nl_lassysmall-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_dutch_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_dutch_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPEeD2X-TcBS"
      },
      "source": [
        "# English Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKhd2diITyGd"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/en_ewt-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_english_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_english_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zz7u-ppTyT9"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/en_ewt-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_english_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_english_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZTkg1h8Tdli"
      },
      "source": [
        "# German Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwVRcMD4Ty9e"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/de_gsd-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_german_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_german_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2DalEfaTzJ0"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/de_gsd-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_german_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_german_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79f76XjrTfya"
      },
      "source": [
        "# Finnish Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMoPdbIDT0EB"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/fi_tdt-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_finnish_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_finnish_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MMvXoTbT0Wz"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/fi_tdt-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_finnish_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_finnish_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyyfT7xWTiwC"
      },
      "source": [
        "# Swedish Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I_vldnGT1GI"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/sv_talbanken-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_swedish_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_swedish_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2okwxAoeT1ai"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/sv_talbanken-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_swedish_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_swedish_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGFyCB0tTk2N"
      },
      "source": [
        "# Hebrew Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vSnTXtNT2S5"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/he_htb-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_hebrew_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_hebrew_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etmwn6OnT2l4"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/he_htb-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_hebrew_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_hebrew_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJvsHq7YTny4"
      },
      "source": [
        "# Afrikaans Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbuZ1wuCT3rO"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/af_afribooms-ud-train.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2]\n",
        "X_afrikaans_train=[[word.form for word in sentence] for sentence in conll] \n",
        "y_afrikaans_train=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3QWa1bdT4Ep"
      },
      "source": [
        "conll =pyconll.load_from_file('/content/af_afribooms-ud-test.conllu') \n",
        "conll=[sentence for sentence in conll if len(sentence)>2] \n",
        "X_afrikaans_test=[[word.form for word in sentence] for sentence in conll] \n",
        "y_afrikaans_test=[[word.upos for word in sentence] for sentence in conll] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LflHCsqkZ9Q0"
      },
      "source": [
        "# Number of Sentences and Sentence Length Data Visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSaNqSNnhHQ",
        "outputId": "b55b3595-357d-4767-d5fb-38b7e0ddcc7f"
      },
      "source": [
        "l = np.asarray([len(x) for x in X_spanish_train], dtype=np.int)\n",
        "plt.figure(figsize=(8, 4))\n",
        "x = np.unique(l)\n",
        "plt.bar(x, [np.sum(l==e) for e in x], width=1)\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"# sentences\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DastmMUHZslW"
      },
      "source": [
        "# Data Encoding and Padding for Spanish\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrIfib7cnkDA",
        "outputId": "7a49dfb9-296c-4642-c628-eac9237cb6c5"
      },
      "source": [
        "\n",
        "tokens = {token for sentence in X_spanish_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_spanish_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'Tratando', 'golazo', 'Ingresa', 'desmarque', 'Fischler', 'planetas', 'atribuyen', 'Ariza', 'Sáiz', 'Laboratory', 'fotográficamente', 'prestigioso', 'jubilarse', 'salpicado']\n",
            "['CCONJ', 'PUNCT', 'DET', 'SCONJ', 'VERB', 'INTJ', 'PRON', 'NOUN', 'ADJ', 'AUX', 'NUM', 'PROPN', 'PART', 'SYM', 'X', 'ADP', None, 'ADV', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA_M2ju4Z0iA",
        "outputId": "89c2ef30-0f9d-4265-aec3-31dac347c387"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_spanish_train[:5], y_spanish_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[29406, 33682, 12722, 27241, 37750, 25729, 36943, 27241, 24037, 26061,\n",
            "         13709, 25513, 24841, 27241, 36797, 36126,  7365, 27241, 24037,  1240,\n",
            "         18607, 23860, 24651, 36523,  8410, 21896, 30770, 31727, 37699,  6137,\n",
            "         37551, 37750, 27044, 13087, 21896, 31412, 27241,  5314, 23682, 27241,\n",
            "         19605, 13087, 36621,  3412, 35715, 38437, 38437, 38437, 38437, 38437,\n",
            "         38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437],\n",
            "        [ 6785, 21896, 15013, 27241, 16563, 18607, 19605, 27241, 36621,  3412,\n",
            "         36523, 31337, 27241, 34090, 21896,  6186, 21291, 34002, 12178,  3644,\n",
            "         36523, 17579, 21422, 26229, 21896,  9581,   279, 13087,  5314,  3412,\n",
            "         31680, 27479, 13087, 36621, 36523, 18717, 21007, 35036, 27479, 36523,\n",
            "         37850, 13087, 37750, 22245, 36523, 18589,  1850, 27406,  5935,  7893,\n",
            "         27090, 24319, 13087,  9507, 35715, 38437, 38437, 38437, 38437],\n",
            "        [ 1082, 36523, 37695, 37750, 22971,  5455, 27479, 36523,  9618, 27241,\n",
            "         10222, 37750, 28300,  5663, 26071, 16775, 28795, 35715, 38437, 38437,\n",
            "         38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
            "         38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
            "         38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
            "         38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437],\n",
            "        [11462, 36549, 36333, 30608, 32621,  5935, 37750, 28145, 17579, 37750,\n",
            "         31899, 27479, 21896, 20642, 37212, 21291,  6740, 16514,  5684, 21291,\n",
            "         37750, 16335, 27241, 23214, 27479, 37750, 30541, 27241, 30608, 27241,\n",
            "         21896, 31876, 27241, 20622, 21291,  3665, 14353,   674, 37097, 21896,\n",
            "         19695, 37458, 23344, 19695, 27241,  5314, 36218, 27479, 21896, 19695,\n",
            "         37458, 27241, 21896,   683, 19695, 27241,  5314,  5684, 35715],\n",
            "        [21563, 21896, 28192, 12722, 27241, 37750, 29607, 19695, 11462, 20642,\n",
            "           674, 11988, 27241, 21896, 30608, 35715, 11462, 30608, 32621, 36333,\n",
            "         23214, 19695, 21291, 19254,   674, 21896, 31876, 27241, 20622, 21291,\n",
            "         37750, 35625, 22492, 27241, 21896, 11990,  3737, 27241,  1637,  6435,\n",
            "          9422, 37733, 21291, 18541, 19506, 21291, 30340,   674, 21896, 23574,\n",
            "         27241,  5314, 24873, 36333,  6147, 27241,   683, 37819, 35715]])\n",
            "tensor([[ 2,  7, 16, 15,  2,  7,  8, 15,  2, 11,  6,  4,  8, 15,  4,  2,  7, 15,\n",
            "          2,  7, 15,  2,  7,  6,  4,  2,  7,  3,  7,  7,  4,  2,  7, 15,  2,  7,\n",
            "         15,  2,  7, 15, 11, 15,  2,  7,  1, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18],\n",
            "        [15,  2,  7, 15,  7, 15, 11, 15,  2,  7,  6,  4, 15,  4,  2, 11,  1, 11,\n",
            "         11,  4,  3, 15, 16,  4,  6,  9,  4, 15,  2,  7,  8,  0, 15,  6,  6, 17,\n",
            "          4,  7,  0,  3, 16, 15,  2,  4,  3,  4,  2,  7,  9,  8,  4,  8, 15,  6,\n",
            "          1, 18, 18, 18, 18],\n",
            "        [ 4,  3,  4,  2,  7,  8,  0,  3,  4, 15,  4,  2,  7,  6, 17,  6,  9,  1,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18],\n",
            "        [ 2,  7, 15,  7,  8,  9,  2,  7, 15,  2,  7,  0,  2,  7,  8,  1,  4, 17,\n",
            "          7,  1,  2,  7, 15, 11,  0,  2,  7, 15,  7, 15,  2, 11, 15, 11,  1,  6,\n",
            "          4, 15,  4,  2,  1,  7,  8,  1, 15,  2,  7,  0,  2,  1,  7, 15,  2,  7,\n",
            "          1, 15,  2,  7,  1],\n",
            "        [15,  2,  7, 16, 15,  2,  7,  1,  2, 11, 15, 11, 15,  2, 11,  1,  2, 11,\n",
            "         11, 15, 11,  1,  1,  8, 15,  2, 11, 15, 11,  1,  2,  7,  8, 15,  2, 11,\n",
            "         11, 15, 11,  1, 11,  1,  1, 11, 11,  1,  4, 15,  2,  7, 15,  2,  7, 15,\n",
            "          7, 15,  7,  8,  1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz7A9AuXa4jr",
        "outputId": "3ee09580-16a4-476c-a9bf-9595208b34b5"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_spanish_train, y_spanish_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[29406, 33682, 12722, 27241, 37750, 25729, 36943, 27241, 24037, 26061,\n",
              "          13709, 25513, 24841, 27241, 36797, 36126,  7365, 27241, 24037,  1240,\n",
              "          18607, 23860, 24651, 36523,  8410, 21896, 30770, 31727, 37699,  6137,\n",
              "          37551, 37750, 27044, 13087, 21896, 31412, 27241,  5314, 23682, 27241,\n",
              "          19605, 13087, 36621,  3412, 35715, 38437, 38437, 38437, 38437, 38437,\n",
              "          38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437],\n",
              "         [ 6785, 21896, 15013, 27241, 16563, 18607, 19605, 27241, 36621,  3412,\n",
              "          36523, 31337, 27241, 34090, 21896,  6186, 21291, 34002, 12178,  3644,\n",
              "          36523, 17579, 21422, 26229, 21896,  9581,   279, 13087,  5314,  3412,\n",
              "          31680, 27479, 13087, 36621, 36523, 18717, 21007, 35036, 27479, 36523,\n",
              "          37850, 13087, 37750, 22245, 36523, 18589,  1850, 27406,  5935,  7893,\n",
              "          27090, 24319, 13087,  9507, 35715, 38437, 38437, 38437, 38437],\n",
              "         [ 1082, 36523, 37695, 37750, 22971,  5455, 27479, 36523,  9618, 27241,\n",
              "          10222, 37750, 28300,  5663, 26071, 16775, 28795, 35715, 38437, 38437,\n",
              "          38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
              "          38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
              "          38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437,\n",
              "          38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437, 38437],\n",
              "         [11462, 36549, 36333, 30608, 32621,  5935, 37750, 28145, 17579, 37750,\n",
              "          31899, 27479, 21896, 20642, 37212, 21291,  6740, 16514,  5684, 21291,\n",
              "          37750, 16335, 27241, 23214, 27479, 37750, 30541, 27241, 30608, 27241,\n",
              "          21896, 31876, 27241, 20622, 21291,  3665, 14353,   674, 37097, 21896,\n",
              "          19695, 37458, 23344, 19695, 27241,  5314, 36218, 27479, 21896, 19695,\n",
              "          37458, 27241, 21896,   683, 19695, 27241,  5314,  5684, 35715],\n",
              "         [21563, 21896, 28192, 12722, 27241, 37750, 29607, 19695, 11462, 20642,\n",
              "            674, 11988, 27241, 21896, 30608, 35715, 11462, 30608, 32621, 36333,\n",
              "          23214, 19695, 21291, 19254,   674, 21896, 31876, 27241, 20622, 21291,\n",
              "          37750, 35625, 22492, 27241, 21896, 11990,  3737, 27241,  1637,  6435,\n",
              "           9422, 37733, 21291, 18541, 19506, 21291, 30340,   674, 21896, 23574,\n",
              "          27241,  5314, 24873, 36333,  6147, 27241,   683, 37819, 35715]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 2,  7, 16, 15,  2,  7,  8, 15,  2, 11,  6,  4,  8, 15,  4,  2,  7, 15,\n",
              "           2,  7, 15,  2,  7,  6,  4,  2,  7,  3,  7,  7,  4,  2,  7, 15,  2,  7,\n",
              "          15,  2,  7, 15, 11, 15,  2,  7,  1, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18],\n",
              "         [15,  2,  7, 15,  7, 15, 11, 15,  2,  7,  6,  4, 15,  4,  2, 11,  1, 11,\n",
              "          11,  4,  3, 15, 16,  4,  6,  9,  4, 15,  2,  7,  8,  0, 15,  6,  6, 17,\n",
              "           4,  7,  0,  3, 16, 15,  2,  4,  3,  4,  2,  7,  9,  8,  4,  8, 15,  6,\n",
              "           1, 18, 18, 18, 18],\n",
              "         [ 4,  3,  4,  2,  7,  8,  0,  3,  4, 15,  4,  2,  7,  6, 17,  6,  9,  1,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18],\n",
              "         [ 2,  7, 15,  7,  8,  9,  2,  7, 15,  2,  7,  0,  2,  7,  8,  1,  4, 17,\n",
              "           7,  1,  2,  7, 15, 11,  0,  2,  7, 15,  7, 15,  2, 11, 15, 11,  1,  6,\n",
              "           4, 15,  4,  2,  1,  7,  8,  1, 15,  2,  7,  0,  2,  1,  7, 15,  2,  7,\n",
              "           1, 15,  2,  7,  1],\n",
              "         [15,  2,  7, 16, 15,  2,  7,  1,  2, 11, 15, 11, 15,  2, 11,  1,  2, 11,\n",
              "          11, 15, 11,  1,  1,  8, 15,  2, 11, 15, 11,  1,  2,  7,  8, 15,  2, 11,\n",
              "          11, 15, 11,  1, 11,  1,  1, 11, 11,  1,  4, 15,  2,  7, 15,  2,  7, 15,\n",
              "           7, 15,  7,  8,  1]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemDHypikdRY"
      },
      "source": [
        "# Model-- Results for Spanish Training and Test Sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkz-im4Wr1tR",
        "outputId": "86cf7186-75c9-4da2-826d-cc41b71696c8"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 16 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_spanish_train, y_spanish_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_spanish_train,y_spanish_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=100,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_spanish_train,y_spanish_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 3/892 [00:00<00:31, 28.29batch/s, accuracy=38.4, loss=2.1]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(38438, 32)\n",
            "  (lstm): LSTM(32, 100, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=19, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 892/892 [00:30<00:00, 28.80batch/s, accuracy=90.7, loss=0.259]\n",
            "Epoch 1: 100%|██████████| 892/892 [00:30<00:00, 28.82batch/s, accuracy=97.7, loss=0.0568]\n",
            "Epoch 2: 100%|██████████| 892/892 [00:30<00:00, 28.78batch/s, accuracy=100, loss=0.0163]\n",
            "Epoch 3: 100%|██████████| 892/892 [00:30<00:00, 28.84batch/s, accuracy=99.1, loss=0.0251]\n",
            "Epoch 4: 100%|██████████| 892/892 [00:31<00:00, 28.75batch/s, accuracy=99.5, loss=0.0167]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmDu9v3bk_E4"
      },
      "source": [
        "# Stored Loss over Epochs Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "XK9n1yj7f5PS",
        "outputId": "d2094763-ab56-4fc1-aa03-94b802086102"
      },
      "source": [
        "batch_size = 100\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = plt.subplot()\n",
        "ax.set_title(\"Plot for the (hopefully) decreasing loss over epochs\")\n",
        "ax.plot(model.training_loss, 'b-')\n",
        "ax.set_ylabel(\"Training Loss\", color='b')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "# ax.set_yscale('log')\n",
        "ax.tick_params(axis='y', labelcolor='b')\n",
        "ax = ax.twinx()\n",
        "ax.plot(model.training_accuracy, 'r-')\n",
        "ax.set_ylabel(\"Accuracy [%]\", color='r')\n",
        "ax.tick_params(axis='y', labelcolor='r')\n",
        "a = list(ax.axis())\n",
        "a[2] = 0\n",
        "a[3] = 100\n",
        "ax.axis(a)\n",
        "t = np.arange(0, len(model.training_accuracy), len(X_spanish_train)//batch_size+1)\n",
        "ax.set_xticks(ticks=t)\n",
        "ax.set_xticklabels(labels=np.arange(len(t)))\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkYl-qNglH5n"
      },
      "source": [
        "# Test Data Accuracy for Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVWv_jfx-50M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a60f18-3b4e-4df9-b995-9dce42b384e9"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size =  100 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_spanish_test, y_spanish_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 95.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVWn8ibvm5UQ"
      },
      "source": [
        "# Number of Sentences and Sentence Length Visualization Ancient Greek \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1ErOUHrnnBgT",
        "outputId": "649fcf8d-582b-409b-a5f2-8030f7ed45e6"
      },
      "source": [
        "l = np.asarray([len(x) for x in X_agreek_train], dtype=np.int)\n",
        "plt.figure(figsize=(8, 4))\n",
        "x = np.unique(l)\n",
        "plt.bar(x, [np.sum(l==e) for e in x], width=1)\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"# sentences\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAEGCAYAAACNRVcrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZUklEQVR4nO3de7BlZXnn8e9vaEXBkYt0CDaMBxG10IpCOoKgFgGjXBybJEZJORENEzJeiLeo7aUkk8sUOikJOjMoggIOhShhBGkHxFZ0Jg5gN3JHpIMo3QFplItK5KLP/LHelm3Tp3t3n7PPPnv191N1aq/1rrXXet5a3fvZ613vft9UFZIkqZ/+zbgDkCRJo2OilySpx0z0kiT1mIlekqQeM9FLktRjC8YdwCjssssuNTU1Ne4wJEmaMytXrry7qhauX97LRD81NcWKFSvGHYYkSXMmyfc3VG7TvSRJPWailySpx0z0kiT1mIlekqQeM9FLktRjI0v0ST6V5K4k1w+U7Zzk0iS3tNedWnmSfDTJqiTXJtlv4D3HtP1vSXLMqOKVJKmPRnlHfwZw2HplS4HlVbU3sLytAxwO7N3+jgNOge6LAXACsD/wAuCEdV8OJEnSpo0s0VfVN4Afr1e8BDizLZ8JHDVQflZ1Lgd2TLIb8HLg0qr6cVXdA1zKY788SJKkacz1M/pdq+qOtnwnsGtbXgTcPrDf6lY2XfljJDkuyYokK9auXTu7UUuSNKHG1hmvqgqoWTzeqVW1uKoWL1z4mBEAx2Jq6TKmli4bdxiSpK3YXCf6H7YmedrrXa18DbDHwH67t7LpyiVJ0hDmOtFfCKzrOX8McMFA+eta7/sDgPtaE/8lwMuS7NQ64b2slUmSpCGMbFKbJOcABwO7JFlN13v+ROBzSY4Fvg+8uu3+JeAIYBXwAPAGgKr6cZK/Ab7V9vvrqlq/g58kSZrGyBJ9Vf3xNJsO3cC+Bbx5muN8CvjULIYmSdJWw5HxJEnqMRO9JEk9ZqKXJKnHTPSSJPWYiV6SpB4bWa/7rZUj4UmS5hPv6CVJ6jETvSRJPWailySpx0z0kiT1mIlekqQeM9FLktRjJnpJknrMRC9JUo+Z6CVJ6jETvSRJPWailySpx0z0kiT1mIlekqQeM9FLktRjJnpJknrMRC9JUo+Z6CVJ6jETvSRJPWailySpxxaMO4CtwdTSZb9avu3EI8cYiSRpa+MdvSRJPWailySpx0z0kiT1mIlekqQeM9FLktRjJnpJknpsLIk+yduT3JDk+iTnJHlCkj2TXJFkVZJzkzy+7bttW1/Vtk+NI2ZJkibRnCf6JIuAvwAWV9VzgW2Ao4EPASdV1TOAe4Bj21uOBe5p5Se1/SRJ0hDG1XS/AHhikgXAdsAdwCHAeW37mcBRbXlJW6dtPzRJ5jBWSZIm1pwn+qpaA/w98AO6BH8fsBK4t6oeabutBha15UXA7e29j7T9n7L+cZMcl2RFkhVr164dbSUkSZoQ42i634nuLn1P4KnA9sBhMz1uVZ1aVYuravHChQtnejhJknphHE33LwW+V1Vrq+ph4HzgIGDH1pQPsDuwpi2vAfYAaNt3AH40tyFLkjSZxpHofwAckGS79qz9UOBG4GvAq9o+xwAXtOUL2zpt+1erquYwXkmSJtY4ntFfQdep7irguhbDqcB7gHckWUX3DP709pbTgae08ncAS+c6ZkmSJtVYpqmtqhOAE9YrvhV4wQb2/TnwR3MRlyRJfePIeJIk9ZiJXpKkHjPRS5LUYyZ6SZJ6zEQvSVKPmeglSeoxE70kST1mopckqcdM9JIk9ZiJXpKkHjPRS5LUYyZ6SZJ6zEQvSVKPmeglSeoxE70kST1mopckqcdM9JIk9ZiJXpKkHjPRS5LUYyZ6SZJ6zEQvSVKPLRh3AH0wtXTZuEOQJGmDvKOXJKnHNpnok3w4yZOTPC7J8iRrk/yHuQhOkiTNzDB39C+rqvuBVwC3Ac8A3jXKoCRJ0uwYJtGve45/JPD5qrpvhPH03tTSZT7TlyTNmWE6412U5DvAvwJvTLIQ+Plow5IkSbNhk3f0VbUUOBBYXFUPAw8AS0YdmCRJmrlhOuNtB7wJOKUVPRVYPMqgJEnS7BjmGf2ngYfo7uoB1gB/O7KIJEnSrBkm0e9VVR8GHgaoqgeAjDQqSZI0K4ZJ9A8leSJQAEn2Ah4caVSSJGlWDNPr/gTgYmCPJGcDBwGvH2VQkiRpdgzT6/5S4A/okvs5dL3vL5vJSZPsmOS8JN9JclOSFybZOcmlSW5przu1fZPko0lWJbk2yX4zObckSVuTYXrd/z7wSFUtq6qLgEeSHDXD854MXFxVzwaeB9wELAWWV9XewPK2DnA4sHf7O45He/9LkqRNGOYZ/QmDo+FV1b10zflbJMkOwEuA09vxHmrHXAKc2XY7E1j3ZWIJcFZ1Lgd2TLLblp5fkqStyTCJfkP7zGR62z2BtcCnk3w7yWlJtgd2rao72j53Aru25UXA7QPvX93Kfk2S45KsSLJi7dq1MwhPkqT+GCbRr0jykSR7tb+PACtncM4FwH7AKVW1L/AzHm2mB6CqitbLf1hVdWpVLa6qxQsXLpxBeJIk9ccwif54ugFzzm1/DwJvnsE5VwOrq+qKtn4eXeL/4bom+fZ6V9u+Bthj4P27tzJJkrQJm2yCr6rH3HHPRFXdmeT2JM+qqpuBQ4Eb298xwInt9YL2lguBtyT5LLA/cN9AE78kSdqITSb6JM8E/hKYGty/qg6ZwXmPB85O8njgVuANdK0Ln0tyLPB94NVt3y8BRwCr6CbUecMMzitJ0lZlmE51nwc+DpwG/GI2TlpVV7PhiXEO3cC+xcweFUiStNUaJtE/UlX+dl2SpAk0TGe8LyZ5U5Ld2uh1OyfZeeSRSZKkGRvmjv6Y9vqugbICnj774Ww9ppYu+9XybSceOcZIJEl9Nkyv+z3nIhBJkjT7hhnrfrskH0hyalvfO8krRh+aJEmaqWGe0X+absCcA9v6GuBvRxaRJEmaNcMk+r2q6sPAwwBV9QCQkUYlSZJmxTCJ/qEkT6SNPZ9kL7phcCVJ0jw3TK/7vwIuBvZIcjZwEI5ON3L2ypckzYZhet1/OclK4AC6Jvu3VtXdI49MkiTN2DC97pdX1Y+qallVXVRVdydZPhfBSZKkmZn2jj7JE4DtgF2S7MSjHfCeDCyag9jUrGvGtwlfkrS5NtZ0/+fA24CnAit5NNHfD/y3EcelDfC5vSRpc02b6KvqZODkJMdX1cfmMCZJkjRLhumM97EkB/LY+ejPGmFcW6XBO3ZJkmbDJhN9ks8AewFX8+h89AWY6CVJmueG+R39YmCfqqpRByNJkmbXMIn+euA3gTtGHMtWyyZ7SdKoDJPodwFuTHIlA0PfVtUrRxaVJEmaFcMOgStJkibQML3uv57kacDeVfWVJNsB24w+NEmSNFPDDIH7Z8B5wCda0SLgC6MMSpIkzY5hpql9M92MdfcDVNUtwG+MMihJkjQ7hkn0D1bVQ+tWkiygzU0vSZLmt2ES/deTvA94YpLfAz4PfHG0YUmSpNkwTKJfCqwFrqOb6OZLwAdGGZQkSZodw/S6/yXwSeCTSXYGdneUvPFz6lpJ0jCG6XV/WZIntyS/ki7hnzT60CRJ0kwN03S/Q1XdD/wBcFZV7Q8cOtqwJEnSbBgm0S9IshvwauCiEccjSZJm0TCJ/q+BS4BVVfWtJE8HbhltWJIkaTYM0xnv83Q/qVu3fivwh6MMSpIkzY5h7uhHIsk2Sb6d5KK2vmeSK5KsSnJukse38m3b+qq2fWpcMUuSNGnGluiBtwI3Dax/CDipqp4B3AMc28qPBe5p5Se1/eaFqaXLnEtekjSvjSXRJ9kdOBI4ra0HOIRu8hyAM4Gj2vKStk7bfmjbX5IkbcIwv6P/wMDytrN03n8A3g38sq0/Bbi3qh5p66vpZsmjvd4O0Lbf1/aXJEmbMG2iT/KeJC8EXjVQ/P9mesIkrwDuqqqVMz3Wesc9LsmKJCvWrl07m4eWJGlibeyO/jvAHwFPT/J/knwSeEqSZ83wnAcBr0xyG/BZuib7k4Ed28x4ALsDa9ryGmAP+NXMeTsAP1r/oFV1alUtrqrFCxcunGGIkiT1w8YS/b3A+4BVwMF0yRhgaZJvbukJq+q9VbV7VU0BRwNfrarXAl/j0daDY4AL2vKFbZ22/auOtS9J0nA2luhfDiwD9gI+AuwP/Kyq3lBVB44glvcA70iyiu4Z/Omt/HS6loRVwDvoZtOTJElDmHbAnKp6H0CSa4DPAPsBC5P8X7qfu/37mZ68qi4DLmvLtwIv2MA+P6d7hCBJkjbTJkfGAy6pqhXAiiRvrKoXJdll1IFJkqSZ2+TP66rq3QOrr29ld48qIEmSNHs2a8CcqrpmVIFIkqTZN84hcCVJ0oiZ6CVJ6jETvSRJPWailySpx0z0kiT1mIlekqQeM9FLktRjw4yMp3lsaumyXy3fduKRY4xEkjQfmeh7xKQvSVqfTfeSJPWYiV6SpB4z0UuS1GMmekmSesxEL0lSj5noJUnqMRO9JEk9ZqKXJKnHTPSSJPWYiV6SpB4z0UuS1GMmekmSesxEL0lSjzl73WYanCFOkqT5zjt6SZJ6zEQvSVKPmeglSeoxn9H31Ib6Etx24pFjiESSNE7e0UuS1GMmekmSesxEL0lSj815ok+yR5KvJbkxyQ1J3trKd05yaZJb2utOrTxJPppkVZJrk+w31zFLkjSpxnFH/wjwzqraBzgAeHOSfYClwPKq2htY3tYBDgf2bn/HAafMfciSJE2mOU/0VXVHVV3Vln8C3AQsApYAZ7bdzgSOastLgLOqczmwY5Ld5jjsXphausyR/SRpKzPWZ/RJpoB9gSuAXavqjrbpTmDXtrwIuH3gbatb2frHOi7JiiQr1q5dO7KYJUmaJGNL9EmeBPwj8Laqun9wW1UVUJtzvKo6taoWV9XihQsXzmKk/eZdviT121gSfZLH0SX5s6vq/Fb8w3VN8u31rla+Bthj4O27tzJJkrQJ4+h1H+B04Kaq+sjApguBY9ryMcAFA+Wva73vDwDuG2jilyRJGzGOIXAPAv4EuC7J1a3sfcCJwOeSHAt8H3h12/Yl4AhgFfAA8Ia5DVeSpMmV7nF4vyxevLhWrFgxkmNvDc+zHRNfkiZPkpVVtXj9ckfGkySpx0z0kiT1mIlekqQeM9FLktRjJnpJknrMRC9JUo+N43f0E2lr+FmdJKl/vKOXJKnHTPSSJPWYiV6SpB4z0UuS1GN2xtNjDHY8dNx7SZpsJnpt1IZ+bWDyl6TJYdO9JEk9ZqKXJKnHTPSSJPWYiV6bbWrpMkcKlKQJYaKXJKnHTPSSJPWYiV6SpB4z0WvW+QxfkuYPE70kST3myHjaYg6VK0nzn4les8Kmekman0z0Ghnv+CVp/HxGrzlhBz1JGg8TvSRJPWailySpx3xGrznlc3tJmlsmeo2NSV+SRs+me80LdtaTpNHwjl7zyrDJ3hYASRqOd/SSJPXYxNzRJzkMOBnYBjitqk4cc0iaJzbUCuAdvyR1JiLRJ9kG+O/A7wGrgW8lubCqbhxvZBqXTTXxbyr5b+r9flGQ1BcTkeiBFwCrqupWgCSfBZYAJnoNbXM6+21s3019YdjQ9unes7EvFP4qQdJsSFWNO4ZNSvIq4LCq+o9t/U+A/avqLQP7HAcc11afBdy8BafaBbh7huHOJ9Zn/upTXcD6zGd9qgtYn415WlUtXL9wUu7oN6mqTgVOnckxkqyoqsWzFNLYWZ/5q091Aeszn/WpLmB9tsSk9LpfA+wxsL57K5MkSRsxKYn+W8DeSfZM8njgaODCMcckSdK8NxFN91X1SJK3AJfQ/bzuU1V1wwhONaOm/3nI+sxffaoLWJ/5rE91Aeuz2SaiM54kSdoyk9J0L0mStoCJXpKkHjPRN0kOS3JzklVJlo47ns2RZI8kX0tyY5Ibkry1le+c5NIkt7TXncYd6+ZIsk2Sbye5qK3vmeSKdo3ObR0zJ0KSHZOcl+Q7SW5K8sJJvT5J3t7+nV2f5JwkT5ika5PkU0nuSnL9QNkGr0U6H231ujbJfuOLfMOmqc9/bf/Wrk3yv5LsOLDtva0+Nyd5+Xiint6G6jOw7Z1JKskubX1eX5/p6pLk+HZ9bkjy4YHykVwbEz2/NsTu4cA+wB8n2We8UW2WR4B3VtU+wAHAm1v8S4HlVbU3sLytT5K3AjcNrH8IOKmqngHcAxw7lqi2zMnAxVX1bOB5dPWauOuTZBHwF8DiqnouXefYo5msa3MGcNh6ZdNdi8OBvdvfccApcxTj5jiDx9bnUuC5VfVbwHeB9wK0z4Wjgee09/yP9vk3n5zBY+tDkj2AlwE/GCie79fnDNarS5LfpRvZ9XlV9Rzg71v5yK6Nib7zqyF2q+ohYN0QuxOhqu6oqqva8k/oksgiujqc2XY7EzhqPBFuviS7A0cCp7X1AIcA57VdJqY+SXYAXgKcDlBVD1XVvUzu9VkAPDHJAmA74A4m6NpU1TeAH69XPN21WAKcVZ3LgR2T7DY3kQ5nQ/Wpqi9X1SNt9XK6sUegq89nq+rBqvoesIru82/emOb6AJwEvBsY7EE+r6/PNHV5I3BiVT3Y9rmrlY/s2pjoO4uA2wfWV7eyiZNkCtgXuALYtaruaJvuBHYdU1hb4h/o/lP/sq0/Bbh34MNrkq7RnsBa4NPtUcRpSbZnAq9PVa2huwP5AV2Cvw9YyeRem3WmuxZ9+Gz4U+B/t+WJrE+SJcCaqrpmvU2TWJ9nAi9uj7q+nuR3WvnI6mKi75EkTwL+EXhbVd0/uK2631FOxG8pk7wCuKuqVo47llmyANgPOKWq9gV+xnrN9JNyfdqz6yV0X16eCmzPBppZJ9mkXIthJHk/3aO9s8cdy5ZKsh3wPuCD445lliwAdqZ7zPou4HOtxXJkTPSdiR9iN8nj6JL82VV1fiv+4bpmrPZ613Tvn2cOAl6Z5Da6xyiH0D3j3rE1F8NkXaPVwOqquqKtn0eX+Cfx+rwU+F5Vra2qh4Hz6a7XpF6bdaa7FhP72ZDk9cArgNfWowOmTGJ99qL7YnlN+0zYHbgqyW8ymfVZDZzfHjdcSddquQsjrIuJvjPRQ+y2b4OnAzdV1UcGNl0IHNOWjwEumOvYtkRVvbeqdq+qKbpr8dWqei3wNeBVbbdJqs+dwO1JntWKDqWbYnkSr88PgAOSbNf+3a2ry0RemwHTXYsLgde13t0HAPcNNPHPW0kOo3v09cqqemBg04XA0Um2TbInXSe2K8cR47Cq6rqq+o2qmmqfCauB/dr/q0m8Pl8AfhcgyTOBx9PNXje6a1NV/nVfdo+g6536z8D7xx3PZsb+IrqmxmuBq9vfEXTPtZcDtwBfAXYed6xbULeDgYva8tPbP/xVwOeBbccd32bU4/nAinaNvgDsNKnXB/jPwHeA64HPANtO0rUBzqHrX/AwXdI4drprAYTuFzn/DFxH92uDsddhiPqsonveu+7z4OMD+7+/1edm4PBxxz9MfdbbfhuwyyRcn2muzeOB/9n+/1wFHDLqa+MQuJIk9ZhN95Ik9ZiJXpKkHjPRS5LUYyZ6SZJ6zEQvSVKPmeilCZPk/W3Wq2uTXJ1k/y08zvOTHDHb8Q157qkNzU42C8c9OMmBA+tnJHnVxt4j9d2CTe8iab5I8kK60c72q6oH23SdWzol7POBxcCXZiu+eeBg4KfAN8cchzRveEcvTZbdgLvr0Zmv7q6qfwFI8tttkoyVSS4ZGNL1siQfSnJlku8meXEbAfKvgde0VoHXJNm+zZ99ZZt8Z0l7/+uTnJ/k4nTztQ/On31YkquSXJNkeSvb4HGmk2SbdPOnf6u1Uvx5Kz+4xX5eurm7z143JniSI1rZynTzkV/UJnT6T8DbW51e3E7xkiTfTHKrd/faGnlHL02WLwMfTPJduhHczq2qr7e5Dj4GLKmqtUleA/wd3cxlAAuq6gWtqf6Eqnppkg/SjST2FoAk/4VuuOE/TbIjcGWSr7T3P59uVsQHgZuTfAz4OfBJ4CVV9b0kO7d937+h41TVz6ap07F0Q5f+TpJtgX9K8uW2bV+6+bn/Bfgn4KAkK4BPDJz3HICqui3Jx4GfVtW6Ob6Ppfty9CLg2XTDjJ6HtBUx0UsTpKp+muS3gRfTjZd9bpKldMPrPhe4tN30bkM39OY66yY6WglMTXP4l9FNJvSXbf0JwL9ry8ur6j6AJDcCT6Mbxvcb1c2dTVX9eBPHuWkj5/2tgbvtHejG+X4IuLKqVrfzXt1i/ylw67rz0g0zetw0xwb4QlX9ErgxybyfCliabSZ6acJU1S+Ay4DLklxHNwnLSuCGqnrhNG97sL3+gun/3wf4w6q6+dcKu85+Dw4UbewY0x5nE/sfX1WXrHfegzfzvNMZPMZIpwOV5iOf0UsTJMmzkuw9UPR84Pt0k2AsbJ31SPK4JM/ZxOF+AvzbgfVLgOMHnoPvu4n3X073/HvPtv+6pvvNPc4lwBvb4weSPDPJ9hvZ/2bg6e2ZPMBrNlInaatnopcmy5OAM5PcmORaYB/gr6rqIbppYj+U5Bq6GcsO3MhxoJtadp91nfGAvwEeB1yb5Ia2Pq2qWkvXZH5+O+e5bdNmHQc4jW6q26vaT+4+wUbu3KvqX4E3ARcnWUmX3O9rm78I/P56nfGkrZqz10maOEme1PorrJum9JaqOmnccUnzkXf0kibRn7XOeTfQdd77xJjjkeYt7+glSeox7+glSeoxE70kST1mopckqcdM9JIk9ZiJXpKkHvv/JY9J2hngJ0sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyiksAgAlYPn"
      },
      "source": [
        "# Data Encoding and Padding for Ancient Greek "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZPQwDuLmM4w",
        "outputId": "24055c46-b705-4c7e-d7d5-81f79d435947"
      },
      "source": [
        "tokens = {token for sentence in X_agreek_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_agreek_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'ἐϊκυῖα', 'σκῆπτρα', 'ἔθειραι', 'εἶδόν', 'ἡγεμονίας', 'θεόντων', 'δνοφερῇσι', 'ἀδελφεὸν', 'τοιοῦτος', 'ταλάντων', 'δώδεκ̓', 'χαὐτοῦ', 'αἰνῇσιν', 'ἂψ']\n",
            "['CCONJ', 'PUNCT', 'DET', 'SCONJ', 'VERB', 'PRON', 'ADJ', 'NOUN', 'NUM', 'X', 'PART', 'INTJ', 'ADP', 'ADV', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlYWiLlemN5b",
        "outputId": "e1c55e1b-cb54-4673-84f5-3864912cf31f"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_agreek_train[:5], y_agreek_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[17294,  3868,  4078,  2338, 22472, 26629, 18608, 30856, 15281,  4771,\n",
            "         22200, 27585, 24373, 23793],\n",
            "        [ 6492, 12245, 17161, 11078, 19318, 25502, 32563,  4771, 23793, 33219,\n",
            "         33219, 33219, 33219, 33219],\n",
            "        [17644, 15281,  5128,  6607,  3643, 23883, 10895, 18484, 14915,  9646,\n",
            "         23793, 33219, 33219, 33219],\n",
            "        [ 3671,   875, 12245, 25551, 16906, 27585,   394, 15920, 30864, 33219,\n",
            "         33219, 33219, 33219, 33219],\n",
            "        [31239, 26879, 24323, 27717, 17644, 23293,  8102, 23793, 33219, 33219,\n",
            "         33219, 33219, 33219, 33219]])\n",
            "tensor([[ 4, 13,  6,  7,  4,  7,  1,  7,  0,  7,  4,  7,  4,  1],\n",
            "        [ 7, 13, 12,  6,  7,  4,  4,  7,  1, 14, 14, 14, 14, 14],\n",
            "        [ 2, 13,  4,  7,  7, 13,  7,  0,  7,  6,  1, 14, 14, 14],\n",
            "        [ 7,  7, 13, 12,  4,  7,  6,  4,  1, 14, 14, 14, 14, 14],\n",
            "        [12,  7,  6, 13,  2,  7,  4,  1, 14, 14, 14, 14, 14, 14]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecz7wSlKmOJl",
        "outputId": "94712bd6-8f4c-4d91-be34-a0be7bb3f57d"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_agreek_train, y_agreek_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[17294,  3868,  4078,  2338, 22472, 26629, 18608, 30856, 15281,  4771,\n",
              "          22200, 27585, 24373, 23793],\n",
              "         [ 6492, 12245, 17161, 11078, 19318, 25502, 32563,  4771, 23793, 33219,\n",
              "          33219, 33219, 33219, 33219],\n",
              "         [17644, 15281,  5128,  6607,  3643, 23883, 10895, 18484, 14915,  9646,\n",
              "          23793, 33219, 33219, 33219],\n",
              "         [ 3671,   875, 12245, 25551, 16906, 27585,   394, 15920, 30864, 33219,\n",
              "          33219, 33219, 33219, 33219],\n",
              "         [31239, 26879, 24323, 27717, 17644, 23293,  8102, 23793, 33219, 33219,\n",
              "          33219, 33219, 33219, 33219]], device='cuda:0'),\n",
              " tensor([[ 4, 13,  6,  7,  4,  7,  1,  7,  0,  7,  4,  7,  4,  1],\n",
              "         [ 7, 13, 12,  6,  7,  4,  4,  7,  1, 14, 14, 14, 14, 14],\n",
              "         [ 2, 13,  4,  7,  7, 13,  7,  0,  7,  6,  1, 14, 14, 14],\n",
              "         [ 7,  7, 13, 12,  4,  7,  6,  4,  1, 14, 14, 14, 14, 14],\n",
              "         [12,  7,  6, 13,  2,  7,  4,  1, 14, 14, 14, 14, 14, 14]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_3hiu1nlga6"
      },
      "source": [
        "# Model Results for Ancient Greek Training and Test Sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f_WRpMcnvBS",
        "outputId": "fb5e8637-83b1-4c0a-8f27-a1389603dc22"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 16 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_agreek_train, y_agreek_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_agreek_train,y_agreek_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=100,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_agreek_train,y_agreek_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 1/714 [00:00<01:33,  7.64batch/s, accuracy=34.1, loss=2.38]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(33220, 32)\n",
            "  (lstm): LSTM(32, 100, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=15, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 714/714 [00:16<00:00, 44.30batch/s, accuracy=68.2, loss=0.829]\n",
            "Epoch 1: 100%|██████████| 714/714 [00:15<00:00, 44.64batch/s, accuracy=90.9, loss=0.29]\n",
            "Epoch 2: 100%|██████████| 714/714 [00:16<00:00, 44.57batch/s, accuracy=97.7, loss=0.103]\n",
            "Epoch 3: 100%|██████████| 714/714 [00:16<00:00, 44.59batch/s, accuracy=95.5, loss=0.0678]\n",
            "Epoch 4: 100%|██████████| 714/714 [00:16<00:00, 44.56batch/s, accuracy=97.7, loss=0.0604]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYhHgNfClrI1"
      },
      "source": [
        "# Stored Loss Over Epochs Ancient Greek "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "eC1iRbeZoM1b",
        "outputId": "47c41563-1b1e-48d3-e86c-abda75712ac6"
      },
      "source": [
        "batch_size = 64\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = plt.subplot()\n",
        "ax.set_title(\"Plot for the (hopefully) decreasing loss over epochs\")\n",
        "ax.plot(model.training_loss, 'b-')\n",
        "ax.set_ylabel(\"Training Loss\", color='b')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "# ax.set_yscale('log')\n",
        "ax.tick_params(axis='y', labelcolor='b')\n",
        "ax = ax.twinx()\n",
        "ax.plot(model.training_accuracy, 'r-')\n",
        "ax.set_ylabel(\"Accuracy [%]\", color='r')\n",
        "ax.tick_params(axis='y', labelcolor='r')\n",
        "a = list(ax.axis())\n",
        "a[2] = 0\n",
        "a[3] = 100\n",
        "ax.axis(a)\n",
        "t = np.arange(0, len(model.training_accuracy), len(X_agreek_train)//batch_size+1)\n",
        "ax.set_xticks(ticks=t)\n",
        "ax.set_xticklabels(labels=np.arange(len(t)))\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd7wU1fXAv+c1OggWRFBAJfaOiga7RsRC1MRg1GA0Yu8VNSq2ny1EjRUjdhEVe0OCvQACAtJUQHpRpDw6r5zfH3fWnd23ZXbflrfs+X4+85mZO+fee2buzJy5Zc4VVcUwDMMwGhol+VbAMAzDMGJhBsowDMNokJiBMgzDMBokZqAMwzCMBokZKMMwDKNBYgbKMAzDaJAUvYESkU9E5B8ZSktE5CkRWSYiozORZow8zhSRLzKY3s4iMkZExNufJSJHZir9FPT4vYj8KCKrROSPSWQ7iYiKSJm3H6gMRWR3EfkqRb1uEZHnU4mTL0TkIBH5PktpZ+w5McJE38tGJEVhoLyX7lrv5bdYRJ4WkeYpphHkRuoOHAV0UNX96qV08Dzry23AfZr/H+JuBR5S1eaq+kY2MlDVicByETk+G+nnG1X9XFV3yLcehpEpisJAeRyvqs2BvYGuwI1ZyKMjMEtVV6caMR9fUCLSDjgMyIpBSJGOwOQc5PMCcG4O8omLfS3nH6+1o5jefwVJ0RWQqs4H3gd2jT4mIiUicqOIzBaRn0XkWRFp5R3+zFsv92piB0TFPRv4L3CAd7y/F36OiEwXkaUi8paIbOWLoyJyoYj8CPwYQ924eYrIfV5T4k8icowvvJWIPCkiC0VkvojcLiKlcS7HUcA4VV0XFb6niEwUkRUiMkREGvvST3Y+l4jITBFZIiL3+l8CInKWiEz19B4mIh298BnAtsDb3nk2im5qDNLUJiIVnl67+cK2EJE1IrK5F/QJcISINIqTRmcR+VREVorIcGCzqOPdROQrEVkuIhNE5FDfsTbimngXeOf4hhd+qIjME5FrRWQR8JR3r10nIjNE5FcReVlE2vjSekVEFnll8JmI7OI71lNEpng6zheRq/z5+ORmichVCcryGu8+WSAi//DKb/tE19iLF/c5EZHGIvK8d07LReQbEWnrHTvTuzdWevftaXHSbyQi93t6LfC2G3nHporIcT7ZMhH5RUT2DlA+n4jIHSLyJbAGd89F572ViAz10vxJRC7xHbtFRF71ruNKERknInv4ju/k5bFcRCaLyAm+Y01E5F/eNVshIl+ISBNf1qeJyBxxz80Nvnj7iWuCrxTX+jMgWflsVKjqRr8As4Ajve2tcV/qt3n7nwD/8LbPAqbjbtzmwGvAc96xToACZQnyORP4wrd/OLAEV2trBPwH+Mx3XIHhQBugSYz06uTp5VEFnAOUAucDCwDxjr8OPA40A7YARgPnxtH3XuDhGNdqNLCVp9dU4LwUzudjL942wA++a9vLu7Y7AWW4GuxXscoozv4twPOxrktUGT4C3O2LdynwdtQ5VgK7x7kmXwMDvPM7GFjpy7c98CvQE/dxd5S3v7l3/F1gCNAaKAcO8cIPBaqBu710m3h6jQQ6eGGPA4N9epwFtPCO3Q+M9x1bCBzkbbcG9vblMy9gWfYAFgG7AE2B571run2c6+K/xomek3OBt700S4F9gJa4+7ES2MGTawfsEievW71rswWwOfAV4ef1JuAFn+yxwNSA5fMJMMc75zKgPCrfEmCsl0eFd34zgaN992AV8CevfK8CfvK2y71rcr0X93DcvRM634e9/Nt71+VAr2w7edf9Ce++2ANYD+zkux/P8LabA93y/T7N5ZJ3BXJyku5BXQUsB2bjXmJNfDdt6MEbAVzgi7eDd0OWkZ6BehK4x7ff3Euvk7evwOEJ0quTp5fHdN9+U09mS6Ctd3M38R0/Ffg4TvpPAHfFuFan+/bvAR5L4Xx6+I5fAIzwtt8HzvYdK8F9xXb05ZsJA7U/7iUUMthjgFOiznE+cHCM67ENzpA084W96Mv3WrwXse/4MKAP7oVbC7SOke6hwAagsS9sKnCEb79d6F6LEX8T73xbeftzcIagZYx8og1UvLIcBPyf79j2BDdQiZ6Ts3AGZfeo+M1wz9/JxPgYi5KdAfT07R+NazoP6bkSaOrtvwDclKx8fOdwa4J89wfmRIX1A57y3YMjo+7hhcBB3rIIKPEdH+zFKQHWAnskeMY7+MJGA7297c+A/sBmia7ZxroUUxPfH1V1E1XtqKoXqOraGDJb4QxYiNm4h65tmnlGpKeqq3BfdO19MnPTSHeRL8013mZzXD9OObDQa2ZYjvsy3yJOOstwX+lx08cZkdCAklTPZ7YXB0+3B3x6LQUkKm69UdVRns6HisiOuBfaW1FiLXAvy2i2ApZpZB+i/37oCPw5dA7eeXTHGZetgaWquiyOar9oZFNqR+B1XzpTgRqgrYiUishdXvNfJc7QQLi58WRcLWG2uObIiObmKBKVpb+sUrkPEz0nz+GMwkte89w9IlLuXdO/AOfh7s93vfIJmv5WAKo6HXetjheRpsAJuI8ISFw+Qc6zI7BVVPzriXz+f4uvqrXAPE+3rYC5Xphf7/a4cmuMM7zxiFdOZwO/A6Z5zaXH1Ym5EWOdtZEswN2kIUJf1ItJ70UakZ6INAM2xX3Bh9AE8RMdi8VcXA1qM1WtDiA/Eff1H5Qg5xNqQgV3/Rb4dLtDVV8ImNdqXO0wxJYp6PkMcDruoX/VbxhEpD2uCSbWcOyFQGsRaeYzUtsQLoe5uC/0c6Ijihtw0kZENlHVWMYvuiznAmep6pcx0joD1yR6JM44tcJ9TAiAqn4D9BKRcuAi4GXcdU+FhbjmxRCpxI/7nHj3XX+gv4h0At7DXesnVXUYMMzre7kdV4M/KEH6se4jcDWTU3E1kyme0YIE5eMj0TM1F/hJVbskkPntOonrX+3g021rESnxGalQM/cSYB2wHTAhQdp1lVX9ETjVy+sk4FUR2VTTGIhViBRTDSoIg4HLxXWUNwfuBIZ4D90vuCacOh2rSdL7u4js6XXy3gmMUtVZAeOnlKeqLgQ+BP4lIi29zuztROSQOFGGA3uLr+M8CUHO52oRaS0iW+P6WYZ44Y8B/cTr7Bc3mOPPCfIaD/QWkXIR6Ypr9w/K88CJOCP1bNSxQ4CPVHV9dCRVnY1rEuwvbsBFd8A/JP153Jf70V4tp7G4gQkdvGv/PvCId/7lInJwAh0fA+6Q8ECRzUWkl3esBe5D41eckb4zFMnT6zQRaaWqVbh+nVpS52VcWe7k1UT+mULcuM+JiBwmIruJG5hTiWv6qxWRtiLSy/uoWY9rco+n92DgRu+abIbrE/IPkHkJ+AOu//VFX3jc8gl4XqOBleIGszTx0thVRPb1yewjIieJG4l5mXcuI4FQzf0ar+wPxd07L3kGaxAwQNwgjFIROUDiDNTxIyKni8jmXhqhD590yrsgMQMVySBcE8VnuM7PdcDF8FtT2h3Al171v1uyxFT1f7gHfyjui3U7oHdQZdLJE/gbroYwBffV/SqRTRz+9BcDH+G+1oPoE+R83sR1NI/HDRp40ov7Om6QwEtes9Uk4Bji808v/WW4L/IXE8hG6zkXGIf7Wv486vBpOOMQj7/i+iKWAjfjM3Beur1wzT6/4L64ryb8HJ2BeyFPA37GvcDi8QCu6fFDEVmJe8nt7x17Ftc8NB9XjiOj4p4BzPKu43neOaWEqr4PPIgb1DLdl0cdwx2DuM8Jrqb7Ks44TQU+9WRLgCtwtY2luA+F8+OkfzvuQ2Ei8B2uLG/36b4QN3jgQMIfQEHKJyGqWgMcB+zpndcS3MjcVj6xN3FNlctw5XCSqlap6gacQTrGi/cI8DdVnebFu8o7l2+88787oF49gMkisgp3z/SO0z2xURLqSDaKFBHZGdcktp/W82YQEQW6+Jpc8oaIDAIWqOqNvrDdgcdVNVGfTVEiIjvhPhoaBWweLjpE5BbcIJLT861LsWB9UEWOqk4B9k0qWEB4fR8nAXv5w9V5kjDj5CEiJ+L6iJrivujfNuNkNCSsic/YqBCR23A1gXtV9ad869PAORfXFDkDN4IwXpObsbEjMgiRnxGZ5Atrg8hwRH701q29cEHkQUSmIzIR7yfprKhlTXyGYRhFjhvQswp4FtVdvbB7gKWo3oXIdUBrVK9FpCeuz7Enrt/0AVT3j5NyvbAalGEYRrGj+hlu8IafXrj+abz1H33hz3p/044ENsH9ZpFxCq4PqqSkRJs0aZJc0Mg5paqUqbK+JPK7R1TZpKaGZWX1u906r13L+pISFjRyo3NLVOmwfj2LKirYEJVnqSo1bgaRCMpUqY4RHqJxbS1NamupLC2lZXU1y8rLfzvWpqqKZWVltKipoVyVpWVldFy/nhIvrzmNGtG2qooW1dW/PVjTmjRBvfwa1dZSokqtCK2rq2lSW8vcRo2oAdpUV1OhyuqSElrU1NCypoZawl+QS8vKaOlLd1FFBVtu2ADA4vJyylXZIPKbvjutCf2/HUaBn8vLqRKhaW0tZaq0rKkB4KfGjSmvraWDl2Y0G0SoiGptqQVWl5bSwksjHitLS1lQUcEWVVW0rq5/F1eVCIsqKmhTVUUp7vw7rF9PqXceW69bhwC/+K7RnEaNKFNlqzjnB+5HrmR3qL9MErHCuy6ZrAH82KRJwns3EWvWrFHcaMgQA1V1YJJobXEjJsH9Uxj6Ybk9kT88z/PCFpJp8u3KItWladOmajRQ2rVT5z0rio4dXXj//qrvvadaU6P6zTex0/juO9UOHVR//rnuMYhM/7jj3P6++6q++abqsce6dUjulVfCsmPGqLZp48Kfey4cXlvrwg47LByv0Jcvv8y/DrZkfnn66bQeS/fosFo1yfsVOilM8u0vjzq+zFu/o9DdFz5CoWvS9NNYMp5gthczUDli/XrVdevC26B68MGqDz2k+sMPqr/+6gzN6NF1H6S+fd36wQdVZ8yoe/yee9z6zTfr5rvbbu7YGWeorlqlescd9XuoVVWnT48Mu+gi1QED6v/CsMWWXC6vvpr245ymgfpeoZ233U7he2/7cYVTY8pleCm4QRLNmjXT1auLwstHfmnfHhYsSC5XX268Eb79Fh5/HHbfHZZGN4PXk3XroHFQRxmG0YD54AM4+ui0oorIGlVtlkSoE/AO4UES9wK/Eh4k0QbVaxA5FudiKzRI4kEyMEFrLGyQREPn559hfZyf+3/9FWp9Xk+mTYMXgrq6S0IujBPA7bfDu+9Chw6ZN05gxilVNvNNf/Xjj1BTA5WVyeONHp09nfLFTTfVDWvbFp56Cu64Azp2TC/ddO/Jww9PL14QRAbjvHPsgMg83Px2dwFH4earO9LbB/fv3EycB5IncLMWZIdsVMtcrUwbg44GnQA6GbR/DJlGoENAp4OOAu2ULN2ia+ID1WOOqRs+d6471r9/OKykxIUl45NPVB99NLxfW6v67bfh/S++yH9zRkNb/vEP1ZdeUp09212jiRNVb7optuyiRfnXN8jy9tvuXG69NXyP1da6e+q77yLvmR9+UF22zPUdhuIfeWSkTE1N4vzat3dNt/6wt95SPftst33sseHwK65Q7dLFpVtVldp5HXVU7PAmTVQPP1x19eqw/s8/rzppUriMly9X3X9/1WnTXN6rV6sef3w4jVCzt6rqhx+q7rGH6m23hY/vuqvq0KHh/XPOCW/ff7/q/Pku7nnnqV5/veoHH4SPRwNOl3jHU4AgTXwNcMlewqiANve2y3EGqFuUzAWg3vw02ht0SLJ0i9JAhW7Odu3cg6uq2r27C992W/fQrF0bKTtunHthqKq2besesug0R450+y+84PZfe809YPl+cTaUpbLSXZ+qquTlA24gxvr1dcPjLaeeWjfshx9UBw0K73/5peqcOa4vbsQIN3hk4sTw8dAgj3jLyy+rnnlm3fBtt63/PekfhOLn73+PrUuIH35Q7ddP9fLLw9f3f/9z5/Loo0526dLINK++2oWH+i9j5XHFFarjx6u++27k9dxuu8j8VV3/ZnV1eL+62uUfiyFDXPzhw+Nfkx9+cGUVYuhQV1bV1XXPP5rp011fbTQhfcrLVXfcMX78AJiBSpQJ2hR0HOj+UeHDQA/wtstAl4BKorQK0kB98IEzIKru6zoVYr2I/OGbblr3QX3iCbe+9FLXsRr9gES/NK6/Pn5axbTss4/qxRe77Y4dg5XPtdfWvb6qqv/+d+wBJKGRhEOHuoEm4L74Q/mGXkrJXmpr1oRfsNXVqueeG5nP+eeHa3t9+riwBx5QffJJt33mmcHOLxZLloTv51hcdpnL47rrnMFIdi5BWLXK1ew2bFBduDB2rcrPp5+GP9DWrXPx68O8eenHBdUttkg/flVVpDFNSwUzUHUTR0tBx4OuAr07xvFJoL6ZJHUGaJ2ZI4G+OO/GYyoqKtIpn/zx7bfuMp97ruobb7jtESNiy44dW/drPfTw+ZtWPv88vRdwdJqgeuedYQO1sS+hYfDxlmuvdS+Ct9+O/zUdix9/VJ05M/ax6DxCNdTx4yPlamrCtS9/vKCEahS33+5e4H6+/todmztX9cUX3fZFFwVPO1VCoy9DL9VMGKhY/OlPLt2//z3zaWeSl19W/emnvKpgBipRJugmoB+D7hoVHshA+Zd0a1DTprmPx/p+SAUm9OV4331ufcgh7osS3MMbzXffuWMXXBD+8vv++8y+oENkMs2ttnLNjU89Ff7fad99Xf/MDTdkNi9wzWjJZOIZ8Hjn3r696qhRiZvy0iX6S3+XXdw6uo8nmsWLnUEJyowZrhyWLUssV13t+kxCzZe5IFsG6tNPXboPPJD5tDcyzEAlywi9CfSqqLCcNfENHKi/fURmlepq17YeeijLysLbN97o1rfcUjfe66+H5a64QvWf/0z95Z0rA/X88+HtG24IpxsaNOA/v2XLnAFIJ5+DD47cP/xw17cGqi1auH6MVAxRdPjkyW5JpbaUDv37u+t0003OeIPq1KnZzbMhcdBBrhkzG4wfn/3y2wgoVAOVNVdHImwOVKmyXIQmwFE4l/5+3sJNOf41bsbUj1RTnuY8ECFPOJqV1D0OPxxWrIBxPo8iftcuzz4bqUyIOXPgxBPD+wMGZE/Hr75KL96AAfDllzB0KFRUuAu5bBm08s3lFjov/9D3TTaBefPg1lvh5ptTy3PTTSP3b701nEfnznDnnW4JuX/p3h3+FGfi3dB5f/ghPPdcuCxygX+48tlnwzPPwA475C7/fPPZZ9lLe489spe2kX+yZflAdwf9FnQirinvJi/8VtATvO3GoK/ghpmPBt02Wbrp1qBCfcOzZqUVPTa//OLcj9x8c/LRVLGWAw9U7dUrvdpFOktoNFKypXHjumGqqu+8k/gihobXDhlS99iddybOs7S0btgf/xjefucdl07IM8VJJ4XT9usYHRbrmGEUGRRoDSrvCqS6pGugnnrKnW1G+yr9Q7L33DPYy78QlosvVt199/B+27bBr0m8vpVVq+rmExrtFSrTESPcfvPmbv3AA+6/kcmTI9N65x3VFSvC+6ecomagDCM+hWqgisbV0TPPwJlnwowZsO22GVImTc/CDZ7eveHRR2H6dNiwwTWntcuAN/2XX4a//MVtn3suXHUVdOkC22/vvBYAjB/v8qusdN4l0r3G0fEK7D43jEwSyNVRA6TgpttIl9D7KiPvqV9+ce6HRDbOF5+I6zvq2jWz6Z5ySthAHX98bJk993Rrf99WOhxwAHz9tTO2mT4PwzByQtEYqIwOkthiiwwk0oCpqMhe2jvsAGvXwrHHhmtN2aiJpjsYxDCMBkPRGKjQO9A/wCwt4jlu3ZiIHmWYSaZNy17ahmFsVBSNN/OUa1Dvvw9VVZFhs2fDv/6VUb0aJNk0UH46doSdd4aHH85NfoZhFBRWg4rFiBHQsyfccIObDqKqyv3z06lTNlXMPd26wciRdcNvuCE3+VdUwOTJucnLMIyCo2hqUCkNkli82K1nzHDrM85w88AUAnvvHd6+887YBijE11+Ht994A+6+203w17lz9vQzDMMISNHUoGI5OQjMkCEZ1SUjjBzpakDRlJeHt/v1C57eUUdBr17118swDCNDWA0qEd9+Gxk5CF9+mUIGKdK0aXh7//0jj7VtCy+9BLfcEiytaOOWq34nwzCMgBTNWymtYebff+98z6VioHbaya0PPhjeeSccnonayemnu3W0jzqARYvcP0Y9ekBpafKh8MOHu3Xo3EpL66+fYRhGBikaA5V0kMSyZW5Umd/RK8B336XWLti6tfO+8NFH7l+fEFdfnZK+CbnjjsTH16xxDlrj8bvfQfPmbjvUZ7WxesUwDKNgKRoDlbQG9fHHzqv4bbdFCo0Zk3pm5eXhGsmwYc57dqNGbn+33dyPqukQrXzoR9doKioi+6KimTAhvP3hh+7cy4qmO9IwjAKhaN5KSWtQIYNSW+umzAhRX9cTf/iDW1dWuvWNN0Ljxqml0bMn7LOPa8bzs/326enkry21aQOHHppeOoZhGFmk6AxUXHsTMlA1NXDhhZlXoGXLxMbuq6/gwANjH3v3Xbd++ml44gn3c2t9sOY8wzAKAGviCxEyUCFjkIiddw47NU134jv/AApwzk1DvP9+bCPZpw/89BMcdFA4bMoUmDQpcV4ffBC5bwbKMIwCoGgMVMImvuXL3cCCWKxbVzfsr391Q9BV3U+8mWLGDPjhBzcS76GH3KANPyJ1vVnstBPsskvidI8+2twJGYZRcBSNgYpbg3r/fTfyLt5U4R99FDyT998PLutXJDSSbttt3fxIISZPhqVLg6eZiAsuCG9bDcowjAKg6Pqg6tSgRoyof+JDhsDCha7mkw6DBsUOb9bMLZnGDJRhGAVA0RmoOjWodEbpRcc55ZS0dALcCL099kg/fjqYgTIMowCwJr58z4ibD2NhBsowjAKgaAxU3Ca+TNSg0iGfhtEMlGEYBUDRGKiM1qC6dq23Puy4o1ufcEL90zIMw9gIKbo+qHrVoEScO6QOHeqvUJcuzmNFixb1T8swDGMjpOgMVL1qUI89lhnjFKJly8ylZRiGsZFhTXxBDFTPns6hat++GdfLMAzDiE3WDJQIW4vwsQhTRJgswqUxZA4VYYUI473lpizqA6TZxLfDDuZQ1TAMI8dks4mvGrhSlXEitADGijBclSlRcp+rclwW9QDqWYNq3Trj+uSF0lLnDNcwDKMAyFoNSpWFqozztlcCU4H22covGfWqQW0scyVNmGA++QzDqIvI5YhMRmQSIoMRaYxIZ0RGITIdkSGIVORarZz0QYnQCdgLGBXj8AEiTBDhfRFiej0Vkb4iMkZExlRXV6erAxDDHgWZLfekk9LKs8Gxyy6RPvkMwzBE2gOXAF1R3RUoBXoDdwP/RnV7YBlwdq5Vy7qBEqE5MBS4TJXKqMPjgI6q7AH8B3gjVhqqOlBVu6pq17I0azNxm/iGDUseeYcd0srTMAyjQCgDmiBSBjQFFgKHA696x58B/phrpbJqoEQoxxmnF1R5Lfq4KpWqrPK23wPKRdgsS7oAvgrThg1wySUwa1Y2sjMMw2hIlIVaobwlPCRZdT5wHzAHZ5hWAGOB5aiGmqzmkYcumqx1roggwJPAVFUGxJHZElisioqwH85g/poNferUoB5+GP7zn/gRmjWD1auzoYphGEauqVbV2C5wRFoDvYDOwHLgFSDNqRkySzZ7/38PnAF8J8J4L+x6YBsAVR4D/gScL0I1sBborUpWnNTVqUGtXJk4QqNGZqAMwygGjgR+QvUXAERew72/N0GkzKtFdQDm51qxrBkoVb4AEnolVeUh4KFs6eAn7iAJP889F54ht23bzE0WaBiG0XCZA3RDpCmuonAEMAb4GFeJeAnoA7yZa8WK15NELEvl9/L93ntZ18kwDCPvqI7CDYYYB3yHswsDgWuBKxCZDmyK67LJKRvJDz7JqdPEN3BgXaHu3eH88+H66zPrc88wDKMho3ozcHNU6Exgvzxo8xtFY6Dq1KAWLKgrVF4OjzySM50MwzCM+BRNE19cTxKxhAzDMIy8U3QGShVYuDCvuhiGYRjJKbomvmYLfoQBMfqfwGpQhmEYDYiiMVAh23PELd2h8uf8KmMYhmEkpWgMVKgGVbFmeWyBa65x/z75OewwOOig7CpmGIZhxEQ0lSnPGwDNmjXT1Wl4eJg+Hbp0geryxpRWra8rUGDXwTAMIygiskZVm+Vbj1QpmkESJUVzpoZhGBsHRfPa/m0UX2LvS4ZhGEYDoegMlDXlGYZhFAZFY6BCTXxl1TH6nwzDMIwGR9EYKPvFyTAMo7AoGgNlgyQMwzAKi6J5bSesQV1xRc70MAzDMIJhBgqgXbuc6WEYhmEEo2gMlGviizOCr337XKpiGIZhBKBoDJQIHMhXsQ/27p1bZQzDMIykFI2BKimBbZhT98CJJ9oQP8MwjAZI0RgoEZBYTXylpblXxjAMw0hKURmoEhJNp2sYhmE0JIrGQJWUxKlBWfOeYRhGg6RoDFTcJj7DMAyjQZI1AyXC1iJ8LMIUESaLcGkMGRHhQRGmizBRhL2zpU/cGpRhGIbRIMnmjLrVwJWqjBOhBTBWhOGqTPHJHAN08Zb9gUe9dcaxPijDMIzCIms1KFUWqjLO214JTAWi/4jtBTyriqoyEthEhKy4dYhroKwPyjAMo0GSkz4oEToBewGjog61B+b69udR14hlhJISOIIR2UjaMAzDyALZbOIDQITmwFDgMlUq00tD+gJ9ASoqKtLVg78yOK24hmEYRu7Jag1KhHKccXpBlddiiMwHtvbtd/DCIlDVgaraVVW7lpWlZ1PjTrdhTXyGYRgNkmyO4hPgSWCqKgPiiL0F/M0bzdcNWKHKwizpYxiGYRQQKVVHRCgBmgdsqvs9cAbwnQjjvbDrgW0AVHkMeA/oCUwH1gB/T0WfVDADZRiGkUNETgogtQ7V9+IdTGqgRHgROA+oAb4BWorwgCr3JoqnyhdAQrOgigIXJtMhE1gTn2EYRk55AniTxHbgYFxFJSZBalA7q1IpwmnA+8B1wFhIbKAaGmaHDMMwcuLEEFcAACAASURBVMr7qJ6VUELk+USHg/RBlXuDHf4IvKVKFXFn/mu4mIEyDMPIIaqn11cmiIF6HJgFNAM+E6EjpDdc3DAMwyhSRLZH5HlEhiJyQJAoSQ2UKg+q0l6Vnp7Hh9nAYfVWNt+cdppbW9XKMAwj84g0jgq5DegHXIZza5eUpAZKhEtFaOkNBX9ShHHA4Skr25DYay/o2TPfWhiGYTQMRDZB5FVEpiEyFZEDEGmDyHBEfvTWrVNM9W1E/ubbrwI6AR1xg+6SEqSJ7yxvWPkfgNa4oeN3paZnA6NDB9CC60YzDMPIFg8AH6C6I7AHznfqdcAIVLsAI7z9VOgBtETkA0QOBq4CjgZOBE4LkkAQAxVqA+sJPKfKZJIMH2+oDCi9ym0M9rk8siY+wzCKGZFWuOHeTwKgugHV5Thn3s94Us/gBsoFR7UG1YeAvwAn4IzgU6heieq0IEkEGWY+VoQPgc5AP2/qjIKct6JSWrmNigo46STXD3XPPflVyjAMI/uUicgY3/5AVR3obXcGfgGeQmQP3G9ElwJtUQ159lkEtE0pR5H9gauBDcCdwFrgDkTmA7d5RjCx0gGyORvYE5ipyhoRNiWLHh+ySWf9yW2IQJMm8HzCIfiGYRgbC9Wq2jXOsTJgb+BiVEch8gDRzXmqikiq/SKP41remuNqTr8HeiNyCDAE19yXkKQGSpVaEToAf/Vawz5V5e0UFW0Q9KkZ5DasWc8wDCPEPGAeqqHpkF7FGajFiLRDdSEi7YCfU0y3GjcoohmuFuVQ/RT4NEgCQUbx3YWr7k3xlktEuDNFRRsWZqAMwzAcqouAuYjs4IUcgXvXvwX08cL64NwWpcJfgZNxo77/lkQ2JqJJRrOJMBHYU9X1O4lQCnyryu7pZFhfmjVrpqtXr04vcsgw1daakTIMo2gQkTWq2iyBwJ7Af4EKYCauG6cEeBnn4Hs2cAqqS7OvbZig3sw3AUKKtcqSLrnDjJNhGEYY1fFArD6qI9JOU+QdVI+rj0wQA/V/wLcifIwbXn4wqY+HNwzDMIqL7oi8leC4ADsnSiDIIInBInwC7OsFXYv7E7jgWEcjGrM+32oYhmEUA70CyGxIdDBpH1TMSMIcVTfxYK7JSB+UeZEwDKOISNoH1UBJd8p368QxDMMwskq6BsqqIIZhGEZWidsHJcLbxDZEAmyaNY0MwzCMjQeR44F3UU3ZRV7cPigRDkkUUTXYn8CZxvqgDMMwUiOvfVBuWvcDgKHAoKCOYiHNQRL5xAyUYRhGauR9kIRIS+BU3A/ACjwFDEZ1ZaJo6fZBGYZhGEYwVCtxPv5eAtrh5oQah8jFiaIVlYFaVdKCBc275FsNwzCM4kHkBEReBz4ByoH9UD0GNzHilYmiBnV1tFEwv6Izy1t0Zqt8K2IYhlE8nAz8G9XPIkJV1yBydqKISQ1UnNF8K4AxwOOqrEtN1/whKGq/cBmGYeSSW4CFv+2JNMFNhjgL1RGJIgZp4psJrAKe8JZKYCXwO28/JiIMEuFnESbFOX6oCCtEGO8tNwXQpV6YgTIMw8g5rxA5C3uNF5aUIE18B6r+5ocP4G0RvlFlXxEmJ4j3NPAQ8GwCmc9VSeztNoOIKuYEwzAMI6eUoeqfsHADIhVBIgapQTUXCfvd87abe7txHf2p8hnhKToaBFaDMgzDyDm/IHLCb3sivYAlQSIGqUFdCXwhwgxc9aMzcIEIzYBnUtc1ggNEmAAsAK5SjV0jE5G+QF+AiopAhjcmZqAMwzByznnAC4g8hLMhcwk4w26gH3VFaATs6O1+H3RghAidgHdU2TXGsZZArSqrROgJPKBK0jHg9flR94eynZjRbHeOWTEkrfiGYRiFSN5/1HVKuJY31VVBowQdZr4P0MmT30MEVBP2LSVFlUrf9nsiPCLCZqrBqn5p5VlTy4pKq0EZhmHkFJFjgV2Axj6PPrcmixZkmPlzwHbAeNzoC3DDzutloETYElisioqwH64/7Nf6pJk0T2viMwzDyC0ijwFNgcOA/wJ/AkYHiRqkBtUV2Fk1tSk2RBgMHApsJsI84GbcX8So8pin5PkiVANrgd6p5pEqJdRSQ2k2szAMwzAiORDV3RGZiGp/RP4FvB8kYhADNQnYEv+PVgFQ5dQkxx/CDUPPGWVUU11czjMMwzDyTWjMwhpEtsK1lLULEjHI23ozYIoIo4H1oUBVTogfpWFiBsowDCPnvI3IJsC9wDhcF1FcJw9+grytb0lfr4aFGSjDMIwcIlICjEB1OTAUkXeAxqiuCBI96ds6XxMTZoNyqaZazUAZhmHkBNVaRB4G9vL21+NriUtGXE8SInzhrVeKUOlbVoqEh4gXEo3LqmnWwgZJGIZh5JARiJyMSMpDqItnRt2aGigrY3L5HuyyYXzmFTMMw2ig5HnK95VAM6AaN2BCAEW1ZbKogdq7RCgF2vrlVZmTlrL54lf3i9UuVRPyrIhhGEYRodoi3ahBftS9GPcP02LCLtMV2D3dTPNCPXz4GYZhGGkicnDM8OgJDGMQpAZ1KbCDana9PGQdrynz3iY3cXWeVTEMwygi/K/cxsB+wFjg8GQRgxioubgZdAsbz0DNW9sGERg2DP7whzzrZBiGsbGjenzEvsjWwP1BogYxUDOBT0R4l8gfdQekoGL+8QxUrTdw8Z57zEAZhmHkgXnATkEEgxioOd5S4S2FSa3rPgs5i01zxg7DMAwjFUT+A7/5WS0B9sR5lEhKkB91+6evWQPCq0GFDNSaNflUxjAMo2gY49uuBgaj+mWQiHENlAj3q3KZCG9DXS/jBeeLL8pA1dYmEjYMwzAyxKvAOlTddE0ipYg0RTVpNSFRDeo5b31f/fVrAEQZKMMwDCMnjACOBEIz6TYBPgQOTBYxroFSZay33jh88UUZqAJzoGEYhpFdREpxzXHzUT0Okc7AS8CmuGHhZ6C6IY2UG0dM8666CpGmQSLG9cUX1pkuIrwqwhQRZoaWNJTML1Gj+MxAGYZhRHApMNW3fzfwb1S3B5YBZ6eZ7mpE9v5tT2Qf3CS1SUlqoICngEdxnVuH4aZ6fz51HfPMN98AsAfO1ZH1QRmGYXiIdACOxU3JjufY9XBc/xHAM8Af00z9MuAVRD5H5AtgCHBRkIhBDFQTVUYAospsVW7BnUhh8cYbABzHOwBMm5ZPZQzDMHJKmYiM8S19o47fD1xD2J3dpsByVKu9/XlA+7RyVv0G2BE4HzgP2AnVsYGUDiCzXoQS4EcRLgLmA83TUtQwDMPIB9Wq2jXmEZHjgJ9RHYvIoRnPWeRC4AVUJ3n7rRE5FdVHkkUNUoO6FGgKXALsA5wO9Elf2zwRo9NpbaBWUMMwjI2a3wMnIDILNyjicOABYBNEQpWYDrjKSTqc482o61BdBpwTJGJCA+VNs/EXVVapMk+Vv6tysioj01Q0f8QYZj55cr6UMQzDaCCo9kO1A6qdgN7AR6ieBnwM/MmT6gO8mWYOpRGTFbrRgoG8EiWaUbdMlRqge5pKNSzsPyjDMIxUuBa4ApHpuD6pJ9NM5wNgCCJHIHIEMNgLS0qiPqjRwN7AtyK8BbwC/ObBTpXX0lQ2P8QwUDbU3DAMw4fqJ8An3vZM3NQY9eVaoC9ukATAcOCJIBGDDJJoDPyKa5dUQtP1UmAGysNqUIZhGDlEtRZ4zFtA5CDgP8CFyaImMlBbiHAFMImwYfoty3R1zRsxqkvmMNYwDCMHiOwFnAqcAvxEwApOIgNVihtOHqvKkdRAiTAIOA74WZVdYxwX3EiRnsAa4EzVYC7Y64O/BnXoodbMZxiGkRVEfoczSqcCS3A/6AqqhwVNIpGBWqjKrfVQ72ngIZzniVgcA3Txlv1x3ir2r0d+ibFBEoZhGLlkGvA5cByq0wEQuTyVBBINM6/Xm1yVz4ClCUR6Ac+qot6w9U1EaFefPJMpBHUN1OLFWcvRMAyjmDkJWAh8jMgT3gi+lOxKIgN1RH00C0B7YK5vP64rDRHpG3LRUV1dHUskbS5PyZ4bhmEYgVB9A9XeODdHH+N88m2ByKOI/CFIEnENlGrC2k9OUdWBqtpVVbuWlQUZeBgzkVSCDcMwjEyguhrVF1E9HueR4lvc0POkBHF1lC3mA1v79uvjSiMw0U18IwvPJ4ZhGEZhoroM1YGoBmqhy6eBegv4mwgiQjdghSoLs5ZbnKrSrFkwZkzWcjUMwzDSJM32suSIMBg4FNhMhHnAzUA5gCqPAe/hhphPxw0z/3u2dMHLFGKP4hs9GrrG9vNrGIZh5ImsGShVTk1yXAnwJ3GmiWWgSvJZjzQMwzBiUjyv5u23B2As++RZEcMwDCMIxWOgujun7A/FmGn4/PPrBBmGYRh5pngMlNcH1aqVeZIwDMMoBIrHQHmYqyPDMIzCoOgMlGEYhlEYFI+BCg0zN88RhmEYBUHxGCiPsnJr4jMMwygEisdAeVWnhx+Gyy7Lsy6GYRhGUorHQHlsu53Qr1++tTAMwzCSUTwGytf5VFsbX0wELsy5fwvDMAwjmuIxUCFEqKpKLPLII7lRxTAMw4hP8RkoYKut6obZzLqGYRgNi+IxUL4mvtLSuoe33BJWrcqhPoZhGEZCisdAhZD4w8yjDVRNjVsMwzCM3FM8BirqD91YQ82jf+ItK4Mjj8yiToZhGEZcisdAhfBqULffXvdQLC8Tn3ySXXUMwzCM2BSfgfJo1qxu2PTpudfDMAzDiE3xGKgATvgOOSQHehiGYRiBKB4DFcI3SGLLLeOLrVmTA10MwzCMuBSPgYpRg1q4ML74scdmURfDMAwjKcVjoEIkGGbuxwZHGIZh5JfiM1BRnH9+vjUwDMMwYlE8BirOIIk2bXKsh2EYhhGI4jFQIaKa+GyGXcMwjIZJVg2UCD1E+F6E6SJcF+P4mSL8IsJ4b/lH1pSJY4mCGKgtt4QNG+IfP/ZY6NgxTb0MwzDyicjWiHyMyBREJiNyqRfeBpHhiPzorVvnWrWsGSgRSoGHgWOAnYFTRdg5hugQVfb0lv9mSx+/Yn6CGKjFi2HwYPjmm9jH33sP5szJgG6GYRi5pxq4EtWdgW7AhYjsDFwHjEC1CzDC288p2axB7QdMV2WmKhuAl4BeWcwvLYI28Z15Juy3X+bynT3b2crBgzOXZjImT4aHHspdfoZhFACqC1Ed522vBKYC7XHv62c8qWeAP+ZatWwaqPbAXN/+PC8smpNFmCjCqyJsHSshEekrImNEZEx1dXV62sSxRIlm180mEye69Qsv5C7PPfaAiy/OXX6GYTQYykLvUG/pG1NKpBOwFzAKaItq6G/RRUDbXCjqJ9+DJN4GOqmyOzCcsLWOQFUHqmpXVe1aVlZWvxyjmvi6d69fcvVVI5eDNGzqEMMoWqpD71BvGVhHQqQ5MBS4DNXKiGOqCuR8SFk2DdR8iKgRdfDCfkOVX1VZ7+3+F9gna9rEsQQnnABjxwZPRgR++qn+6sQyUGPHwsiR4f3KSli+vP55GYZhJESkHGecXkD1NS90MSLtvOPtgJ9zrVY2DdQ3QBcROotQAfQG3vILiNDOt3sCru0zu8TwJLH33vDaazFk43DBBfVX47jj3Npfq+naFQ44ILy/2WbQOufjZgzDKCpEBHgSmIrqAN+Rt4A+3nYf4M1cq1bP9rL4qFItwkXAMKAUGKTKZBFuBcao8hZwiQgn4EaRLAXOzJY+yQjoAQmAbt0yl++HH8KUKbBzjPGNVVWZy8cwDCMOvwfOAL5DZLwXdj1wF/AyImcDs4FTcq1Y1gwUgCrvAe9Fhd3k2+4H9MumDv6M63E4bdkgfPllbAOVKQYNgnHjwvuqqRlkwzA2YlS/AOK9EY7IpSrRZNVANUjivJlTGc2XaQO1cmXk/vLlsGBB5tI/++zIfTNQhmEUAvkexZc7kliVUN/P8OFw9dWJk/rxRxg6FFatiuxD2nbb9FS78kpYvz6837077LJLXbkNG+DJJ+tvIM29k2EYhYDVoDy22ir84k40TxS4n2tDP9j26RMOr8/ovsmTY2/7ufVWuOMOaN4c/vKX9PMyA2UYRiFQPDWoFEil+euZmH9upc4+AQbY/+wN8lyxIhw2fz7Mm5daXmagDMMoBIrHQKXwVs5m/8xTT6WevgiMGBH7FDp0gK19f5vNmwf9+iXuU8uX9wzDMIxUKB4DFSKAdejcObz91FPpZ7V8OcyY4fqp3n7bZX3WWemldeSRYQOV6BROPx3uugtGj44v458teO7c3LpbMgzDCErxGKgUalAHHui8OtTUwBlnwHbbpZbV9Olw3nnuJ9vtt4ejjoKrrkpR3wT07Rv+0dfPmjXw6aduO1EtqUeP8PZBBzmjtnZt5vQzDMPIBMVjoEIEbF/be28oKYHSUmdwgvLGG9ClCzz+eDjs44/hl19S1DMG/r6nd991HtFDqEKrVuH9I45ww9fXrImd1qxZbh1K49BDYdky+znYMIyGQ/EZqDTx/+iaiBNPjB2+bFn9dXj11cj9Tp3C2yUl4Hf0vm4dtGwZfyLFDz90vv5CjB4NbdrUb3SgYRhGJikeA1XPoWu77pohPXLMkiWxw889N7LGFeL117Orj5/qajj6aPj669zlaRhG4WD/QQWktDTDehjMmuVqcjNnup+fDcMw/FgNKiAlJW4qjGQ/8W4MZGuKjylT4MIL4bvv3H6Jd/fZsHfDMGJRPAYqRD1+ctp/f9hyywzq0kDp3z876XbrBo88Arvv7vZDBiobEyk+/jg89ljm0zUMI3cUn4HKANGDFTY2Vq8Obz/8MIwZU/80R42q6xQ31GyajRrUeefB+ee7eb5SmZDSMIyGQ/EYqAz69zn5ZOd2KFOd+z17ZiadTPLKK66yedFFsO++weKsXev+94o1tH348Lphocrs3Lnp6wnw5z/HrxiffLKbCNIwjMKjeAxUiAz5Mdp888xNXPjGG5lJJ1OowikxpiZ7/313+ebMiR3vgQfgX/+CZs3i/38V4pxz4KWXwvvDhjmvGyJuefTR8LGqqkjvF9EUUo12xgznLd/8IRpGcorHQGXpjbB6NXz0kUv+7rvTS6O8PPIFfPnlzjN6vH+Y0qVRo2BysQaCjBrlvKmDGyyydm3dprl168LbixaFt2fNgn/+M1L2v/+NnNakRw/ndSOEvx/sxhvhsMOcDhs2wCGHuNprVVX8YfQNiQULwp46TjwR7rsPpk7Nr06GUQgUj4EKkWFPsE2bupcnwDXXuA7/L76A556rKztoUHi7e3fnAPabb9x+6D+riy+GAQPcT7j/938ZVZXHHgtmRN99t25Yt27OMIEzRE2bwhVXRMr4BzuEBkCsXOlcPaXK4sUwYYIrrnvucWHz58O0afDZZ87dU58+riYbYuHCsIeMaE47za3vv9+l2b59pBHNJu3bwzHHuO3QNbIalGEEQFULamnatKmmxbPPqoLq9OnpxU+DsWNdlqDaurULW7VKdccdVb/6qq78nDmqVVXh/TVrwvEzsYSobzrnnBPeXrkynO7114fD33lH9bPPMqt/8+aqr7/utnfYIb7c6NHxz9+/37+/6rbbqk6aFD6HqirVV15Rra0NVsYXXODS2nPP+DKh/Gprw9sTJrhjs2erLlsWLK9ErF6t+vDDqjU1dY8tWaJ6ySWq69fXP5+GxJIlqnPn5luLwgBYrQ3g/Z3qkncFUl3SNlDPPKO5NlCq7oV34YXO+KRD6IX2+OP1e7ln0kD5l7ZtVVu1cuvoY8cdl9m86rv07h07vGvX8LW55x4XNnhwauXjv74hqqtVJ04MHz/xxPD2l1+G47drl9694efmm11azz1X96V91lnu2Isv1j+foCxZEt7+5BPVzz/PfB6NGrnzmjUr/ecrKGPHuuc46IdLQ8MMVI6WehuoGTPSi58nQi+0BQvc+vLLVadNC4e3bOnWAweGwwYMcOu//U31ssvqvkCjX9BVVe7yfPNN7Bd4sSxjx4av14AB7lqtWpW4hpPIQN1yS/y82rePjD92bGTc665TPf30yLCqKlfO1dV187rwwsj0/cYo9KGwyy5uf/787L1oJ09W7dfP5Td6tAuLd33qS/Q19bNyZaSRrC+tWrk8li4NJj9smOq4cZnLv76YgcrRkraBevppLVQD1bix266qCr9YbrvNHdt550hZcM08d9+tumKFe7mC6jXXhOW22caFPfqoe6FE51esy803q155pds+4ADVdevCNUNVtz97dvzrFavsEi3RMvvv78pu6NBImaVLXdPmrru6sIceCuexfLnqmWc6ff1pnXOOOx667UPLu++69aBB4TRuvVW1R4+kt2Kd83rttcTn/OSTqmvXxr4+O+2k2qFDsPw+/bRu0+WiRXWv5y67uOdjxYpw2IoVqiNG1L/2GPoQDNocG33ONTWql16q+v339dMjXcxA5Wipt4GaOTO9+Hniuedi39SzZ7vTufjicNidd4b7uhKxbFn8JpFvv038Ui3WRVX1tNPc9k8/ha+XX+ann1Rvukn1gw9U+/ZNL5/ddovcHzhQ9ZBDYstedJH7eImX1n/+o3r88fGPP/xw5Dmouo8gcE3KqqojR7oau5+Q/BFH1L1//Okfemi4GQ5UKytV77svUuaFF8Jxa2tVN2xw9/b8+ZHNo3fe6farqxNfP3+LAajutVfk+fn1/Oc/3faGDapffx0+9u67kX3BX3wRTiOWgaqsdLqNGeOe1x9/DMvPm+ee39tvd/v+vsqamrrP4b33uhpoqGxUXRNmfb+rzUDlaCk2A5WIKVPcw5VpMj04I59LZWX+dWjIy8KFkfubbx7e9tdE+vd3fXXHHBMO69kzXNsbNSqxMUy0XHON6hZbBJMNtdSnsxx/vKv1+Y3cSy+pnnyy2540ydW2QsdU3WCm6HT+8hdnSNavdx8kqejQtavqxx9Hhr31lvuYiO7HffBB1Y8+itQnXQrVQInTvXBo1qyZrvb74gnK00/D3//uXGf753Q3YnL//e5/rFzw2WduaH02flhWzfifBUYMDjvMTcy5MdG7d+TP5NG0ahU5iWi2qayEFi3Siysia1S1WWY1yj5Z/Q9KhB4ifC/CdBGui3G8kQhDvOOjROiUTX1CmRrJueQS50II3GSG4PzbDR0K48e7f6Fqa2Hy5LpxX37Z/RP28suRRueAA9x6+vTI78qDDoJnn3XeJHbaycmceWb9z6FNG7eO/pn3d79zun3wQf3zMBwbm3GCxMYJcmucAN57L7f5NQiyVTUDLQWdAbotaAXoBNCdo2QuAH3M2+4NOiRZumk38Q0a5N6H/g4EI6P066e69dZ1w//6V3fpg4xqmj7dDRZYutQVlb8jPmTSqqtdX0Cowx9cs0nfvk7u++9dmL81d8oU1f/9z4X7h5BPmuTCWrdOrammIS+DB+dfB1syv8QalBIUCrSJL3sJoweADvPt9wPtFyUzDPQAb7sMdAmoJEq33gZq1qz04htpU1ur+ssv9U9n6tTIzuLaWjccvLIyeBrx9KitdX1vV1/tBiWsW+dGj733XnhE5GWXuf95PvjADff3G4Itt3T9OSNHRg4vX7HCdbh/8onqY4+5rtDBg13H+8yZqr/+qvrmm66/YckS16dx5JF1X04DB6rut1/sF9fmm7vRnP4RhqFjfsMbGv59112qvXolHmCR6eXii7OT7g03uJGoPXq4/RYt4sttt13uzjcby7BhaT023v1QmAYqa31QIvwJ6KHKP7z9M4D9VbnIJzPJk5nn7c/wZJZEpiV9gb4AFRUV+6xfvz51hZ56Cs46y/nCybSTO6NoUY3darxihfMb6HfFlA7z5kGHDuH9deucJ/1ttoHqaudSqiROQ33IV2JtrXM5tckmwVq4q6uhLMZc23PmQNu2zkXXMcdEprVmjXNNtffezufjd99B8+bOzVNFhZNRdWl07OjyqKqCJk3c+bRs6fwVLl/uPOLffHN43rDRo2GPPZxOofMISlWV85fpj1NbC6+/7vw/1tQ4b/rl5a7pNxSntNStx451zo932MHpucUW7nwWLnQ+Ft9/37kB220354Zrxx1duUe/YlascOfRrp3Lv7LSuTurrHRN2/Pnw9/+5vLr1g0GDnTTxSxZ4vQ78MD69U4Uah9UQRgoP2kPkhg0CM4+2wyUYRhFR6EaqGwOkpgPbO3b7+CFxZQRoQxoBfyaRZ1skIRhGEaBkE0D9Q3QRYTOIlQAvYG3omTeAvp4238CPlIlO1W6LNUUDcMwjOwQo6U5M6hSLcJFwDCgFBikymQRbgXGqPIW8CTwnAjTgaU4I5ZdrAZlGIZREGTNQAGo8h7wXlTYTb7tdcCfs6mDP2PDMAyjcLAJCw3DMIwGSfEZKMMwDCMSkR6IfI/IdETqeP3JF8VjoLp1g3//2znQMgzDMBwipcDDwDHAzsCpiOycX6UcWe2DalDsuqtbDMMwDD/7AdNRnQmAyEtAL2BKPpWCAjRQa9asURFZm2b0MqA6y3GKTT4XeRS6fC7yKHT5XORR6PL1oYmIjPHtD1TVgd52e2Cu79g8YP8c6ZWQgjNQqpp2s6SIjFHVrtmMU2zyDVGnhibfEHVqaPINUaeGJl+MFE8flGEYhhGLIF5/8oIZKMMwjOLmG6ALIp0Rief1Jy8UXBNfPRmYXKTecYpNPhd5FLp8LvIodPlc5FHo8tlBtRqRCK8/qMaYijT3FNyU74ZhGEZxYE18hmEYRoPEDJRhGIbRICkaAyUiPUTkexGZLklceYjIIBH5WUQmBUx7axH5WESmiMhkEbk0iXxjERktIhM8+f4B8ykVkW9F5J2A8rNE5DsRGR/1D0Q8+U1E5FURmSYiU0XkgASyO3jphpZKEbksSfqXe+c7SUQGi0jjJPKXerKT46Udq6xEpI2IDBeRH7116yTyf/byqBWRrgHSv9e7RhNF5HUR2SSJ/G2e7HgR+VBEtkqWh+/YlSKiIrJZkjxuEZH5vvLomSx9hbY3qwAACEdJREFUEbnYO4/JInJPkvSH+NKeJSLjk8jvKSIjQ/eeiOyXRH4PEfnau1/fFpGWvmMxn6945ZxAPlE5x4sTs6wTyMcs63jyicrZgLzPOZ+LBdfxNwPYFqgAJgA7J5A/GNgbmBQw/XbA3t52C+CHJOkL0NzbLgdGAd0C5HMF8CLwTkC9ZgGbpXCdngH+4W1XAJukcH0XAR0TyLQHfgKaePsvA2cmkN8VmAQ0xQ3m+R+wfZCyAu4BrvO2rwPuTiK/E7AD8AnQNUD6fwDKvO27A6Tf0rd9CfBYkPsNN/R3GDDbX45x8rgFuCro/Qwc5l3TRt7+FkHvf+BfwE1J0v8QOMbb7gl8kkT+G+AQb/ss4LZkz1e8ck4gn6ic48WJWdYJ5GOWdTz5ROVsixZNDWo/YLqqzlTVDUDIlUdMVPUz3PxUgVDVhao6ztteCUzFvZDjyauqrvJ2y70l4WgVEekAHAv8N6heqSAirXAvjic9HTeo6vKA0Y8AZqjq7CRyZbg/2stwhmdBAtmdgFGqukZVq4FPgZOiheKUVS+cscVb/zGRvKpOVdXvYykRR/5DTyeAkbj/RhLJV/p2mxFV1gnut38D16QgH5M48ucDd6nqek/m5yDpi4gApwCDk8grEKoFtcJX1nHkfwd85m0PB072ycd7vmKWczz5JOUcL07Msk4gH7Osk7wjYpazUTxNfLFcecQ1IPVBRDoBe+FqRYnkSr1mkp+B4aqaUB64H3cT16agjgIfishYEembRLYz8AvwlLhmxP+KSLOA+fTG98KKqYjqfOA+YA6wEFihqh8miDIJOEhENhWRpriv8K0TyPtpq6oLve1FQNuA8dLhLOD9ZEIicoeIzAVOg/CcaAnkewHzVXVCCrpc5DUvDRJfs2Ycfoe7vqNE5FMR2TdgHgcBi1X1xyRylwH3eud8H9Avifxkwh+NfyZOWUc9X0nLOejzGDBOzLKOlk9W1n75NMu5aCgWA5UTRKQ5MBS4LOpLqg6qWqOqe+K+yPYTkbiebEXkOOBnVR2bokrdVXVvnJfiC0Xk4ASyZbhml0dVdS9gNa7ZJCHifuw7AXgliVxr3AuoM7AV0ExETo8nr6pTcU0qHwIfAOOBmmT6xEhHydKXqYjcgPOl9kIAPW5Q1a092YuSpNsUuJ4AhszHo8B2wJ64D4B/JZEvA9oA3YCrgZe92lEyTiXJx4jH+cDl3jlfjlczT8BZwAUiMhbXBLYhWiDR8xWrnFN5HpPFiVfWseQTlbVf3ksv1XIuKorFQGXdlYeIlONuvBdU9bWg8bxmtI+BHgnEfg+cICKzcM2Th4vI8wHSnu+tfwZexzV1xmMeMM9Xk3sVZ7CScQwwTlUXJ5E7EvhJVX9R1SrgNeDAJPo/qar7qOrBwDJcu30QFotIOwBv/XMS+ZQRkTOB44DTvJdjUF7A13wVh+1whnyCV+YdgHEismW8CKq62PvoqQWeIHFZgyvv17zm5tG4mnnCDnqvafYkYEiStAH64MoY3MdLQn1UdZqq/kFV98EZwBlRecd6vuKWczrPY7w48co6QB4RZR1DPuVyLjaKxUB9A3QRkc6SBVce3pfnk8BUVR0QQH5z32igJsBRwLR48qraT1U7qGonnO4fqWrc2oeXbjMRaRHaxnX2xh2VqKqLgLkisoMXdATB3O0H/aKeA3QTkabe9ToC1w4fFxHZwltvg3sxvhggH3Bl28fb7gO8GTBeIESkB6659QRVXRNAvotvtxcJyhpAVb9T1S1UtZNX5vNwHeyLEuTRzrd7IgnK2uMN3EAJROR3uEExS5LEORKYpqrzksiB63M6xNs+HEjYJOgr6xLgRuAx37F4z1fMck71eUwUJ15ZJ5CPWdax5NMp56JDG8BIjVwsuD6MH3BfZjckkR2Mayapwt00ZyeR745rXpiIa4oaD/RMIL878K0nPwnfiKgA53EoAUbx4UYsTvCWycnO2YuzJzDG0+sNoHUS+WbAr0CrgLr3xz2wk4Dn8EaQJZD/HGckJwBHBC0rYFNgBO6l+D+gTRL5E73t9cBiYFgS+em4Ps1QWT+WRH6od84TgbdxnemB7zeiRmPGyeM54Dsvj7eAdknkK4DnPb3GAYcn0wd4GjgvYBl0B8Z6ZTcK2CeJ/KW45/MH4C48LzeJnq945ZxAPlE5x4sTs6wTyMcs63jyicrZFjVXR4ZhGEbDpFia+AzDMIwCwwyUYRiG0SAxA2UYhmE0SMxAGYZhGA0SM1CGYRhGg8QMlGFEISI1EumpPalHjRTS7iQBveQbRrFTbFO+G0YQ1qpzQ2UYRh6xGpRhBETcPEj3iJuzaLSIbO+FdxKRjzxHrSM8zxeISFtxcwhN8JaQa6dSEXlC3LxAH3reRAzDiMIMlGHUpUlUE99ffMdWqOpuwEM4D/MA/wGeUdXdcf7XHvTCHwQ+VdU9cH4NJ3vhXYCHVXUXYDnJffMZRlFiniQMIwoRWaX/394dozQQBWEc/6awCAgiprSwyQ28i1iKlUVIFbxATuFJbKwE7T2A2CnoBSSEL8XMQiARsxDlKf9fk7evCLvVZPKW+ez9DfsvypFAzzX48832UUR8KEcLzWv/1fYwIt4lHbsyl+o7TpTxKqO6vpa0Z3v2808G/C10UEA//mLdx+fKeiHOgoGNKFBAP2crn4+1flBOmZcypO6+1nfKXKQuoPLgt24S+A/45QasG0SmHXdubXevmh9GxJOyCzqvvbEyiXiqTCW+qP2JpJuIuFR2SlfKKd4AtsAZFLClOoM6tf1dbhKAHeAvPgBAk+igAABNooMCADSJAgUAaBIFCgDQJAoUAKBJFCgAQJOWc3nUNtIq8q8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klaZRLJUlxik"
      },
      "source": [
        "# Test Data Accuracy for Ancient Greek "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW7S-0kVorQD",
        "outputId": "146e45e0-96ac-4109-d3fa-2db306feabc4"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 64 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_agreek_test, y_agreek_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 78.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Qi0jHgnYBg"
      },
      "source": [
        "# Number of Sentences and Sentence Length Visualization Latin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Jw3PADDenh3W",
        "outputId": "b344f2f5-b4bd-43b2-9033-c2831d47e5f7"
      },
      "source": [
        "l = np.asarray([len(x) for x in X_latin_train], dtype=np.int)\n",
        "plt.figure(figsize=(8, 4))\n",
        "x = np.unique(l)\n",
        "plt.bar(x, [np.sum(l==e) for e in x], width=1)\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"# sentences\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAEGCAYAAACTjGeYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWQklEQVR4nO3dfbRddX3n8fdnCBTwiYfcYTAQE2iKi3ZVoBnkQVkpVEuBZeiUQbvaTlSm6ShSbGs1pS7pOLULaReUOl1oFDV2MQhSKgguHkxB2zpFE0QegpQMhhoKJNQCohYMfuePs69cQ+7NuffmPO37fq111z17n33O/ua3OHzub+/f+f1SVUiSpNH2HwZdgCRJmj0DXZKkFjDQJUlqAQNdkqQWMNAlSWqBeYMuYDbmz59fixYtGnQZkiT1xfr16x+vqrEdPTfSgb5o0SLWrVs36DIkSeqLJA9N9pyX3CVJagEDXZKkFjDQJUlqAQNdkqQWMNAlSWoBA12SpBYw0CVJagEDXZKkFjDQJUlqgZGeKa7tFq26YdLnNl1wah8rkSQNO3vokiS1gIEuSVILGOiSJLWAgS5JUgsY6JIktYCj3AdsqpHskiR1yx66JEktYKBLktQCBrokSS3Qs0BP8vEkW5LcM2HffkluSfJA83vfZn+S/EWSjUnuSnJUr+qSJKmNetlD/yRw8nb7VgFrq2oJsLbZBvglYEnzsxK4tId1SZLUOj0L9Kr6EvDt7XYvB9Y0j9cAp0/Y/6nq+EdgnyQH9qo2SZLapt/30A+oqkeax48CBzSPFwDfmnDc5mbfCyRZmWRdknVbt27tXaWSJI2QgQ2Kq6oCagavW11VS6tq6djYWA8qkyRp9PQ70B8bv5Te/N7S7H8YOHjCcQc1+yRJUhf6HejXASuaxyuAayfs/2/NaPdjgCcnXJqXJEk70bOpX5NcASwD5ifZDJwPXABcleQs4CHgzObwzwOnABuB7wFv6VVdkiS1Uc8Cvap+dZKnTtrBsQWc3ataJElqO2eKkySpBQx0SZJawECXJKkFDHRJklrAQJckqQUMdEmSWsBAlySpBQx0SZJawECXJKkFDHRJklrAQJckqQUMdEmSWsBAlySpBQx0SZJawECXJKkFDHRJklrAQJckqQUMdEmSWsBAlySpBQx0SZJawECXJKkFDHRJklrAQJckqQUMdEmSWsBAlySpBQx0SZJawECXJKkFDHRJklrAQJckqQUMdEmSWmAggZ7kd5Lcm+SeJFck2TPJ4iS3J9mY5MokewyiNkmSRtG8fp8wyQLgt4HDq+r7Sa4C3gScAlxcVZ9O8mHgLODSftfXC4tW3TDoEiRJLTeoS+7zgL2SzAP2Bh4BTgSubp5fA5w+oNokSRo5fe+hV9XDSf4M+Gfg+8DNwHrgiara1hy2GViwo9cnWQmsBFi4cGHvCx5SU/X6N11wah8rkSQNg7730JPsCywHFgMvB14EnNzt66tqdVUtraqlY2NjPapSkqTRMohL7r8AfLOqtlbVD4BrgOOBfZpL8AAHAQ8PoDZJkkbSIAL9n4FjkuydJMBJwAbgVuCM5pgVwLUDqE2SpJHU90CvqtvpDH67A7i7qWE18B7gd5NsBPYHLut3bZIkjaq+D4oDqKrzgfO32/0gcPQAypEkaeQ5U5wkSS1goEuS1AIGuiRJLWCgS5LUAga6JEktYKBLktQCA/namobTzlaFc454SRpe9tAlSWoBA12SpBbwkru65pKtkjS87KFLktQCOw30JBcmeWmS3ZOsTbI1ya/3ozhJktSdbnror6+qp4DTgE3ATwK/38uiJEnS9HRzD338mFOBz1TVk51lzDWsvNctSXNPN4F+fZJvAN8H3pZkDPj33pYlSZKmY6eBXlWrklwIPFlVzyX5HrC896WpLbxiIEm9182guL2BtwOXNrteDiztZVGSJGl6uhkU9wngWeC4Zvth4I97VpEkSZq2bgL90Kq6EPgBQFV9D3BUnCRJQ6SbQH82yV5AASQ5FHimp1VJkqRp6WaU+/nAjcDBSS4Hjgfe3MuiJEnS9HQzyv2WJHcAx9C51H5uVT3e88rUEztbIlWSNJq6GeX+y8C2qrqhqq4HtiU5vfelSZKkbnVzD/38qnpyfKOqnqBzGV6SJA2JbgJ9R8e47KokSUOkm0Bfl+SiJIc2PxcB63tdmCRJ6l43gX4OnYllrmx+ngHO7mVRkiRperoZ5f5dYFUfatEIc/S8JA3WTgM9yU8B7wIWTTy+qk7sXVmSJGk6uhnc9hngw8DHgOd6W44kSZqJbgJ9W1VduvPDupdkHzp/IPwMnSll3wrcT+ce/SJgE3BmVf3brjyvJElt1c2guM8leXuSA5PsN/4zy/NeAtxYVa8EXgXcR+c+/dqqWgKsxfv2kiR1rZse+orm9+9P2FfAITM5YZKXASfQzAdfVc/SWQBmObCsOWwNcBvwnpmcQ5KkuaabUe6Ld/E5FwNbgU8keRWd77SfCxxQVY80xzwKHLCjFydZCawEWLhw4S4uTZKk0dTNXO57J3lvktXN9pIkp83inPOAo4BLq+pI4AVfi6uqolmudXtVtbqqllbV0rGxsVmUIUlSe3RzD/0TdCaWOa7Zfhj441mcczOwuapub7avphPwjyU5EKD5vWUW55AkaU7pJtAPraoLgR8AVNX36CyjOiNV9SjwrSSHNbtOAjYA1/H8/foVwLUzPYckSXNNN4Pink2yF80l8CSH0pn+dTbOAS5PsgfwIPAWOn9cXJXkLOAh4MxZnkOSpDmjm0D/I+BG4OAklwPH0wngGauqO4GlO3jqpNm8ryRJc1U3o9xvTrIeOIbOpfZzq+rxnlcmSZK61s0o97VV9a9VdUNVXV9VjydZ24/iJElSdybtoSfZE9gbmJ9kX54fCPdSYEEfapMkSV2a6pL7bwHvBF5OZ/KX8UB/CvjfPa5LkiRNw6SBXlWXAJckOaeqPtTHmiRJ0jR1MyjuQ0mO44XroX+qh3WNnEWrbhh0CZKkOWyngZ7kr4BDgTt5fj30Agx0SZKGRDffQ18KHN7Mry5JkoZQN1O/3gP8p14XIkmSZq6bHvp8YEOSrzBhyteqekPPqpIkSdPS7dSvkiRpiHUzyv2LSV4BLKmqLyTZG9it96VJkqRudTP162/SWbP8I82uBcBne1mUJEmanm4GxZ1NZ4W1pwCq6gHgP/ayKEmSND3dBPozVfXs+EaSeTRro0uSpOHQTaB/Mcl5wF5JXgd8Bvhcb8uSJEnT0U2grwK2AnfTWbDl88B7e1mUJEmanm5Guf8Q+Cjw0ST7AQc5a5z6Yar58TddcGofK5Gk4dfNKPfbkry0CfP1dIL94t6XJkmSutXNJfeXVdVTwH8BPlVVrwZO6m1ZkiRpOroJ9HlJDgTOBK7vcT2SJGkGugn09wM3ARur6qtJDgEe6G1ZkiRpOroZFPcZOl9VG99+EPiVXhYlSZKmp5seuiRJGnIGuiRJLdDN8qli6u9ES5I0aN18D/29Ex7/RG/LkSRJMzFpoCd5T5JjgTMm7P6/vS9JkiRN11SX3L8B/FfgkCR/12zvn+Swqrq/L9VJkqSuTHXJ/QngPGAjsAy4pNm/KsmXZ3viJLsl+VqS65vtxUluT7IxyZVJ9pjtOSRJmium6qH/IvA+4FDgIuAu4LtV9ZZddO5zgfuAlzbbHwQurqpPJ/kwcBZw6S46l4aUgw0ladeYtIdeVedV1UnAJuCvgN2AsSR/n2RW66EnOQg4FfhYsx3gRODq5pA1wOmzOYckSXNJN19bu6mq1gHrkrytql6TZP4sz/vnwLuBlzTb+wNPVNW2ZnszsGBHL0yyElgJsHDhwlmWoVHl0qqS9ON2+rW1qnr3hM03N/sen+kJk5wGbKmq9TN5fVWtrqqlVbV0bGxspmVIktQq05pYpqq+vgvOeTzwhiSnAHvSuYd+CbBPknlNL/0g4OFdcC7NQfbeJc1FfZ/6tar+oKoOqqpFwJuAv62qXwNu5fnvvK8Aru13bZIkjaphmsv9PcDvJtlI5576ZQOuR5KkkTHQudyr6jbgtubxg8DRg6xHkqRRNUw9dEmSNEMGuiRJLWCgS5LUAga6JEktYKBLktQCBrokSS1goEuS1AIGuiRJLWCgS5LUAga6JEktYKBLktQCBrokSS1goEuS1AIGuiRJLTDQ5VOlUbJo1Q2TPrfpglP7WIkkvZA9dEmSWsBAlySpBQx0SZJawHvo0gRT3SeXpGFmD12SpBYw0CVJagEvuUu7gF9pkzRo9tAlSWoBA12SpBYw0CVJagHvoWtO8WtpktrKHrokSS1gD30Ce2+SpFFlD12SpBYw0CVJaoG+B3qSg5PcmmRDknuTnNvs3y/JLUkeaH7v2+/aJEkaVYPooW8Dfq+qDgeOAc5OcjiwClhbVUuAtc22JEnqQt8Dvaoeqao7msffAe4DFgDLgTXNYWuA0/tdmyRJo2qgo9yTLAKOBG4HDqiqR5qnHgUOmOQ1K4GVAAsXLux9kdIsOc+7pH4Y2KC4JC8G/hp4Z1U9NfG5qiqgdvS6qlpdVUuraunY2FgfKpUkafgNpIeeZHc6YX55VV3T7H4syYFV9UiSA4Etg6hNGhb27CVNxyBGuQe4DLivqi6a8NR1wIrm8Qrg2n7XJknSqBpED/144DeAu5Pc2ew7D7gAuCrJWcBDwJkDqE2SpJHU90Cvqr8HMsnTJ/WzFkmS2sK53KUBmun6Ad5fl7Q9p36VJKkFDHRJklrAQJckqQUMdEmSWsBAlySpBQx0SZJawECXJKkFDHRJklrAQJckqQWcKU6aQ3Y2M52zzEmjyx66JEktYA9dUk8577zUH/bQJUlqAQNdkqQWMNAlSWoBA12SpBYw0CVJagEDXZKkFjDQJUlqAQNdkqQWcGIZSUPJCWmk6bGHLklSC9hDl1pmZwuwDNP79qpWaS6yhy5JUgvYQ5f0I/aYpdFlD12SpBawhy6pVXZ2lcER8more+iSJLWAPXRJI2c29/pH5fvtg6hzVNpGOzZUPfQkJye5P8nGJKsGXY8kSaNiaHroSXYD/hJ4HbAZ+GqS66pqw2ArkzRXzLTnP1XvdRDf3+93PTM10ysCvRon0Yt6+nllY5h66EcDG6vqwap6Fvg0sHzANUmSNBJSVYOuAYAkZwAnV9V/b7Z/A3h1Vb1ju+NWAiubzcOA+5vH84HH+1TuqLFtJmfbTM62mZxtMzXbZ3KzbZtXVNXYjp4Ymkvu3aqq1cDq7fcnWVdVSwdQ0tCzbSZn20zOtpmcbTM122dyvWybYbrk/jBw8ITtg5p9kiRpJ4Yp0L8KLEmyOMkewJuA6wZckyRJI2FoLrlX1bYk7wBuAnYDPl5V907jLV5wGV4/YttMzraZnG0zOdtmarbP5HrWNkMzKE6SJM3cMF1ylyRJM2SgS5LUAiMf6E4X++OSfDzJliT3TNi3X5JbkjzQ/N53kDUOQpKDk9yaZEOSe5Oc2+yf820DkGTPJF9J8vWmff5ns39xktubz9eVzYDVOSnJbkm+luT6Ztu2AZJsSnJ3kjuTrGv2+bkCkuyT5Ook30hyX5Jje9k2Ix3oE6aL/SXgcOBXkxw+2KoG7pPAydvtWwWsraolwNpme67ZBvxeVR0OHAOc3fy3Ytt0PAOcWFWvAo4ATk5yDPBB4OKq+kng34CzBljjoJ0L3Ddh27Z53s9X1RETvl/t56rjEuDGqnol8Co6//30rG1GOtBxutgXqKovAd/ebvdyYE3zeA1wel+LGgJV9UhV3dE8/g6dD9YCbBsAquPpZnP35qeAE4Grm/1ztn2SHAScCnys2Q62zVTm/OcqycuAE4DLAKrq2ap6gh62zagH+gLgWxO2Nzf79OMOqKpHmsePAgcMsphBS7IIOBK4HdvmR5pLyncCW4BbgP8HPFFV25pD5vLn68+BdwM/bLb3x7YZV8DNSdY3U3ODnyuAxcBW4BPNrZqPJXkRPWybUQ90TVN1vqc4Z7+rmOTFwF8D76yqpyY+N9fbpqqeq6oj6MzSeDTwygGXNBSSnAZsqar1g65lSL2mqo6ic+vz7CQnTHxyDn+u5gFHAZdW1ZHAd9nu8vqubptRD3Sni+3OY0kOBGh+bxlwPQORZHc6YX55VV3T7LZtttNcFrwVOBbYJ8n4BFRz9fN1PPCGJJvo3NY7kc69UdsGqKqHm99bgL+h88egn6vOVZvNVXV7s301nYDvWduMeqA7XWx3rgNWNI9XANcOsJaBaO55XgbcV1UXTXhqzrcNQJKxJPs0j/cCXkdnnMGtwBnNYXOyfarqD6rqoKpaROf/MX9bVb+GbUOSFyV5yfhj4PXAPfi5oqoeBb6V5LBm10nABnrYNiM/U1ySU+jc3xqfLvYDAy5poJJcASyjs0TfY8D5wGeBq4CFwEPAmVW1/cC5VkvyGuDvgLt5/j7oeXTuo8/ptgFI8rN0BujsRucP/auq6v1JDqHTK90P+Brw61X1zOAqHawky4B3VdVptg00bfA3zeY84P9U1QeS7I+fK5IcQWcg5R7Ag8BbaD5f9KBtRj7QJUnS6F9ylyRJGOiSJLWCgS5JUgsY6JIktYCBLklSCxjo0hBK8ofNqmd3NatYvXqG73NE89XOvkuyaOKqf7vwfZclOW7C9ieTnDHVa6S5YN7OD5HUT0mOBU4DjqqqZ5LMp/M91pk4AlgKfH5X1TcElgFPA18ecB3SULGHLg2fA4HHxycpqarHq+pfAJL8XJIvNgth3DRhCsnbknywWdP8n5K8tpk98f3AG5te/hubmb0+3hz3tSTLm9e/Ock1SW5s1mm+cLyYJCcnuSOdtdLXNvt2+D6TaRZ++dMkX22uOvxWs39ZU/v4mtGXN7P6keSUZt/6JH+R5PpmYZ3/AfxO8296bXOKE5J8OcmD9tY1V9lDl4bPzcD7kvwT8AXgyqr6YjMX/YeA5VW1NckbgQ8Ab21eN6+qjm4usZ9fVb+Q5H3A0qp6B0CSP6Ezdelbm6lev5LkC83rj6CzCt0zwP1JPgT8O/BR4ISq+maS/Zpj/3BH71NV353k33QW8GRV/eckPwH8Q5Kbm+eOBH4a+BfgH4Djk6wDPjLhvFcAVNWmJB8Gnq6qP2v+TWfR+SPoNXQWlLmO55c1leYMA10aMlX1dJKfA14L/DxwZZJVwDrgZ4Bbmk7sbsAjE146vuDMemDRJG//ejoLjbyr2d6TzhSUAGur6kmAJBuAVwD7Al+qqm82tX17J+9z3xTn/dkJveeXAUuAZ4GvVNXm5rx3NrU/DTw4fl7gCmAlk/tsVf0Q2JBkLi7VKRno0jCqqueA24DbktxNZxGH9cC9VXXsJC8bn0f8OSb/bAf4laq6/8d2dgbdTZyHfKr3mPR9dnL8OVV103bnXTbN805m4ntkBq+XRp730KUhk+SwJEsm7DqCziIO9wNjzaA5kuye5Kd38nbfAV4yYfsm4JwJ96mP3Mnr/5HO/enFzfHjl9yn+z43AW9rbhuQ5KfSWZ1rMvcDhzT3zAHeOMW/SRIGujSMXgysSbIhyV3A4cAfVdWzdJbr/GCSrwN3AsdN8T7QWeLz8PFBccD/AnYH7kpyb7M9qaraSudS9zXNOa9snprW+9BZcWoDcEfzVbaPMEVPvKq+D7wduDHJejoh/mTz9OeAX95uUJw057namqShlOTFzXiCAH8JPFBVFw+6LmlY2UOXNKx+sxkkdy+dQXQfGXA90lCzhy5JUgvYQ5ckqQUMdEmSWsBAlySpBQx0SZJawECXJKkF/j8zLz9LT0wUlwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fuFTJqzluVR"
      },
      "source": [
        "# Data Encoding and Padding for Latin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emw_ViT6malT",
        "outputId": "cc3f8ac5-3322-4a1e-ccc8-150e593c92df"
      },
      "source": [
        "tokens = {token for sentence in X_latin_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_latin_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'edoctus', 'servitio', 'mysterium', 'hesterno', 'clavem', 'adiudicauit', 'homine', 'conspici', 'impertiente', 'plenam', 'cervice', 'manus', 'contumacius', 'patres']\n",
            "['CCONJ', 'PUNCT', 'SCONJ', 'VERB', 'PRON', 'ADJ', 'NOUN', 'NUM', 'X', 'PROPN', 'INTJ', 'ADP', 'ADV', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X1XUvWnmcxb",
        "outputId": "247b953f-60ae-4044-d355-5f511b531154"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_latin_train[:5], y_latin_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3307, 4030, 2306, 2955, 3232, 1576,  691, 1576, 6469, 1799, 4128, 5630,\n",
            "         1576, 4737, 2102, 3685, 2704, 4332, 3142, 4976],\n",
            "        [5116, 4221, 1301, 1717, 2146, 4976, 6927, 6927, 6927, 6927, 6927, 6927,\n",
            "         6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
            "        [4643,  911,  306, 3937, 4976, 6927, 6927, 6927, 6927, 6927, 6927, 6927,\n",
            "         6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
            "        [3667, 5995, 6457,  655, 6054,  770, 3025, 4534, 6927, 6927, 6927, 6927,\n",
            "         6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
            "        [5487, 2066, 2197, 4976, 6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927,\n",
            "         6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927]])\n",
            "tensor([[ 4,  5,  2,  3,  6,  1,  3,  1, 12,  3,  5,  3,  1,  5,  0,  3,  4, 12,\n",
            "          3,  1],\n",
            "        [11,  6,  3,  3,  6,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "         13, 13],\n",
            "        [ 6,  3,  6,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "         13, 13],\n",
            "        [ 3,  3,  2,  3, 11,  4,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "         13, 13],\n",
            "        [ 0,  5,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "         13, 13]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttMYr5TLmfFt",
        "outputId": "a1bb7520-a8e7-4a47-9ac3-5cf4191fcd80"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_latin_train, y_latin_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3307, 4030, 2306, 2955, 3232, 1576,  691, 1576, 6469, 1799, 4128, 5630,\n",
              "          1576, 4737, 2102, 3685, 2704, 4332, 3142, 4976],\n",
              "         [5116, 4221, 1301, 1717, 2146, 4976, 6927, 6927, 6927, 6927, 6927, 6927,\n",
              "          6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
              "         [4643,  911,  306, 3937, 4976, 6927, 6927, 6927, 6927, 6927, 6927, 6927,\n",
              "          6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
              "         [3667, 5995, 6457,  655, 6054,  770, 3025, 4534, 6927, 6927, 6927, 6927,\n",
              "          6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927],\n",
              "         [5487, 2066, 2197, 4976, 6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927,\n",
              "          6927, 6927, 6927, 6927, 6927, 6927, 6927, 6927]], device='cuda:0'),\n",
              " tensor([[ 4,  5,  2,  3,  6,  1,  3,  1, 12,  3,  5,  3,  1,  5,  0,  3,  4, 12,\n",
              "           3,  1],\n",
              "         [11,  6,  3,  3,  6,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "          13, 13],\n",
              "         [ 6,  3,  6,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "          13, 13],\n",
              "         [ 3,  3,  2,  3, 11,  4,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "          13, 13],\n",
              "         [ 0,  5,  3,  1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "          13, 13]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INgd_jMEl8Hr"
      },
      "source": [
        "# Model results for Latin Training and Test Sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOxyVoSnwqa",
        "outputId": "536dd111-d64f-4b01-a69f-b74c43a054ce"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 16 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_latin_train, y_latin_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_latin_train,y_latin_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_latin_train,y_latin_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   7%|▋         | 6/84 [00:00<00:01, 58.51batch/s, accuracy=36.9, loss=1.71]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(6928, 32)\n",
            "  (lstm): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=14, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 84/84 [00:01<00:00, 49.48batch/s, accuracy=40, loss=1.27]\n",
            "Epoch 1: 100%|██████████| 84/84 [00:01<00:00, 48.57batch/s, accuracy=86.7, loss=0.366]\n",
            "Epoch 2: 100%|██████████| 84/84 [00:01<00:00, 48.36batch/s, accuracy=100, loss=0.0555]\n",
            "Epoch 3: 100%|██████████| 84/84 [00:01<00:00, 48.33batch/s, accuracy=100, loss=0.00979]\n",
            "Epoch 4: 100%|██████████| 84/84 [00:01<00:00, 49.56batch/s, accuracy=100, loss=0.00382]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1upNWl6Hl_iO"
      },
      "source": [
        "# Stored Loss Over Epochs Latin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QW0_cd5FoW5E",
        "outputId": "7cd3c19f-f142-41b2-8926-c838082bb67c"
      },
      "source": [
        "batch_size = 16\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = plt.subplot()\n",
        "ax.set_title(\"Plot for the (hopefully) decreasing loss over epochs\")\n",
        "ax.plot(model.training_loss, 'b-')\n",
        "ax.set_ylabel(\"Training Loss\", color='b')\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "# ax.set_yscale('log')\n",
        "ax.tick_params(axis='y', labelcolor='b')\n",
        "ax = ax.twinx()\n",
        "ax.plot(model.training_accuracy, 'r-')\n",
        "ax.set_ylabel(\"Accuracy [%]\", color='r')\n",
        "ax.tick_params(axis='y', labelcolor='r')\n",
        "a = list(ax.axis())\n",
        "a[2] = 0\n",
        "a[3] = 100\n",
        "ax.axis(a)\n",
        "t = np.arange(0, len(model.training_accuracy), len(X_latin_train)//batch_size+1)\n",
        "ax.set_xticks(ticks=t)\n",
        "ax.set_xticklabels(labels=np.arange(len(t)))\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkdpYOmKmC9X"
      },
      "source": [
        "# Test data Accuracy for Latin "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9-UrtXppI7_",
        "outputId": "2a640cba-af4a-4cd3-bb64-0f7f691e5b11"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 16 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_latin_test, y_latin_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 72.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0dQor4FP6aW"
      },
      "source": [
        "# Data Encoding and Padding for French "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Gf-Gopep-K",
        "outputId": "68f51f48-f639-4df9-9ae2-e076ae5f7de5"
      },
      "source": [
        "tokens = {token for sentence in X_french_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_french_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'Puis', '1993', 'Connu', 'Partie', 'Espérer', 'Remarquez', 'Adl', 'Las', 'Enjeu', 'Entré', 'Patrick', 'Costas', 'Télé', 'Attirés']\n",
            "['INTJ', 'NUM', 'ADV', 'PART', 'PUNCT', 'ADP', 'AUX', 'NOUN', 'ADJ', 'CCONJ', 'X', 'PROPN', 'SCONJ', 'PRON', None, 'VERB', 'DET', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4VYZzXeqS4",
        "outputId": "d38ff9de-e037-4d9a-b4c4-90e8dc8bd452"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_french_train[:5], y_french_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 516, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597],\n",
            "        [ 295, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256],\n",
            "        [1256,  322, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1597],\n",
            "        [ 174, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597],\n",
            "        [ 941, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
            "         1597, 1597, 1597, 1597, 1597, 1597, 1597]])\n",
            "tensor([[ 2,  4, 13,  2, 15, 12, 16,  8,  7,  5,  7,  5, 16,  7,  5,  7,  4, 15,\n",
            "         16,  7, 14,  5, 16,  1,  7,  4,  2,  6,  2, 15, 16,  8,  9, 16,  7,  4,\n",
            "         15, 16,  7,  4,  2, 15,  2, 16,  2,  8,  4, 17, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [ 2, 15, 13, 12, 16,  7,  6, 15,  2, 12, 16,  7,  8,  2, 15, 16,  7,  8,\n",
            "          9, 15,  4,  5, 16,  8,  7,  4, 12, 16,  7, 14,  5, 16,  7, 14,  5, 16,\n",
            "          7, 15,  5, 16,  7,  5, 16,  7, 13, 15,  5, 15, 16,  7,  8,  9, 14,  5,\n",
            "         16,  7, 15, 14,  5, 16,  7,  5, 16,  4, 11,  4,  4],\n",
            "        [14,  5, 16,  7,  4, 13, 13,  6, 15,  5, 16,  7, 14,  5, 16,  7, 14,  5,\n",
            "         16,  7,  8,  4, 13, 15, 16,  8,  7,  5,  7, 12, 16,  7, 14,  5, 16,  7,\n",
            "          8,  4,  4,  2,  8,  5, 16,  7,  8, 12,  5, 16,  7, 14,  5, 16,  7,  5,\n",
            "         16,  7,  5,  7, 14,  5, 16,  7,  8,  9,  8,  4, 17],\n",
            "        [16,  7, 13, 15,  2,  5, 15, 16,  7,  5, 16,  7,  5,  7, 13,  6,  2, 15,\n",
            "         16,  7,  5, 16,  7,  5, 15, 16,  7,  5,  7,  4, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [ 7, 14,  5, 16,  7,  4, 13, 13, 15,  5, 13, 13, 16,  7,  5,  7, 15,  5,\n",
            "         16,  8,  7, 16,  7,  8,  5,  1, 15,  5, 16,  7,  4,  7,  9, 16,  7,  4,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4wshZeogG9C",
        "outputId": "e45ac99b-16c2-4de7-b9df-4b28d9039390"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_french_train, y_french_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 516, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597],\n",
              "         [ 295, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256],\n",
              "         [1256,  322, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1597],\n",
              "         [ 174, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597],\n",
              "         [ 941, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256, 1256,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597,\n",
              "          1597, 1597, 1597, 1597, 1597, 1597, 1597]], device='cuda:0'),\n",
              " tensor([[ 2,  4, 13,  2, 15, 12, 16,  8,  7,  5,  7,  5, 16,  7,  5,  7,  4, 15,\n",
              "          16,  7, 14,  5, 16,  1,  7,  4,  2,  6,  2, 15, 16,  8,  9, 16,  7,  4,\n",
              "          15, 16,  7,  4,  2, 15,  2, 16,  2,  8,  4, 17, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
              "         [ 2, 15, 13, 12, 16,  7,  6, 15,  2, 12, 16,  7,  8,  2, 15, 16,  7,  8,\n",
              "           9, 15,  4,  5, 16,  8,  7,  4, 12, 16,  7, 14,  5, 16,  7, 14,  5, 16,\n",
              "           7, 15,  5, 16,  7,  5, 16,  7, 13, 15,  5, 15, 16,  7,  8,  9, 14,  5,\n",
              "          16,  7, 15, 14,  5, 16,  7,  5, 16,  4, 11,  4,  4],\n",
              "         [14,  5, 16,  7,  4, 13, 13,  6, 15,  5, 16,  7, 14,  5, 16,  7, 14,  5,\n",
              "          16,  7,  8,  4, 13, 15, 16,  8,  7,  5,  7, 12, 16,  7, 14,  5, 16,  7,\n",
              "           8,  4,  4,  2,  8,  5, 16,  7,  8, 12,  5, 16,  7, 14,  5, 16,  7,  5,\n",
              "          16,  7,  5,  7, 14,  5, 16,  7,  8,  9,  8,  4, 17],\n",
              "         [16,  7, 13, 15,  2,  5, 15, 16,  7,  5, 16,  7,  5,  7, 13,  6,  2, 15,\n",
              "          16,  7,  5, 16,  7,  5, 15, 16,  7,  5,  7,  4, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
              "         [ 7, 14,  5, 16,  7,  4, 13, 13, 15,  5, 13, 13, 16,  7,  5,  7, 15,  5,\n",
              "          16,  8,  7, 16,  7,  8,  5,  1, 15,  5, 16,  7,  4,  7,  9, 16,  7,  4,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL1UyJROQL7R"
      },
      "source": [
        "# Model Results for Training and Test sets French "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWEMkBM3k8yZ",
        "outputId": "ec9f3f46-06a7-4a82-9959-7acb904d7062"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 100 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_french_train, y_french_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_french_train,y_french_train,embedding_dim=100,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=74,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_french_train,y_french_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 5/147 [00:00<00:02, 49.39batch/s, accuracy=19.8, loss=2.4] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(1598, 100)\n",
            "  (lstm): LSTM(100, 74, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=148, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 917batch [00:14, 62.12batch/s, accuracy=31.1, loss=2.06]\n",
            "Epoch 1: 917batch [00:14, 62.79batch/s, accuracy=31.4, loss=2.03]\n",
            "Epoch 2: 917batch [00:14, 62.62batch/s, accuracy=31.4, loss=2.03]\n",
            "Epoch 3: 917batch [00:14, 62.64batch/s, accuracy=32.6, loss=2]\n",
            "Epoch 4: 917batch [00:14, 61.63batch/s, accuracy=31.4, loss=1.99]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTzMeGURQRC1"
      },
      "source": [
        "# Test Data Accuracy for French "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms15KEgLlVJ_",
        "outputId": "a800c9e5-fabe-48ea-df54-b00587bcd660"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 100 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_french_test, y_french_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 27.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYSDbQQXQbdu"
      },
      "source": [
        "# Data Encoding and Padding for Italian "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WxoXLCYhT8s",
        "outputId": "65e303eb-4f16-4948-ebea-eeabab644a67"
      },
      "source": [
        "l = np.asarray([len(x) for x in X_italian_train], dtype=np.int)\n",
        "plt.figure(figsize=(8, 4))\n",
        "x = np.unique(l)\n",
        "plt.bar(x, [np.sum(l==e) for e in x], width=1)\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"# sentences\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZo0mvJNgBAX",
        "outputId": "9b3f36fc-a777-4aee-cfbd-2b0200053953"
      },
      "source": [
        "tokens = {token for sentence in X_italian_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_italian_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'Augusto', 'distinto', '1993', 'lacerazioni', 'bandito', 'Polti', '+0,7%', 'tipicamente', 'infrangono', 'Signal', 'concessione', 'Csce', 'intendiamo', 'riferirsi']\n",
            "['INTJ', 'NUM', 'ADV', 'PART', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'X', 'ADJ', 'PROPN', 'SCONJ', 'CCONJ', 'PRON', None, 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HamRoInWgH3o",
        "outputId": "afa0a300-7583-415e-d666-1f0adc005ac3"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_italian_train[:5], y_italian_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[17597,  9683, 17190,  3236,  8581,  4164,  8581,   490,  9884, 10185,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168],\n",
            "        [ 7847, 14520, 21562, 10835,  4875, 22781,  1998,  2118,  8581, 22938,\n",
            "          9983,  8581, 18416,  8999, 18774, 14216, 20952,  1813, 18793, 18906,\n",
            "         12439,  9770,  8581, 17533, 15061, 14225, 17468, 11308,  8999, 16072,\n",
            "           502,  7242, 18906, 10671,  3581,  5014, 20290, 10579, 22938,  5878,\n",
            "         20494, 22934, 21742, 13291, 13274, 12439, 16875,  8581, 17533,  1696,\n",
            "          2118,  8581, 22938,  2482,  1861, 14575,  4225, 12709, 22934,  9268,\n",
            "         12525, 10101, 15658, 20973, 10185, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168],\n",
            "        [12214, 17351, 22934,  4854,  7356,  8581,  7004,  5835, 22441, 14216,\n",
            "         20952,  4854,  9029, 23077,  8581, 22781, 16317, 14575, 10671,  3129,\n",
            "          2118,  8581, 22938, 11490,  4225, 12046, 16488, 11608, 20494, 13581,\n",
            "         22934, 22781, 16298,  8581, 19611, 18247, 12164, 12525,  4854,  4050,\n",
            "           353,  8867,  8581,  4268, 10185, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168],\n",
            "        [22972, 11838,  8999,  2065,  8581, 19997, 22840, 14575, 10101, 10671,\n",
            "         12084, 13291, 22938, 19547, 12709, 13291,  4854, 21670,  2583, 20581,\n",
            "         13291, 10671, 19611, 21546, 22934,  4582, 13291, 10671,  9683, 13291,\n",
            "         10671, 10929,  8948, 17468, 11308, 15762, 12525,  6947, 18241, 18046,\n",
            "          8581,  4339, 17872, 13291,  8712, 17468, 18781,  5257, 12584, 17533,\n",
            "          8575,  4602, 13291,  8983, 18906, 19880,  9188,  4095, 22781, 10009,\n",
            "         23077,  8581, 22781, 17664,  9299, 13291, 10579,  4783,  7670, 13291,\n",
            "         22934, 12439, 19481,  8354,  8581,  4919, 12503,  8581, 10671, 12084,\n",
            "         13291, 12525,  8588, 10185],\n",
            "        [12214,  4050, 15063, 13291,  1217, 18906, 21910, 21348,  8999,  2840,\n",
            "          8553, 21669,  2118,  8581, 22938, 18046,  8581,  4919, 12525,  3235,\n",
            "         12164, 12525,  4854,  2555, 13291, 18793, 18906, 12439, 13645, 11612,\n",
            "          2762, 21910,  1518, 22934, 21612, 13180, 12525,  9578, 12503,  8581,\n",
            "         10671, 19997,   283, 17468, 16274, 10579, 14676, 22781, 15059, 17955,\n",
            "         21545,  8581,  4854, 23111,  8867, 10185, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
            "         23168, 23168, 23168, 23168]])\n",
            "tensor([[ 6, 17,  5, 17,  5, 17,  5, 11, 11,  4, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [15,  5,  6, 10, 17,  6, 17, 15,  5,  6, 17,  5, 17,  8,  8,  2,  2, 16,\n",
            "         15,  5,  6, 17,  5,  6, 10, 17, 14, 14,  8,  2, 16, 15,  5,  6, 10, 17,\n",
            "         15,  5,  6, 17, 10, 13, 10,  4, 16,  6, 17,  5,  6, 17, 15,  5,  6, 17,\n",
            "         16,  5, 17, 10, 13, 17,  5, 14, 14, 16,  4, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 6, 17, 13,  6, 17,  5, 17, 10,  8,  2,  2,  6, 17, 15,  5,  6, 17,  5,\n",
            "          6, 17, 15,  5,  6, 10, 17,  4,  2,  2, 10,  4, 13,  6, 17,  5, 17, 10,\n",
            "         15,  5,  6, 17, 10, 10,  5, 17,  4, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 6, 10,  8, 17,  5, 17, 10,  5, 14,  6, 17,  4,  6, 17, 10,  4,  6, 17,\n",
            "         10, 10,  4,  6, 17, 10, 13, 10,  4,  6, 17,  4,  6, 17, 10, 14, 14, 16,\n",
            "          5, 17,  5, 17,  5, 10, 17,  4, 13, 14,  2,  8, 16,  6, 10, 17,  4, 16,\n",
            "          5, 17, 10,  5,  6, 17, 15,  5,  6, 17, 10,  4,  5, 17, 10,  4, 13,  6,\n",
            "         10, 17,  5, 17, 15,  5,  6, 17,  4,  5, 11,  4],\n",
            "        [ 6, 17, 10,  4, 12,  5,  6, 17,  8,  8, 17, 10, 15,  5,  6, 17,  5, 17,\n",
            "          5, 17, 15,  5,  6, 17,  4, 15,  5,  6, 14, 16, 16,  6, 10, 13, 10, 17,\n",
            "          5, 14, 15,  5,  6, 17, 17, 14, 16,  5, 16,  6, 17, 10, 15,  5,  6, 17,\n",
            "         10,  4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6rSgCM3mHWb",
        "outputId": "8896aa06-701b-4fc6-f000-50f71cbc37af"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_italian_train, y_italian_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[17597,  9683, 17190,  3236,  8581,  4164,  8581,   490,  9884, 10185,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168],\n",
              "         [ 7847, 14520, 21562, 10835,  4875, 22781,  1998,  2118,  8581, 22938,\n",
              "           9983,  8581, 18416,  8999, 18774, 14216, 20952,  1813, 18793, 18906,\n",
              "          12439,  9770,  8581, 17533, 15061, 14225, 17468, 11308,  8999, 16072,\n",
              "            502,  7242, 18906, 10671,  3581,  5014, 20290, 10579, 22938,  5878,\n",
              "          20494, 22934, 21742, 13291, 13274, 12439, 16875,  8581, 17533,  1696,\n",
              "           2118,  8581, 22938,  2482,  1861, 14575,  4225, 12709, 22934,  9268,\n",
              "          12525, 10101, 15658, 20973, 10185, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168],\n",
              "         [12214, 17351, 22934,  4854,  7356,  8581,  7004,  5835, 22441, 14216,\n",
              "          20952,  4854,  9029, 23077,  8581, 22781, 16317, 14575, 10671,  3129,\n",
              "           2118,  8581, 22938, 11490,  4225, 12046, 16488, 11608, 20494, 13581,\n",
              "          22934, 22781, 16298,  8581, 19611, 18247, 12164, 12525,  4854,  4050,\n",
              "            353,  8867,  8581,  4268, 10185, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168],\n",
              "         [22972, 11838,  8999,  2065,  8581, 19997, 22840, 14575, 10101, 10671,\n",
              "          12084, 13291, 22938, 19547, 12709, 13291,  4854, 21670,  2583, 20581,\n",
              "          13291, 10671, 19611, 21546, 22934,  4582, 13291, 10671,  9683, 13291,\n",
              "          10671, 10929,  8948, 17468, 11308, 15762, 12525,  6947, 18241, 18046,\n",
              "           8581,  4339, 17872, 13291,  8712, 17468, 18781,  5257, 12584, 17533,\n",
              "           8575,  4602, 13291,  8983, 18906, 19880,  9188,  4095, 22781, 10009,\n",
              "          23077,  8581, 22781, 17664,  9299, 13291, 10579,  4783,  7670, 13291,\n",
              "          22934, 12439, 19481,  8354,  8581,  4919, 12503,  8581, 10671, 12084,\n",
              "          13291, 12525,  8588, 10185],\n",
              "         [12214,  4050, 15063, 13291,  1217, 18906, 21910, 21348,  8999,  2840,\n",
              "           8553, 21669,  2118,  8581, 22938, 18046,  8581,  4919, 12525,  3235,\n",
              "          12164, 12525,  4854,  2555, 13291, 18793, 18906, 12439, 13645, 11612,\n",
              "           2762, 21910,  1518, 22934, 21612, 13180, 12525,  9578, 12503,  8581,\n",
              "          10671, 19997,   283, 17468, 16274, 10579, 14676, 22781, 15059, 17955,\n",
              "          21545,  8581,  4854, 23111,  8867, 10185, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168, 23168,\n",
              "          23168, 23168, 23168, 23168]], device='cuda:0'),\n",
              " tensor([[ 6, 17,  5, 17,  5, 17,  5, 11, 11,  4, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [15,  5,  6, 10, 17,  6, 17, 15,  5,  6, 17,  5, 17,  8,  8,  2,  2, 16,\n",
              "          15,  5,  6, 17,  5,  6, 10, 17, 14, 14,  8,  2, 16, 15,  5,  6, 10, 17,\n",
              "          15,  5,  6, 17, 10, 13, 10,  4, 16,  6, 17,  5,  6, 17, 15,  5,  6, 17,\n",
              "          16,  5, 17, 10, 13, 17,  5, 14, 14, 16,  4, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [ 6, 17, 13,  6, 17,  5, 17, 10,  8,  2,  2,  6, 17, 15,  5,  6, 17,  5,\n",
              "           6, 17, 15,  5,  6, 10, 17,  4,  2,  2, 10,  4, 13,  6, 17,  5, 17, 10,\n",
              "          15,  5,  6, 17, 10, 10,  5, 17,  4, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [ 6, 10,  8, 17,  5, 17, 10,  5, 14,  6, 17,  4,  6, 17, 10,  4,  6, 17,\n",
              "          10, 10,  4,  6, 17, 10, 13, 10,  4,  6, 17,  4,  6, 17, 10, 14, 14, 16,\n",
              "           5, 17,  5, 17,  5, 10, 17,  4, 13, 14,  2,  8, 16,  6, 10, 17,  4, 16,\n",
              "           5, 17, 10,  5,  6, 17, 15,  5,  6, 17, 10,  4,  5, 17, 10,  4, 13,  6,\n",
              "          10, 17,  5, 17, 15,  5,  6, 17,  4,  5, 11,  4],\n",
              "         [ 6, 17, 10,  4, 12,  5,  6, 17,  8,  8, 17, 10, 15,  5,  6, 17,  5, 17,\n",
              "           5, 17, 15,  5,  6, 17,  4, 15,  5,  6, 14, 16, 16,  6, 10, 13, 10, 17,\n",
              "           5, 14, 15,  5,  6, 17, 17, 14, 16,  5, 16,  6, 17, 10, 15,  5,  6, 17,\n",
              "          10,  4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTtMoGzhQio1"
      },
      "source": [
        "# Model Results for Training and Test Sets Italian  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TrfU5E2mZzY",
        "outputId": "49b829ba-f9fe-458d-ea3a-fdbf185f4e4e"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 100 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_italian_train, y_italian_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_italian_train,y_italian_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_italian_train,y_italian_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   1%|          | 6/517 [00:00<00:09, 56.30batch/s, accuracy=46.9, loss=1.85]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(23169, 32)\n",
            "  (lstm): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=19, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 517/517 [00:08<00:00, 64.02batch/s, accuracy=88.9, loss=0.34]\n",
            "Epoch 1: 100%|██████████| 517/517 [00:08<00:00, 64.11batch/s, accuracy=95.5, loss=0.149]\n",
            "Epoch 2: 100%|██████████| 517/517 [00:08<00:00, 64.21batch/s, accuracy=98.9, loss=0.0441]\n",
            "Epoch 3: 100%|██████████| 517/517 [00:08<00:00, 64.17batch/s, accuracy=99.7, loss=0.0213]\n",
            "Epoch 4: 100%|██████████| 517/517 [00:08<00:00, 63.39batch/s, accuracy=99.5, loss=0.02]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trdBRj8TQj17"
      },
      "source": [
        "# Test Data Accuracy for Italian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AXBn9H4my2v",
        "outputId": "5e03d423-77a2-4d1b-a229-bd9042428b20"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 100 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_italian_test, y_italian_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 92.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW0zdOcSQt-8"
      },
      "source": [
        "# Data Encoding and Padding for Dutch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeptNK9Ygicc",
        "outputId": "c3c54e4d-bb94-4af2-dc33-704b8b8fcb0d"
      },
      "source": [
        "tokens = {token for sentence in X_dutch_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_dutch_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'onderscheiden', 'Wereldrecords', 'Sugiyama', '1993', 'bewind', 'oude', 'afgerekend', 'verplichte', 'Décoratives', 'voort', 'uitgenodigd', 'Gheynst', 'hoog', 'garde']\n",
            "['INTJ', 'NUM', 'ADV', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'X', 'ADJ', 'PROPN', 'CCONJ', 'PRON', 'SCONJ', 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtB3TVWygn8v",
        "outputId": "c21f5fb2-e5cd-4ec6-c3cd-5271abe35c3f"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_dutch_train[:5], y_dutch_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5877, 13397,  4313,  6553,  6459, 12043,  4313,  1036,  7777,  2875,\n",
            "          2496,  6890,  5990,  9659, 11570,  4513, 13475, 13475, 13475, 13475,\n",
            "         13475],\n",
            "        [ 5877,  6970, 12527,  6134, 12259, 11615,  6553,  6903, 11537, 12527,\n",
            "           201,  1036,  7777, 11878,  5640,  2496,  6890,  5990,  9659, 12017,\n",
            "          4513],\n",
            "        [ 5877,  8505,  4055,  9079,  2496,  6878,  6459,  6005,  4055,  7569,\n",
            "          3849,  8031, 11338, 11682, 12597, 10004,  4055,  1930,  4055,  9508,\n",
            "         10229],\n",
            "        [  175,  2900,  7072,  9448,  6322,  5008,  6459,  3010,  4055, 12597,\n",
            "         12921,  6553, 12597,  9883,  4055,  6459, 13235, 10229, 13475, 13475,\n",
            "         13475],\n",
            "        [10740,  3565,  9448, 10206, 11519,   560,  5226, 10229, 13475, 13475,\n",
            "         13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475,\n",
            "         13475]])\n",
            "tensor([[ 5,  9, 15, 11,  5,  9, 15,  3,  5,  9,  7, 10, 15,  6,  1,  3, 16, 16,\n",
            "         16, 16, 16],\n",
            "        [ 5, 15,  4,  5,  9, 15, 11,  9, 15,  4, 15,  3,  5,  9, 15,  7, 10, 15,\n",
            "          6,  1,  3],\n",
            "        [ 5, 15,  4, 10,  7,  2,  5, 15,  4, 10,  3, 11,  7,  9,  5, 15,  4, 10,\n",
            "         10, 10,  3],\n",
            "        [10, 10, 10,  3, 15,  4,  5, 15,  4,  5, 15, 11,  5, 15,  4,  5, 14,  3,\n",
            "         16, 16, 16],\n",
            "        [ 9, 15,  3,  9, 15,  9, 15,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "         16, 16, 16]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVePKa4nglhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7fddbe-b193-4152-dbb5-2e72bb4268a1"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_dutch_train, y_dutch_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 5877, 13397,  4313,  6553,  6459, 12043,  4313,  1036,  7777,  2875,\n",
              "           2496,  6890,  5990,  9659, 11570,  4513, 13475, 13475, 13475, 13475,\n",
              "          13475],\n",
              "         [ 5877,  6970, 12527,  6134, 12259, 11615,  6553,  6903, 11537, 12527,\n",
              "            201,  1036,  7777, 11878,  5640,  2496,  6890,  5990,  9659, 12017,\n",
              "           4513],\n",
              "         [ 5877,  8505,  4055,  9079,  2496,  6878,  6459,  6005,  4055,  7569,\n",
              "           3849,  8031, 11338, 11682, 12597, 10004,  4055,  1930,  4055,  9508,\n",
              "          10229],\n",
              "         [  175,  2900,  7072,  9448,  6322,  5008,  6459,  3010,  4055, 12597,\n",
              "          12921,  6553, 12597,  9883,  4055,  6459, 13235, 10229, 13475, 13475,\n",
              "          13475],\n",
              "         [10740,  3565,  9448, 10206, 11519,   560,  5226, 10229, 13475, 13475,\n",
              "          13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475, 13475,\n",
              "          13475]], device='cuda:0'),\n",
              " tensor([[ 5,  9, 15, 11,  5,  9, 15,  3,  5,  9,  7, 10, 15,  6,  1,  3, 16, 16,\n",
              "          16, 16, 16],\n",
              "         [ 5, 15,  4,  5,  9, 15, 11,  9, 15,  4, 15,  3,  5,  9, 15,  7, 10, 15,\n",
              "           6,  1,  3],\n",
              "         [ 5, 15,  4, 10,  7,  2,  5, 15,  4, 10,  3, 11,  7,  9,  5, 15,  4, 10,\n",
              "          10, 10,  3],\n",
              "         [10, 10, 10,  3, 15,  4,  5, 15,  4,  5, 15, 11,  5, 15,  4,  5, 14,  3,\n",
              "          16, 16, 16],\n",
              "         [ 9, 15,  3,  9, 15,  9, 15,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "          16, 16, 16]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXIV4uKDQ17P"
      },
      "source": [
        "# Model Results for Training and Test Sets Dutch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0i8Z1zMzBSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583710ec-4af8-4224-867c-f2d42b2ca88a"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 100 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_dutch_train, y_dutch_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_dutch_train,y_dutch_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_dutch_train,y_dutch_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  20%|██        | 10/50 [00:00<00:00, 90.22batch/s, accuracy=55.2, loss=1.41]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(13476, 32)\n",
            "  (lstm): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=17, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 310batch [00:03, 82.96batch/s, accuracy=81, loss=0.52]\n",
            "Epoch 1: 310batch [00:03, 84.83batch/s, accuracy=92.5, loss=0.215]\n",
            "Epoch 2: 310batch [00:03, 85.81batch/s, accuracy=98, loss=0.0609]\n",
            "Epoch 3: 310batch [00:03, 84.63batch/s, accuracy=99.5, loss=0.0265]\n",
            "Epoch 4: 310batch [00:03, 85.33batch/s, accuracy=100, loss=0.00762]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3dwbLFeQ9Be"
      },
      "source": [
        "# Test data Accuracy for Dutch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh3rymQmowwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df7514b-ff09-4066-fc5b-bbb509723d5d"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 100 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_dutch_test, y_dutch_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 86.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAASZBTcQ-5M"
      },
      "source": [
        "#Data Encoding and Padding for English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlLgxNEng7jr",
        "outputId": "d1f7f44a-8622-481c-af03-deeb89ba79d0"
      },
      "source": [
        "tokens = {token for sentence in X_english_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_english_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', '1993', 'Fascist', 'prominent', 'favourite', 'Troy', 'frosting', 'aware', 'wherein', '!!!!!!!!!!!!!!!', 'Dentistry', 'secluded', 'listings', \"Diego's\", 'Percell,']\n",
            "['INTJ', 'NUM', None, 'ADV', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'CCONJ', 'ADJ', 'X', 'PROPN', 'SCONJ', 'PRON', 'PART', 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zquCHBpkg76P",
        "outputId": "3ae7463b-fc95-4002-98c2-f991a638ebdf"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_english_train[:5], y_english_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3580,  1734,   638,  3489, 10614,  3989,  7798,  8759,  9275, 13558,\n",
            "          1734,  4133, 11313,  4263, 10569,  2195,  4263, 19758, 10686,  4263,\n",
            "          2732, 11417,  7206, 11313,  7497,  4263, 12568, 13145,  8731, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817],\n",
            "        [ 3586,  3424, 18728, 11417,  9050, 10513, 11933,  7433, 14780, 15948,\n",
            "          6665, 14988,  6516, 11966,  2836, 14671,  8731,  3093, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817],\n",
            "        [ 9648,  3489, 10055, 15433, 18735,  7459, 13978,  8496, 14694, 17240,\n",
            "          8000,  4778, 11951,  8616, 10686, 15163,  8731, 19817, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817],\n",
            "        [13035, 11417,  2126,  2575,  2750, 19144,  6120,  6634,  4164, 11417,\n",
            "          4263, 15520, 11417,  4263,  7294,  8790, 19817, 19817, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
            "         19817, 19817, 19817, 19817, 19817, 19817],\n",
            "        [16232,  9254, 10686, 13541,  5888,  8468,  2836,  4263, 17752,  1643,\n",
            "         11313, 13125, 18051, 14355, 14780, 15624,  8685,   646, 17982,  7155,\n",
            "         17500, 12556,  2195,  9050, 19730, 18421,  6324, 11417,  4263,  8063,\n",
            "         16676, 18251, 10686,  4263,  1593,  8731]])\n",
            "tensor([[12,  4, 12,  4, 10, 17, 16, 12, 12, 12,  4, 12,  4,  6, 17,  5,  6, 17,\n",
            "          5,  6, 17,  5, 12,  4,  5,  6, 10, 17,  4, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 4,  6, 17,  5,  6, 10, 17,  8,  8, 16, 14, 17,  5, 17, 15, 16,  4,  4,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [12,  4, 10, 17, 16, 13, 14,  8, 16,  5,  1, 10, 17, 16,  5, 12,  4, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 1,  5, 14,  8,  8, 16,  5,  1, 17,  5,  6, 12,  5,  6, 12,  4, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [ 6, 12,  5, 12,  8, 10,  5,  6, 12, 12,  4,  3, 14,  8, 16, 13, 16, 12,\n",
            "         12, 12,  3, 16,  5,  6, 10, 17, 17,  5,  6, 12, 17,  3,  5,  6, 17,  4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KewFhNFooWD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef63e0c6-64a3-4112-a518-910fd0431993"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_english_train, y_english_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3580,  1734,   638,  3489, 10614,  3989,  7798,  8759,  9275, 13558,\n",
              "           1734,  4133, 11313,  4263, 10569,  2195,  4263, 19758, 10686,  4263,\n",
              "           2732, 11417,  7206, 11313,  7497,  4263, 12568, 13145,  8731, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817],\n",
              "         [ 3586,  3424, 18728, 11417,  9050, 10513, 11933,  7433, 14780, 15948,\n",
              "           6665, 14988,  6516, 11966,  2836, 14671,  8731,  3093, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817],\n",
              "         [ 9648,  3489, 10055, 15433, 18735,  7459, 13978,  8496, 14694, 17240,\n",
              "           8000,  4778, 11951,  8616, 10686, 15163,  8731, 19817, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817],\n",
              "         [13035, 11417,  2126,  2575,  2750, 19144,  6120,  6634,  4164, 11417,\n",
              "           4263, 15520, 11417,  4263,  7294,  8790, 19817, 19817, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817, 19817,\n",
              "          19817, 19817, 19817, 19817, 19817, 19817],\n",
              "         [16232,  9254, 10686, 13541,  5888,  8468,  2836,  4263, 17752,  1643,\n",
              "          11313, 13125, 18051, 14355, 14780, 15624,  8685,   646, 17982,  7155,\n",
              "          17500, 12556,  2195,  9050, 19730, 18421,  6324, 11417,  4263,  8063,\n",
              "          16676, 18251, 10686,  4263,  1593,  8731]], device='cuda:0'),\n",
              " tensor([[12,  4, 12,  4, 10, 17, 16, 12, 12, 12,  4, 12,  4,  6, 17,  5,  6, 17,\n",
              "           5,  6, 17,  5, 12,  4,  5,  6, 10, 17,  4, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [ 4,  6, 17,  5,  6, 10, 17,  8,  8, 16, 14, 17,  5, 17, 15, 16,  4,  4,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [12,  4, 10, 17, 16, 13, 14,  8, 16,  5,  1, 10, 17, 16,  5, 12,  4, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [ 1,  5, 14,  8,  8, 16,  5,  1, 17,  5,  6, 12,  5,  6, 12,  4, 18, 18,\n",
              "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
              "         [ 6, 12,  5, 12,  8, 10,  5,  6, 12, 12,  4,  3, 14,  8, 16, 13, 16, 12,\n",
              "          12, 12,  3, 16,  5,  6, 10, 17, 17,  5,  6, 12, 17,  3,  5,  6, 17,  4]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ki3i_a2SYFy"
      },
      "source": [
        "# Model Results for Training and Test Sets English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxnfQA4yxKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab961782-d98f-4354-bd88-6dbdc0677a68"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 16 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_english_train, y_english_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_english_train,y_english_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_english_train,y_english_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   1%|          | 7/713 [00:00<00:10, 67.35batch/s, accuracy=40.2, loss=1.89]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(19818, 32)\n",
            "  (lstm): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=19, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 713/713 [00:09<00:00, 78.29batch/s, accuracy=95.1, loss=0.197]\n",
            "Epoch 1: 100%|██████████| 713/713 [00:09<00:00, 78.93batch/s, accuracy=95.5, loss=0.149]\n",
            "Epoch 2: 100%|██████████| 713/713 [00:09<00:00, 78.45batch/s, accuracy=97.3, loss=0.11]\n",
            "Epoch 3: 100%|██████████| 713/713 [00:09<00:00, 78.63batch/s, accuracy=98.2, loss=0.0512]\n",
            "Epoch 4: 100%|██████████| 713/713 [00:09<00:00, 79.02batch/s, accuracy=98.2, loss=0.0685]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beSxHEIeSvnS"
      },
      "source": [
        "# Test data Accuracy for English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zttp55mlob5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456166c8-0e6c-4e20-fd9b-e2e5813eb342"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 16\n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_english_test, y_english_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 89.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVdHqXbxR9_f"
      },
      "source": [
        "# Data Encoding and Padding for German "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ROu_Nj60Sgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e4b0f3-49e8-401a-f696-28f6f178e2b4"
      },
      "source": [
        "tokens = {token for sentence in X_german_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_german_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'Mannschaftsfahren', 'heraus', '1993', 'Nachwuchsmangel', 'Binnenkolonisation', 'Karatschew', 'Teleroboter', 'davonkommen', 'Regierungsvertreter', 'Signal', 'vorgelagerte', 'abgelegensten', 'Verpuppung', 'Schuhmodell']\n",
            "['NUM', 'ADV', 'PART', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'X', 'ADJ', 'PROPN', 'SCONJ', 'CCONJ', 'PRON', None, 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vLfUBmz0S7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b797b7a-06c6-4e59-d79a-db7f6549c1e6"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_german_train[:5], y_german_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[29317, 16867, 13175, 28347, 28852, 36008,  8163,  5647, 28347, 32810,\n",
            "         20632, 12978, 17400, 14183, 15813, 21689, 49511, 49511, 49511, 49511,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511],\n",
            "        [29464, 35754, 47506, 18065,   842, 49422, 26703, 23266,  4671, 21689,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511],\n",
            "        [42235, 46126, 28347,  4886, 34973, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511],\n",
            "        [ 9567, 16536, 14062, 39112, 39026, 49119, 17224,  8163, 18024, 45969,\n",
            "          5628, 47919,  5628, 26703,  8163,   746,  5628,  3810, 19682,  5628,\n",
            "         49422, 26703, 23266, 44656, 20227,  5723, 14420, 24658, 36333, 37633,\n",
            "         21840],\n",
            "        [33352, 46769,  8163, 32609, 28347, 29355, 38328,   743, 29355, 10944,\n",
            "         13513, 32021, 47506, 10762, 24319,  7522, 27657,  5723, 24949, 21689,\n",
            "         49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
            "         49511]])\n",
            "tensor([[ 1,  9, 16,  3,  9, 16,  5, 16,  3,  1, 15, 13, 13, 16,  4,  3, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [ 5, 16, 15,  1,  1, 14,  4,  5, 16,  3, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [ 9, 16,  3,  9, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [13, 15,  4,  9, 16, 14,  4,  5, 16,  9,  3, 16,  3,  4,  5, 16,  3, 10,\n",
            "         10,  3, 14,  4,  5, 10, 10, 12,  7,  1, 16, 15,  3],\n",
            "        [12,  4,  5, 16,  3,  5, 16, 12,  5,  1,  9, 16,  7, 13, 16,  1,  9, 12,\n",
            "          9,  3, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oeFMqZy0Tfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce7acdb-6997-45a9-9710-324372044e42"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_german_train, y_german_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[29317, 16867, 13175, 28347, 28852, 36008,  8163,  5647, 28347, 32810,\n",
              "          20632, 12978, 17400, 14183, 15813, 21689, 49511, 49511, 49511, 49511,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511],\n",
              "         [29464, 35754, 47506, 18065,   842, 49422, 26703, 23266,  4671, 21689,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511],\n",
              "         [42235, 46126, 28347,  4886, 34973, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511],\n",
              "         [ 9567, 16536, 14062, 39112, 39026, 49119, 17224,  8163, 18024, 45969,\n",
              "           5628, 47919,  5628, 26703,  8163,   746,  5628,  3810, 19682,  5628,\n",
              "          49422, 26703, 23266, 44656, 20227,  5723, 14420, 24658, 36333, 37633,\n",
              "          21840],\n",
              "         [33352, 46769,  8163, 32609, 28347, 29355, 38328,   743, 29355, 10944,\n",
              "          13513, 32021, 47506, 10762, 24319,  7522, 27657,  5723, 24949, 21689,\n",
              "          49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511, 49511,\n",
              "          49511]], device='cuda:0'),\n",
              " tensor([[ 1,  9, 16,  3,  9, 16,  5, 16,  3,  1, 15, 13, 13, 16,  4,  3, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
              "         [ 5, 16, 15,  1,  1, 14,  4,  5, 16,  3, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
              "         [ 9, 16,  3,  9, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
              "         [13, 15,  4,  9, 16, 14,  4,  5, 16,  9,  3, 16,  3,  4,  5, 16,  3, 10,\n",
              "          10,  3, 14,  4,  5, 10, 10, 12,  7,  1, 16, 15,  3],\n",
              "         [12,  4,  5, 16,  3,  5, 16, 12,  5,  1,  9, 16,  7, 13, 16,  1,  9, 12,\n",
              "           9,  3, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGRKT0CMSaHI"
      },
      "source": [
        "# Model Results for Training and Test Sets German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBgD04Bnyuvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7b1aa6-33b0-4fad-b023-6a449a3e94a4"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 100 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_german_train, y_german_train, batch_size=16), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_german_train,y_german_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_german_train,y_german_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   6%|▌         | 8/139 [00:00<00:01, 79.52batch/s, accuracy=42.8, loss=1.77]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(49512, 32)\n",
            "  (lstm): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 863batch [00:11, 75.74batch/s, accuracy=90.6, loss=0.284]\n",
            "Epoch 1: 863batch [00:11, 76.36batch/s, accuracy=97.1, loss=0.108]\n",
            "Epoch 2: 863batch [00:11, 76.70batch/s, accuracy=97.6, loss=0.0677]\n",
            "Epoch 3: 863batch [00:11, 75.49batch/s, accuracy=97.6, loss=0.055]\n",
            "Epoch 4: 863batch [00:11, 75.87batch/s, accuracy=98.8, loss=0.0357]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2KVizu4Sxnz"
      },
      "source": [
        "# Test data Accuracy for German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hlSeTAQ9amX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "1fe0d500-ad71-4f89-88c7-9fbff749828e"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 16 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_german_test, y_german_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-7c498e403472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mn_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_german_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_german_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop once over the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m                                                      \u001b[0;31m# Runs the test data through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Finds the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-145-561036e6fba8>\u001b[0m in \u001b[0;36mbatch_iterator\u001b[0;34m(sentences, labels, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n\u001b[0;32m----> 6\u001b[0;31m                           labels[i:min(i+batch_size, len(sentences))])\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                                               \u001b[0;31m# Move data to the GPU, if possible, before yielding it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-9b25f81e4c37>\u001b[0m in \u001b[0;36mpad_and_encode\u001b[0;34m(sentences, labels)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpadded_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<UNK>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mpadded_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'INTJ'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUQlsFoLSCCM"
      },
      "source": [
        "# Data Encoding and Padding for Finnish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSD9QYFM2DGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f28137e-05a7-4d5f-e073-3ec5916eec11"
      },
      "source": [
        "tokens = {token for sentence in X_finnish_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_finnish_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'ottaisimme', 'Augusto', 'maorien', '1993', 'vinkuu', 'helppoon', 'mystifioinut', 'lepoon', 'talouksissa', 'maailmanhistorian', 'assosiaationeuvostossa', 'teologina', 'epäoikeudenmukaisesti', 'Microsoft-pohjaisia']\n",
            "['INTJ', 'NUM', None, 'ADV', 'PUNCT', 'ADP', 'SYM', 'AUX', 'NOUN', 'X', 'PROPN', 'CCONJ', 'PRON', 'SCONJ', 'VERB', 'ADJ', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoeM5joO2Dfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39966f9-bfe0-44c7-fb2b-68e662996593"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_finnish_train[:5], y_finnish_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 8934,  4094, 18354, 45817, 46747, 43337, 18050, 18578, 22653, 21700,\n",
            "         49003, 49003, 49003, 49003, 49003],\n",
            "        [  944, 48855, 18806,  6334, 45877, 28140, 45502, 18571, 25453, 26013,\n",
            "         40763, 47470, 34318, 30026, 21700],\n",
            "        [ 4944,  5902, 31585,  6852, 39214, 21700, 49003, 49003, 49003, 49003,\n",
            "         49003, 49003, 49003, 49003, 49003],\n",
            "        [24332,  8478, 28140,  5243, 38251, 16368, 46864, 28140,  2533, 20644,\n",
            "         20292, 21700, 49003, 49003, 49003],\n",
            "        [ 8846, 26875, 22794, 16368,   730, 22528, 28140, 22409,  9118, 49003,\n",
            "         49003, 49003, 49003, 49003, 49003]])\n",
            "tensor([[ 8,  8, 14,  3, 15, 11, 15,  8,  8,  4, 16, 16, 16, 16, 16],\n",
            "        [ 3, 15,  8, 13,  3,  4, 13,  8, 14, 12,  3,  3,  8,  8,  4],\n",
            "        [ 3, 15,  8,  3, 14,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [13, 14,  4, 15, 10,  7,  8,  4, 12, 14,  3,  4, 16, 16, 16],\n",
            "        [13, 10,  8,  7,  3,  3,  4, 11,  4, 16, 16, 16, 16, 16, 16]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnjClrxh2Dxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7e1607-eef0-4e80-ff7f-8612171f8a52"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_finnish_train, y_finnish_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 8934,  4094, 18354, 45817, 46747, 43337, 18050, 18578, 22653, 21700,\n",
              "          49003, 49003, 49003, 49003, 49003],\n",
              "         [  944, 48855, 18806,  6334, 45877, 28140, 45502, 18571, 25453, 26013,\n",
              "          40763, 47470, 34318, 30026, 21700],\n",
              "         [ 4944,  5902, 31585,  6852, 39214, 21700, 49003, 49003, 49003, 49003,\n",
              "          49003, 49003, 49003, 49003, 49003],\n",
              "         [24332,  8478, 28140,  5243, 38251, 16368, 46864, 28140,  2533, 20644,\n",
              "          20292, 21700, 49003, 49003, 49003],\n",
              "         [ 8846, 26875, 22794, 16368,   730, 22528, 28140, 22409,  9118, 49003,\n",
              "          49003, 49003, 49003, 49003, 49003]], device='cuda:0'),\n",
              " tensor([[ 8,  8, 14,  3, 15, 11, 15,  8,  8,  4, 16, 16, 16, 16, 16],\n",
              "         [ 3, 15,  8, 13,  3,  4, 13,  8, 14, 12,  3,  3,  8,  8,  4],\n",
              "         [ 3, 15,  8,  3, 14,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [13, 14,  4, 15, 10,  7,  8,  4, 12, 14,  3,  4, 16, 16, 16],\n",
              "         [13, 10,  8,  7,  3,  3,  4, 11,  4, 16, 16, 16, 16, 16, 16]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HQlYNuoSczt"
      },
      "source": [
        "# Model Results for Training and Test Sets Finnish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FSr8m0UyrXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84769aef-37fd-41b3-b006-39c4a794c2d0"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 64 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_finnish_train, y_finnish_train, batch_size=64), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_finnish_train,y_finnish_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=100,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_finnish_train,y_finnish_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 6/186 [00:00<00:03, 54.52batch/s, accuracy=37.2, loss=2.01]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(49004, 32)\n",
            "  (lstm): LSTM(32, 100, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=17, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 186/186 [00:03<00:00, 47.50batch/s, accuracy=71.4, loss=0.887]\n",
            "Epoch 1: 100%|██████████| 186/186 [00:03<00:00, 48.62batch/s, accuracy=84.8, loss=0.455]\n",
            "Epoch 2: 100%|██████████| 186/186 [00:03<00:00, 47.99batch/s, accuracy=95.4, loss=0.15]\n",
            "Epoch 3: 100%|██████████| 186/186 [00:03<00:00, 48.09batch/s, accuracy=98.7, loss=0.0462]\n",
            "Epoch 4: 100%|██████████| 186/186 [00:03<00:00, 49.62batch/s, accuracy=100, loss=0.0124]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWzVtGLVS0I_"
      },
      "source": [
        "# Test data Accuracy for Finnish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aij-hxGNof3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5245b496-2eec-4885-83bc-01c982bf06ef"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 16 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_finnish_test, y_finnish_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 85.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuot-2j6SLSi"
      },
      "source": [
        "# Data Encoding and Padding for Swedish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOy3QfIQ17-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032e77cb-7488-40dd-d1ba-37d842aafbee"
      },
      "source": [
        "tokens = {token for sentence in X_swedish_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_swedish_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'dämpas', 'operationen', 'valmaskinleverantören', 'variera', 'trycks', 'Från', 'maktfullkomlig', 'Vardagstrafikanter', 'stadigare', 'preliminärskatt', 'namnetiketter', 'heter', 'Socialt', 'sociologerna']\n",
            "['INTJ', 'NUM', 'ADV', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'CCONJ', 'ADJ', 'PROPN', 'SCONJ', 'PRON', 'PART', 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww3LHB-018ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9bc0f7-f884-4f59-ec36-02da2b5bcc15"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_swedish_train[:5], y_swedish_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5563,  1085,  5550,  8922, 12809, 12809, 12809, 12809, 12809, 12809,\n",
            "         12809, 12809, 12809, 12809, 12809, 12809],\n",
            "        [ 5156,  2433,  4282, 11346,  1085,   974,  5087,  4413,  5550,  8922,\n",
            "          9808, 12809, 12809, 12809, 12809, 12809],\n",
            "        [ 4807,  9390,   101,  3057,  7066,  6322,  9833,  6357,  3057, 11408,\n",
            "          8346,  2524,  5550,  3688, 10261,  9808],\n",
            "        [   29,  9396,    51,  8346, 12593,  7031,   187, 12638,  9808, 12809,\n",
            "         12809, 12809, 12809, 12809, 12809, 12809],\n",
            "        [   29,  2935,   257,  8346,  6911,  6858,  3111, 10437,  9808, 12809,\n",
            "         12809, 12809, 12809, 12809, 12809, 12809]])\n",
            "tensor([[ 9, 15,  4, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [ 4, 15, 14,  9, 15,  3, 15,  3,  4, 15,  3, 16, 16, 16, 16, 16],\n",
            "        [12, 14,  2, 11,  2,  1, 15,  7, 13, 14,  4, 15,  4,  9, 15,  3],\n",
            "        [12, 14,  9,  4,  5, 15,  4, 15,  3, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [12, 14,  2,  4,  9, 15,  8, 15,  3, 16, 16, 16, 16, 16, 16, 16]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppQOGU418od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e30105-4408-4282-d2b0-829953f0a2b3"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_swedish_train, y_swedish_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 5563,  1085,  5550,  8922, 12809, 12809, 12809, 12809, 12809, 12809,\n",
              "          12809, 12809, 12809, 12809, 12809, 12809],\n",
              "         [ 5156,  2433,  4282, 11346,  1085,   974,  5087,  4413,  5550,  8922,\n",
              "           9808, 12809, 12809, 12809, 12809, 12809],\n",
              "         [ 4807,  9390,   101,  3057,  7066,  6322,  9833,  6357,  3057, 11408,\n",
              "           8346,  2524,  5550,  3688, 10261,  9808],\n",
              "         [   29,  9396,    51,  8346, 12593,  7031,   187, 12638,  9808, 12809,\n",
              "          12809, 12809, 12809, 12809, 12809, 12809],\n",
              "         [   29,  2935,   257,  8346,  6911,  6858,  3111, 10437,  9808, 12809,\n",
              "          12809, 12809, 12809, 12809, 12809, 12809]], device='cuda:0'),\n",
              " tensor([[ 9, 15,  4, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [ 4, 15, 14,  9, 15,  3, 15,  3,  4, 15,  3, 16, 16, 16, 16, 16],\n",
              "         [12, 14,  2, 11,  2,  1, 15,  7, 13, 14,  4, 15,  4,  9, 15,  3],\n",
              "         [12, 14,  9,  4,  5, 15,  4, 15,  3, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [12, 14,  2,  4,  9, 15,  8, 15,  3, 16, 16, 16, 16, 16, 16, 16]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k09zU4NSeTu"
      },
      "source": [
        "# Model Results for Training and Test Sets Swedish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np4kDAnzypZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3067de66-cf45-4ccf-c973-a4fa05fcb423"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 64 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_swedish_train, y_swedish_train, batch_size=64), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_swedish_train,y_swedish_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=100,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_swedish_train,y_swedish_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   8%|▊         | 5/66 [00:00<00:01, 45.45batch/s, accuracy=42.9, loss=1.96]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(12810, 32)\n",
            "  (lstm): LSTM(32, 100, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=17, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 66/66 [00:01<00:00, 44.32batch/s, accuracy=76.5, loss=0.727]\n",
            "Epoch 1: 100%|██████████| 66/66 [00:01<00:00, 43.88batch/s, accuracy=92.2, loss=0.261]\n",
            "Epoch 2: 100%|██████████| 66/66 [00:01<00:00, 43.27batch/s, accuracy=99.4, loss=0.0428]\n",
            "Epoch 3: 100%|██████████| 66/66 [00:01<00:00, 43.39batch/s, accuracy=100, loss=0.015]\n",
            "Epoch 4: 100%|██████████| 66/66 [00:01<00:00, 44.29batch/s, accuracy=100, loss=0.00517]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCLBIoLRS2cA"
      },
      "source": [
        "# Test data Accuracy for Swedish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNefmF7IoiIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683138ad-7c95-4be8-89d7-33c5957f4d7c"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 64 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_swedish_test, y_swedish_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 89.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZjGWdXTSOul"
      },
      "source": [
        "# Data Encoding and Padding for Hebrew"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msArfyOXj8P7",
        "outputId": "713a49a0-6d4c-4ce5-c531-6c5b26c0e6a6"
      },
      "source": [
        "tokens = {token for sentence in X_hebrew_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_hebrew_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'חזיתות', 'במעלה', 'יריות', 'ולעשות', 'המפד\"ל', 'בכרמל', 'הכלה', 'בבירות', 'רמקול', 'שמועות', 'אליך', 'בכמיליון', 'שיו\"ר', 'סרטי']\n",
            "['INTJ', 'NUM', 'ADV', 'PUNCT', 'ADP', 'DET', 'AUX', 'X', 'ADJ', 'SCONJ', 'PROPN', 'CCONJ', 'PRON', None, 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfqvcyfAj8hO",
        "outputId": "bb1948cb-0741-4bac-81ea-430689b862c7"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_hebrew_train[:5], y_hebrew_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[14048,   244, 18574, 24864, 26740, 26740, 19833, 12696,   312, 15807,\n",
            "          1803, 28532, 26796, 17891,  5378, 10135, 21064, 13172, 29666, 29666,\n",
            "         29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666,\n",
            "         29666, 29666],\n",
            "        [12749, 10155, 26085,  5866,  7706,   244, 11286, 26872,   312, 10979,\n",
            "          6625, 19260, 17891, 20957,  5546, 13172, 29666, 29666, 29666, 29666,\n",
            "         29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666,\n",
            "         29666, 29666],\n",
            "        [ 1839,   244, 19397, 12763, 19958,  1627, 27116,   312,  1006, 25852,\n",
            "         15693,  6697,   244,   401,  4979, 27836, 16409, 24271, 23152,  4954,\n",
            "           144,   312, 24271, 23152, 24028,  8479,   327, 26445,   244,  1647,\n",
            "         13172, 29666],\n",
            "        [13248,  9416,   312,  9043,  1684, 12541, 24271,   401,  1839,   244,\n",
            "         19397, 16994, 11711,  4791, 21639,  5138, 17040,  5866, 22043,   244,\n",
            "          8697, 16994, 14403, 23106,  8479,  7706,   244, 11286, 12493,   244,\n",
            "         19833, 13172],\n",
            "        [25852, 19699,  1839,   244, 19397, 25943, 16994, 24301,  5007,   244,\n",
            "         13248,  4489, 13028, 22929,   244, 10921, 16994,  6721, 11166,   312,\n",
            "          9086, 14513,  4791, 29149,  5138, 17891, 14752,  7583, 23152,  4200,\n",
            "         13172, 29666]])\n",
            "tensor([[13,  5, 15, 14, 15, 15, 15, 13, 11, 15, 14, 13,  4, 12,  4, 15, 15,  3,\n",
            "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [15, 15, 14,  4, 13,  5, 15, 13, 11, 14, 13,  4, 12, 15,  8,  3, 16, 16,\n",
            "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [13,  5, 15, 14,  2,  2, 13, 11,  2,  9, 14, 13,  5, 15, 14,  1, 13,  4,\n",
            "          5, 15, 13, 11,  4,  5, 15,  4, 15, 13,  5, 15,  3, 16],\n",
            "        [15, 13, 11, 15, 14, 13,  4, 15, 13,  5, 15,  3, 13,  4, 15,  4, 12,  4,\n",
            "         13,  5, 15,  3,  4, 14,  4, 13,  5, 15, 13,  5,  8,  3],\n",
            "        [ 9, 14, 13,  5, 15, 14,  3, 14, 13,  5, 15,  4, 15, 13,  5, 15,  3, 14,\n",
            "         13, 11, 14, 13,  9, 15,  4, 12, 13,  4,  5, 15,  3, 16]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBkJBPyDo42l",
        "outputId": "4272ab41-6d7b-4c88-9c36-f7668f56fbd1"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_hebrew_train, y_hebrew_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[14048,   244, 18574, 24864, 26740, 26740, 19833, 12696,   312, 15807,\n",
              "           1803, 28532, 26796, 17891,  5378, 10135, 21064, 13172, 29666, 29666,\n",
              "          29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666,\n",
              "          29666, 29666],\n",
              "         [12749, 10155, 26085,  5866,  7706,   244, 11286, 26872,   312, 10979,\n",
              "           6625, 19260, 17891, 20957,  5546, 13172, 29666, 29666, 29666, 29666,\n",
              "          29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666, 29666,\n",
              "          29666, 29666],\n",
              "         [ 1839,   244, 19397, 12763, 19958,  1627, 27116,   312,  1006, 25852,\n",
              "          15693,  6697,   244,   401,  4979, 27836, 16409, 24271, 23152,  4954,\n",
              "            144,   312, 24271, 23152, 24028,  8479,   327, 26445,   244,  1647,\n",
              "          13172, 29666],\n",
              "         [13248,  9416,   312,  9043,  1684, 12541, 24271,   401,  1839,   244,\n",
              "          19397, 16994, 11711,  4791, 21639,  5138, 17040,  5866, 22043,   244,\n",
              "           8697, 16994, 14403, 23106,  8479,  7706,   244, 11286, 12493,   244,\n",
              "          19833, 13172],\n",
              "         [25852, 19699,  1839,   244, 19397, 25943, 16994, 24301,  5007,   244,\n",
              "          13248,  4489, 13028, 22929,   244, 10921, 16994,  6721, 11166,   312,\n",
              "           9086, 14513,  4791, 29149,  5138, 17891, 14752,  7583, 23152,  4200,\n",
              "          13172, 29666]], device='cuda:0'),\n",
              " tensor([[13,  5, 15, 14, 15, 15, 15, 13, 11, 15, 14, 13,  4, 12,  4, 15, 15,  3,\n",
              "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [15, 15, 14,  4, 13,  5, 15, 13, 11, 14, 13,  4, 12, 15,  8,  3, 16, 16,\n",
              "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [13,  5, 15, 14,  2,  2, 13, 11,  2,  9, 14, 13,  5, 15, 14,  1, 13,  4,\n",
              "           5, 15, 13, 11,  4,  5, 15,  4, 15, 13,  5, 15,  3, 16],\n",
              "         [15, 13, 11, 15, 14, 13,  4, 15, 13,  5, 15,  3, 13,  4, 15,  4, 12,  4,\n",
              "          13,  5, 15,  3,  4, 14,  4, 13,  5, 15, 13,  5,  8,  3],\n",
              "         [ 9, 14, 13,  5, 15, 14,  3, 14, 13,  5, 15,  4, 15, 13,  5, 15,  3, 14,\n",
              "          13, 11, 14, 13,  9, 15,  4, 12, 13,  4,  5, 15,  3, 16]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrmu0sniSi40"
      },
      "source": [
        "# Model Results for Training and Test Sets Hebrew"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJdD92JtpIhw",
        "outputId": "7aa80b6a-1f68-4d3a-a801-52ed3dec54fa"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 64 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_hebrew_train, y_hebrew_train, batch_size=64), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_hebrew_train,y_hebrew_train,embedding_dim=32,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=100,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_hebrew_train,y_hebrew_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   4%|▎         | 3/82 [00:00<00:02, 28.53batch/s, accuracy=40.5, loss=2.11]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(29667, 32)\n",
            "  (lstm): LSTM(32, 100, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=17, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 82/82 [00:02<00:00, 27.45batch/s, accuracy=80.5, loss=0.547]\n",
            "Epoch 1: 100%|██████████| 82/82 [00:02<00:00, 27.43batch/s, accuracy=90.8, loss=0.273]\n",
            "Epoch 2: 100%|██████████| 82/82 [00:02<00:00, 28.00batch/s, accuracy=96.7, loss=0.108]\n",
            "Epoch 3: 100%|██████████| 82/82 [00:02<00:00, 27.80batch/s, accuracy=99.4, loss=0.0359]\n",
            "Epoch 4: 100%|██████████| 82/82 [00:02<00:00, 28.20batch/s, accuracy=99.5, loss=0.0145]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQGN7vIjS4wb"
      },
      "source": [
        "# Test data Accuracy for Hebrew"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjIKGPoCokpq",
        "outputId": "85fc3102-aeb1-43d0-e820-7c076505f977"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 64 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_hebrew_test, y_hebrew_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 92.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpfHNjDqSTjM"
      },
      "source": [
        "# Data Encoding and Padding for Afrikaans "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnctZ8x_1hcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe806de-02c2-459b-fccb-8bfe974ccdda"
      },
      "source": [
        "tokens = {token for sentence in X_afrikaans_train for token in sentence}\n",
        "idx2token = list(tokens)\n",
        "idx2token.insert(0, '<UNK>')\n",
        "idx2token.append('<PAD>')\n",
        "token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "tags = {tag for tags in y_afrikaans_train for tag in tags}\n",
        "idx2tag = list(tags)\n",
        "idx2tag.append('<PAD>')\n",
        "tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "print(idx2token[:15])\n",
        "print(idx2tag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<UNK>', 'verkies', 'voort', 'invoerpermit', 'nywerheidsbeleid', 'spesiale', 'toename', 'Via', 'ouditbeampte', 'www.info.gov.za', '30', 'leed', 'aparte', 'prysenswaardige', 'aanmerking']\n",
            "['NUM', 'ADV', 'PUNCT', 'ADP', 'DET', 'SYM', 'AUX', 'X', 'ADJ', 'SCONJ', 'PROPN', 'CCONJ', 'PRON', 'PART', 'VERB', 'NOUN', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALoEd_ul1h2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4f0aba-c1be-4627-b618-3dfeed3fab17"
      },
      "source": [
        "def pad_and_encode(sentences, labels):\n",
        "  assert len(sentences)==len(labels)\n",
        "  assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "  max_sentence_length = np.max([len(sentence) for sentence in sentences]) # Find out how much to pad\n",
        "  padded_sentences = torch.zeros(len(sentences), max_sentence_length,     # Create data structures with <PAD> as default\n",
        "                                 dtype=torch.long)\n",
        "  padded_sentences[:] = token2idx['<PAD>']\n",
        "  padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                              dtype=torch.long)\n",
        "  padded_labels[:] = tag2idx['<PAD>']\n",
        "  for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "    for j, token in enumerate(sentence):\n",
        "      if token in token2idx.keys():\n",
        "        padded_sentences[i, j] = token2idx[token]\n",
        "      else:\n",
        "        padded_sentences[i, j] = token2idx['<UNK>']\n",
        "    for j, tag in enumerate(tags):\n",
        "      padded_labels[i, j] = tag2idx[tag]\n",
        "  return padded_sentences, padded_labels\n",
        "\n",
        "a, b = pad_and_encode(X_afrikaans_train[:5], y_afrikaans_train[:5])\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1933, 2960, 1548, 4484, 4584, 2521, 2294,  138,  943, 3547,  144, 3575,\n",
            "         3029, 1548, 3284,  640, 3389, 2482, 3035, 2059, 3345, 4484, 2294, 1229,\n",
            "         2262, 2190, 3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082],\n",
            "        [1933, 2624,  943, 3547, 4484,  246,  640, 4632, 2059, 2697, 4484, 2375,\n",
            "         2498, 4484, 2668, 1474, 4929, 4484, 2489, 2498, 1764,  364, 1474, 2900,\n",
            "         3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082],\n",
            "        [1933, 4584,  943,  144,  896, 2935, 2059, 1947, 1761,  943, 3547,  627,\n",
            "          640, 4519, 4863, 1371, 4702, 4484, 1229,  798,  324,  686, 3202, 2727,\n",
            "         3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082],\n",
            "        [1933, 4292, 4943, 1548, 4484, 4584,  943, 2294, 3715,  798, 4397, 1365,\n",
            "         1548, 4484,  693, 1474, 4289, 1576, 2600, 2294, 4517, 1576,  227, 1474,\n",
            "         2498, 3715, 2498,  227, 1548, 4228,  269, 2059, 3035, 3345, 4484, 2294,\n",
            "         1229, 3623, 2468, 3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
            "         5082, 5082, 5082, 5082, 5082],\n",
            "        [ 144,  190, 1248, 1548, 4943,  943, 3725, 4484, 2800, 1474, 2751, 4484,\n",
            "         1204, 2877,  404, 1404, 1727, 1474, 2907,  404, 1766, 1727, 2498, 4484,\n",
            "         5081, 3008,  475, 1474, 2059, 3388, 2059, 1985,  798, 1963,  943, 3547,\n",
            "         1147, 4125, 3406, 4484, 3218,  640,  799, 1985, 1474,  686, 1730, 3547,\n",
            "         4484, 4584,  640, 1106, 3841]])\n",
            "tensor([[ 4, 15,  3,  4, 15,  3,  8, 15,  6,  3,  4,  0, 15,  3, 15, 13, 14,  3,\n",
            "         15, 12,  3,  4,  8, 15, 14,  6,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [ 4, 15,  6,  3,  4, 15, 13, 14, 12,  3,  4, 15, 11,  4, 15,  2,  9,  4,\n",
            "          8, 11,  8, 15,  2, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [ 4, 15,  6,  4,  8, 15, 12, 12, 14,  6,  3,  1, 13, 14,  9, 15,  3,  4,\n",
            "         15,  3, 15,  6,  6, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [ 4,  8, 15,  3,  4, 15,  6,  8, 15,  3,  4, 15,  3,  4, 15,  2,  8, 11,\n",
            "          8,  8, 15, 11, 15,  2, 11, 15, 11, 15,  3,  8, 15, 12, 15,  3,  4,  8,\n",
            "         15,  1, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [ 4,  8, 15,  3, 15,  6,  4,  4, 15,  2,  9,  4,  8, 15,  2,  7,  2,  2,\n",
            "         15,  2,  7,  2, 11,  4, 10, 10, 15,  2, 12, 12, 12,  1,  3, 15,  6,  3,\n",
            "          1, 15,  3,  4, 10, 13, 14, 13,  2,  6, 14,  3,  4, 15, 13, 14,  2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzoWu2-P1iS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d153883e-cb37-4a32-a514-90b866c51971"
      },
      "source": [
        "def batch_iterator(sentences, labels, batch_size=64):\n",
        "  \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "  assert len(sentences) == len(labels)\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    X, y = pad_and_encode(sentences[i:min(i+batch_size, len(sentences))], \n",
        "                          labels[i:min(i+batch_size, len(sentences))])\n",
        "    if torch.cuda.is_available():                                               # Move data to the GPU, if possible, before yielding it\n",
        "      yield (X.cuda(), y.cuda())\n",
        "    else:\n",
        "      yield (X, y)\n",
        "\n",
        "next(batch_iterator(X_afrikaans_train, y_afrikaans_train, batch_size=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1933, 2960, 1548, 4484, 4584, 2521, 2294,  138,  943, 3547,  144, 3575,\n",
              "          3029, 1548, 3284,  640, 3389, 2482, 3035, 2059, 3345, 4484, 2294, 1229,\n",
              "          2262, 2190, 3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082],\n",
              "         [1933, 2624,  943, 3547, 4484,  246,  640, 4632, 2059, 2697, 4484, 2375,\n",
              "          2498, 4484, 2668, 1474, 4929, 4484, 2489, 2498, 1764,  364, 1474, 2900,\n",
              "          3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082],\n",
              "         [1933, 4584,  943,  144,  896, 2935, 2059, 1947, 1761,  943, 3547,  627,\n",
              "           640, 4519, 4863, 1371, 4702, 4484, 1229,  798,  324,  686, 3202, 2727,\n",
              "          3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082],\n",
              "         [1933, 4292, 4943, 1548, 4484, 4584,  943, 2294, 3715,  798, 4397, 1365,\n",
              "          1548, 4484,  693, 1474, 4289, 1576, 2600, 2294, 4517, 1576,  227, 1474,\n",
              "          2498, 3715, 2498,  227, 1548, 4228,  269, 2059, 3035, 3345, 4484, 2294,\n",
              "          1229, 3623, 2468, 3841, 5082, 5082, 5082, 5082, 5082, 5082, 5082, 5082,\n",
              "          5082, 5082, 5082, 5082, 5082],\n",
              "         [ 144,  190, 1248, 1548, 4943,  943, 3725, 4484, 2800, 1474, 2751, 4484,\n",
              "          1204, 2877,  404, 1404, 1727, 1474, 2907,  404, 1766, 1727, 2498, 4484,\n",
              "          5081, 3008,  475, 1474, 2059, 3388, 2059, 1985,  798, 1963,  943, 3547,\n",
              "          1147, 4125, 3406, 4484, 3218,  640,  799, 1985, 1474,  686, 1730, 3547,\n",
              "          4484, 4584,  640, 1106, 3841]], device='cuda:0'),\n",
              " tensor([[ 4, 15,  3,  4, 15,  3,  8, 15,  6,  3,  4,  0, 15,  3, 15, 13, 14,  3,\n",
              "          15, 12,  3,  4,  8, 15, 14,  6,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [ 4, 15,  6,  3,  4, 15, 13, 14, 12,  3,  4, 15, 11,  4, 15,  2,  9,  4,\n",
              "           8, 11,  8, 15,  2, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [ 4, 15,  6,  4,  8, 15, 12, 12, 14,  6,  3,  1, 13, 14,  9, 15,  3,  4,\n",
              "          15,  3, 15,  6,  6, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [ 4,  8, 15,  3,  4, 15,  6,  8, 15,  3,  4, 15,  3,  4, 15,  2,  8, 11,\n",
              "           8,  8, 15, 11, 15,  2, 11, 15, 11, 15,  3,  8, 15, 12, 15,  3,  4,  8,\n",
              "          15,  1, 14,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
              "         [ 4,  8, 15,  3, 15,  6,  4,  4, 15,  2,  9,  4,  8, 15,  2,  7,  2,  2,\n",
              "          15,  2,  7,  2, 11,  4, 10, 10, 15,  2, 12, 12, 12,  1,  3, 15,  6,  3,\n",
              "           1, 15,  3,  4, 10, 13, 14, 13,  2,  6, 14,  3,  4, 15, 13, 14,  2]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOOP926hSldS"
      },
      "source": [
        "# Model Results for Training and Test Sets Afrikaans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUo_zBB6ygtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba1e504-02b9-41c1-8736-20a779e2eb11"
      },
      "source": [
        "#Create Model\n",
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, X_train, Y_train, embedding_dim, hidden_dim, vocabulary_size, tagset_size, bidirectional = True):\n",
        "    \n",
        "    super(LSTMTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.word_embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    self.vocabulary_size = len(token2idx) \n",
        "    self.tagset_size= len(tag2idx)\n",
        "    \n",
        "\n",
        "#LSTm takes word embeddings as input and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim,                         # The LSTM takes an embedded sentence as input, and outputs \n",
        "                         hidden_size=hidden_dim,                           # vectors with dimensionality lstm_hidden_dim.\n",
        "                         batch_first=True, bidirectional=True)\n",
        "    #self.lstm =nn.LSTM(embedding_dim, input_size=embedding_dim,hidden_size=hidden_dim, batch_first=True))\n",
        "    #self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
        "    self.fc = nn.Linear (hidden_dim*2, tagset_size)         #adding one more hidden layer for the bidirectional LSTM option\n",
        "    self.training_loss = list()                                                \n",
        "    self.training_accuracy = list()                         # The linear layer maps from the RNN output space to tag space\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "    embedded_sentences = self.word_embeddings(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "    sentence_lengths = (padded_sentences!=token2idx['<PAD>']).sum(dim=1)        # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, _ = self.lstm(X)                                                # Run the LSTM layer\n",
        "    X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True,total_length=max_sentence_length)         # Unpack the output from the LSTM\n",
        "    X = X.contiguous().view(-1, X.shape[2])   \n",
        "    tag_space = self.fc(X)                                                  # Fully connected layer\n",
        "    tag_scores = self.softmax(tag_space)      \n",
        "                              \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "      loss_function = nn.NLLLoss(ignore_index=tag2idx['<PAD>'])\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      batch_size = 64 \n",
        "      for epoch in range(5):                                                          # Times to loop over the full dataset\n",
        "        with tqdm(batch_iterator(X_afrikaans_train, y_afrikaans_train, batch_size=64), \n",
        "                  total=len(X_train)//batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:  \n",
        "          for inputs, targets in batches:\n",
        "            #print(targets.shape)\n",
        "            self.zero_grad()                                                 # Reset gradients\n",
        "            scores = self.forward(inputs) \n",
        "            #print(scores)                                                   # Forward pass\n",
        "            loss = loss_function(scores.view(-1, self.tagset_size),                 # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                                  targets.view(-1))               \n",
        "            loss.backward() \n",
        "                                                              # Backpropagate the error\n",
        "            optimizer.step()                                                          # Run the optimizer to change the weights w.r.t the loss\n",
        "            predictions = scores.argmax(dim=2, keepdim=True).squeeze()                # Calculate the batch training accuracy\n",
        "            mask = targets!=tag2idx['<PAD>']                                          # Create a mask for ignoring <PAD> in the targets\n",
        "            correct = (predictions[mask] == targets[mask]).sum().item()               # Item pulls the value from the GPU automatically (if needed)\n",
        "            accuracy = correct / mask.sum().item()*100\n",
        "            self.training_accuracy.append(accuracy)                                 # Save the accuracy for plotting\n",
        "            self.training_loss.append(loss.item())                                  # Save the loss for plotting\n",
        "            batches.set_postfix(loss=loss.item(), accuracy=accuracy) \n",
        "model = LSTMTagger(X_afrikaans_train,y_afrikaans_train,embedding_dim=100,                                       # Dimensionality of the work embedding\n",
        "                    hidden_dim=64,bidirectional = True,                                         # Dimensionality of the hidden state in the LSTM\n",
        "                    vocabulary_size=len(token2idx),                              # The vocabulary incudes both the 'padding' and 'unknown' symbols\n",
        "                    tagset_size=len(tag2idx))                                  # We have no interest in the network outputting the padding symbol\n",
        "print(model)\n",
        "model.fit(X_afrikaans_train,y_afrikaans_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 39.46batch/s, accuracy=62.8, loss=1.53]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(5083, 100)\n",
            "  (lstm): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=17, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 21/21 [00:00<00:00, 34.00batch/s, accuracy=79.2, loss=0.704]\n",
            "Epoch 1: 100%|██████████| 21/21 [00:00<00:00, 35.25batch/s, accuracy=89.6, loss=0.351]\n",
            "Epoch 2: 100%|██████████| 21/21 [00:00<00:00, 34.07batch/s, accuracy=95.5, loss=0.171]\n",
            "Epoch 3: 100%|██████████| 21/21 [00:00<00:00, 34.60batch/s, accuracy=98.7, loss=0.0706]\n",
            "Epoch 4: 100%|██████████| 21/21 [00:00<00:00, 34.62batch/s, accuracy=99.5, loss=0.028]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkTZuAmRS65D"
      },
      "source": [
        "# Test data Accuracy for Afrikaans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRVOL5UDomdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dd5773-8937-4215-f9a7-3689f35346e9"
      },
      "source": [
        "with torch.no_grad():                                                           # Do not use the following forward passes to calculate a gradient\n",
        "  n_correct = 0\n",
        "  batch_size = 64 \n",
        "  n_total = 0\n",
        "  for inputs, targets in batch_iterator(X_afrikaans_test, y_afrikaans_test, batch_size=batch_size): # Loop once over the test data\n",
        "    scores = model(inputs)                                                      # Runs the test data through the model\n",
        "    predictions = scores.argmax(dim=2, keepdim=True).squeeze()                  # Finds the predictions\n",
        "    mask = targets!=tag2idx['<PAD>']                                            # Create a mask for ignoring <PAD> in the targets\n",
        "    n_correct += (predictions[mask] == targets[mask]).sum().item()              # Sums the number of correct predictions\n",
        "    n_total += mask.sum().item()\n",
        "print(\"Test accuracy %.1f%%\" % (100*n_correct/n_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 90.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kCWJlWZp0Ma"
      },
      "source": [
        "# Qualitative Analysis and Model Evaluation \n",
        "\n",
        "When I made absolutely no changes to the model in between languages (I made sure to run the Spanish data set first), the accuracy varied quite a bit between the datasets, for Spanish the model achieved a 94.4% accuracy, whereas for Ancient Greek it achieved 74.4% and for Latin a 70.6% accuracy. There is an obvious difference here in terms of how much data is available for each of these languages. Spanish has the most out of all of them and therefore is able to also achieve the highest rate of accuracy. Ancient Greek and Latin have a comparable size in terms of how many sentences are available as per the data visualization tool at the beginning of each section. It should be noted that the parameters used to achieve this result are the following: \n",
        "\n",
        "embedding dimension =32\n",
        "lstm dimension =64\n",
        "batch size = 64\n",
        "\n",
        "When I changed the values to the following the accuracy suffered for both latin and greek, which presumably means these languages do not benefit from a highest embedding dimensionality. \n",
        "\n",
        "embedding dimension =100\n",
        "lstm dimension =64\n",
        "batch size=64\n",
        "\n",
        "In the end, for testing purposes with the additional languages for the extension I chose the following paramaters: \n",
        "bidirectional =True \n",
        "Embedding dimension = 72\n",
        "lstm dimension = 64\n",
        "batch size = 100\n",
        "\n",
        "Interestingly, with this model, the highest accuracies were in Spanish and Afrikaans. Presumably the size of the corpora is quite different for these two languages, but this LSTM model worked well on both, whereas it performed poorly on French, a relatively large and common language like Spanish.\n",
        "# Model Complexity and Accuracy \n",
        "If the model has too much complexity it will necessarily overfit, and the accuracy with the test set will be lower than it could be with a simpler model that is overfitting less. In order to avoid this one could tune the learning rate, but one could also use gridsearch to try to find the optimal parameters for the data given. Of course model complexity should vary with respect to the data that one is trying to classify, and some of these datasets, as we have seen in the paper I explore below, are smaller and therefore there is a lower possibela ccuracy overall. Additionally, some language benefit from high dimensionality while others do not. The bidirectional RNN layer I implemented does add to the models' complexity, but it allows for the model to see not only forwards, but forwards and backwards, and the accuracy improved across the board. The results are explained in more detail below. \n",
        "# Design Choices\n",
        "With regard to design choices, I went through several drafts of the preprocessing steps, and even tried implmenting a class to no avail when I would try to fit the model. I constantly got the error message that said there was a zero value array, which I tried to find by filtering out short sentences and printing out the shape of the array throughout the fit method, but ultimately concluded it was not necessarily the preprocessing that was the issue, but the way the data was getting fed into the model. \n",
        "I then refactored the class for the LSTM neural network from the begining and the preprocessing using a data loader worked well and the model could be trained a tested well. In doing this, I learned a bit about the different preprocessing options, and perhaps using the dataloader and dataset methods in a preprocessing class could be useful if one wanted to import many different languages in an easy and quick way, so as to minimize the number of preprocessing steps and cells one would have to run before fitting the model and getting the accuracy. \n",
        " # Defining a baseline\n",
        "I read the paper \"Do LSTMs really work so well for PoS tagging? – A replication study\" by Tobias Horsmann and Torsten Zesch. They explore extent to which LSTMs can be said to work well for sequence tagging tasks for different languages and for different LSTM variations. For determining a baseline, it seemed meaningless to define it in terms of the accuracy of a given language on the model since based on their research, the same model had a lot of variability in terms of accuracy going from one language to another. They divided the languages in their study into the main categories of germanic, romantic, slavic, and other. The languages I chose to do as a part of my initial implementation are all romantic, so I chose to average the accuracies of all the romance languages across only word, not word_char, and all the words, not just OOV, out of vocabulary words. I came up with the baseline of 93.5% in doing this. This means that the accuracy for the spanish corpus, even without significant tweaks to the model's parameter values, still performed above the baseline, while ancient greek and latin performed below the baseline. This could be due to the fact that there is not a growing corpora when it comes to these languages and the data we have available to train our models, given that they are no longer used. The UD corpora I imported for latin and greek are from the perseus project, which includes only classical texts that have been uploaded into a database and have all the parts of speech and additional information about case, tense, gender, and other features of the languages that are specific to these two ancient languages. \n",
        "# Expansion 1: Improving this model according to insights in a published paper (number 7 in extensions)\n",
        "The paper titled \"Do LSTMs really work so well for PoS tagging? – A replication study\" written by Tobias Horsmann and Torsten Zesch, touches on LSTM performance on fine grained tagsets. They conclude that the advantage of using an LSTM tagger is more notable when one is using a UD tagset that is significantly large. The advantage of using an LSTM grows proportionally with the size of the tagset. Notably, on morphologically rich tagsets, even the LSTM fails to recreate the results reported in other papers as the baseline in the same setup. \n",
        "\n",
        "Additionally, this paper explored the possibility of using word, char, word-char or word-char+ on the tagsets mentioned, and they cite the accuracy reported. It seems that an obvious improvement is to implement a bidirectional LSTM. Unlike what I did in my implementation, they used the bidirectional LSTM to provide the character embeddings of a word to the LSTM. It seems reasonable that including information about characters and words, with both forward and backward passes would benefit the accuracy of the model and it is certainly possible to use the UD treebanks available in this way. \n",
        "\n",
        "# Extension 2: Bidirectional RNN layer \n",
        "I initially failed to set bidirectional = True in one of the places where it was necessary. Not just in the place where one specifies the model and the self.fn, but also needed to do it inside of the LSTM layer, which could of course add the extra layer necessary. Additionally, it was necessary to change the parameter value for self.fn to hidden_layer*2, which would of course mean having two layers for the model to move forward and backward, making it bidirectional. The results of the model before and after this tweak are specified below in extension 3. Accuracy went up significantly after making this change. For example, in ancient greek the accuracy score went from 75.7% to 78.6%. When I implemented the RNN bidirectional layer incorrectly, the results improved only marginally, which would be explained by a simple variance in results from one training process to another where the model was slightly different and it performed slightly better the second time I ran it. \n",
        "\n",
        "\n",
        "# Extension 3: Adding more sources (number 6 in extensions)\n",
        "#A survey of accuracy of the working model in the following languages: \n",
        "\n",
        "Before Bidirectional RNN Layer \n",
        "\n",
        "Romantic Languages\n",
        "1. Spanish 94.4 %\n",
        "2. Ancient Greek 75.7%\n",
        "3. Latin 71.4%\n",
        "4. French 23.3%\n",
        "5. Italian 89.5%\n",
        "\n",
        "Germanic Languages \n",
        "\n",
        "6. Dutch 85.4%\n",
        "7. English 87.4 %\n",
        "8. German \n",
        "Tried to do German but there was a key arror when the model encountered a tag in the scoring method that was not present in training. We still have enough sources for the expansion, but it's worth noting this can happen from time to time with certain languages and their part of speech tags. \n",
        "9. Finnish 83.5 %\n",
        "10. Swedish 86.3%\n",
        "\n",
        "Other \n",
        "11. Hebrew 86.3%\n",
        "12. Afrikaans 90% \n",
        "\n",
        "\n",
        "After Implementing the Bidirectional RNN layer \n",
        "Romantic Languages\n",
        "1. Spanish 95.3 %\n",
        "2. Ancient Greek 78.6%\n",
        "3. Latin 72.3%\n",
        "4. French 27.3% (after tweaking the dimensionality to 100 for embeddings) This low accuracy could be due to this being a specific tagset in french and perhaps not the biggest in terms of sentence number. \n",
        "5. Italian 92%\n",
        "\n",
        "Germanic Languages \n",
        "\n",
        "6. Dutch 86.7%\n",
        "7. English 89.3 %\n",
        "8. German \n",
        "Tried to do German but there was a key arror when the model encountered a tag in the scoring method that was not present in training. We still have enough sources for the expansion, but it's worth noting this can happen from time to time with certain languages and their part of speech tags. \n",
        "9. Finnish 85.6 %\n",
        "10. Swedish 89.8%\n",
        "\n",
        "Other \n",
        "11. Hebrew 92.3%\n",
        "12. Afrikaans 90.7% This language benefitted quite a lot from increasing the dimensionality of the model. \n",
        "\n",
        "As I ran the model again with the bidirectional RNN layer, I also tweaked the dimensions to see what could happen with certain languages. For example, English did not benefit from that in terms of accuracy, but finnish, swedish, afrikaans, and hebrew. This could of course be because the languages that did benefit from this are more morphologically rich than languages like English.\n",
        "\n",
        "The average accuracy for the model without any improvements across all these languages was 79.37. The average accuracy for the tuned model with the additional RNN layer was 81.41. If we are to use the initial average percentage value as our baseline, the improved model did perform well after the improvements implemented. \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}